<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tech @ Namshi.com]]></title>
  <link href="http://namshi.github.io/atom.xml" rel="self"/>
  <link href="http://namshi.github.io/"/>
  <updated>2018-10-10T14:33:16+00:00</updated>
  <id>http://namshi.github.io/</id>
  <author>
    <name><![CDATA[Namshi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rewriting an MS SQL gateway with Golang]]></title>
    <link href="http://namshi.github.io/blog/2018/10/10/rewriting-ms-sql-talk-with-golang/"/>
    <updated>2018-10-10T05:51:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/10/10/rewriting-ms-sql-talk-with-golang</id>
    <content type="html"><![CDATA[<p>Innovation happens at an increasing rate today, which means code that is only one
or two years old might become outdated and hard to maintain.
In Namshi, we also face issues caused by legacy code. When an app starts to lag or break,
the team gathers and discusses a best approach to fix issues. Sometimes we do an incremental
refactor and other times we go for a complete rewrite.
This month we rewrote an app from scratch, and here is how we did it.</p>

<!-- more -->


<h3>Why?</h3>

<p>Namshi runs an app that acts as a gateway in front of an MS SQL server. We recently moved our MS SQL server to a different cloud provider, and our MS SQL gateway started to get stuck (taking more than 10 seconds to respond), causing slow operations in the apps relying on the gateway. We received daily (and nightly) calls due to slow response and needed to restart the app quite often. The limited amount of logging also made it hard for us to pinpoint the bottleneck. The app was also written in C#, a less used language in our team, and requires more attention.</p>

<p>Refactoring the code gives us the ease of not needing to go through a full development and testing cycle. However, the app might still get stuck and take huge effort to debug and maintain. On the other hand, a complete rewrite will improve stability, the logging system as well as easier performance management.</p>

<p>Considering the benefits of each approach, we decided to give it a complete rewrite.</p>

<h3>How?</h3>

<p>First we went out scouting for a driver. The driver we started with was the <a href="https://www.npmjs.com/package/mssql">Node.JS driver</a>. It was easy to use. However, it requires to specify SQL variable type when we create prepared statement. Our existing queries do not specify the SQL type for parameters, so it&rsquo;s painful to add all the fields. So, we decided to opt for a second choice, the <a href="https://github.com/denisenkom/go-mssqldb">Golang driver</a>. Golang has been popular in the backend team. We love it for its simplicity, performance, concurrency as well as its rapid development and growing community. Check out below the difference of creating prepared statement with NodeJS and Golang drivers:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>/* Node driver: create prepared statements */
const ps = new sql.PreparedStatement(/* [pool] */)
/* We need to specify the SQL type of parameters */
ps.input(&apos;param&apos;, sql.Int)
ps.prepare(&apos;select @param as value&apos;, err =&gt; {
    // ... error checks
    ps.execute({param: 12345}, (err, result) =&gt; {
        // ... error checks
        ps.unprepare(err =&gt; {
            // ... error checks
        })
    })
})</code></pre></figure>




<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-go'>// Golang driver: create prepared statements
// We don&apos;t need to specify the SQL type of parameters
db.QueryContext(ctx, `select * from t where ID = @ID and Name = @p2;`, sql.Named(&quot;ID&quot;, 6), &quot;Bob&quot;)</code></pre></figure>


<p>To run an MS SQL Server locally, we used this [Docker Image] (<a href="https://hub.docker.com/r/microsoft/mssql-server-linux/">https://hub.docker.com/r/microsoft/mssql-server-linux/</a>) and created a test database for rapid prototyping. Our first snippet of code only had a single function to execute a dummy query against the database.</p>

<p>From there, we started implementing the app as per the old <code>README</code>. We had to battle with taking care of data types (e.g, casting DECIMAL to float, or formatting dates correctly for MSSQL), use transactions in write queries and use connection pooling to enhance performance. For logging, we add logs for the time each query takes and the specific parameters each query uses. It becomes much easier for future troubleshooting and debugging.</p>

<h3>Rollout</h3>

<p>Rolling out a critical app requires careful planning. To start with, we rolled out the apps on staging and ran test queries to make sure everything worked fine. Then we switched a few live apps on a separate service and kept them running for a period of time. After couple days, we rolled out more live apps and fixed bugs as they came. A week later, we switched all live apps and checked logs closely to make sure all went well.</p>

<h3>Outcome</h3>

<p>With this rewrite we achieved much better performance! The integration with New Relic lets us check app performance in real time and figure out what is causing performance issue. Detailed logging allows us to debug and improve code rapidly. More importantly, this new app is well understood by the team and has been very stable since we switched. We are not receiving daily or nightly calls any more! :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Namshi is hiring: come and hack with us!]]></title>
    <link href="http://namshi.github.io/blog/2018/09/16/namshi-is-hiring-come-and-hack-with-us/"/>
    <updated>2018-09-16T13:27:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/09/16/namshi-is-hiring-come-and-hack-with-us</id>
    <content type="html"><![CDATA[<p>Looking for a fresh new start in 2019? We might have
the right opening for you!</p>

<!-- more -->


<p>In order to support the growth of our business, we&rsquo;re currently
beefing up our entire tech department, with the intention of
developing even <a href="http://namshi.github.io/blog/2017/05/28/rewriting-the-catalog-api/">faster services</a>
and delivering an even more <a href="http://tech.namshi.io/blog/2018/08/16/improve-our-exchange-process/">amazing customer experience</a>:
the end goal is to re-organize the structure of our team
(which has always been split by skillset, as in &ldquo;mobile&rdquo;, &ldquo;backend&rdquo;, etc)
and mimic the <a href="https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/">squad framework</a>, where technical teams are split
by &ldquo;business function&rdquo;.
We&rsquo;re never going to employ thousands
of engineers but, as we feel the need to build a bigger tech
pipeline and consequently hire additional software engineers,
we think the squad framework provides a good structure for
a bigger organization.</p>

<p>So, lots of hiring coming up here at Namshi: mobile, SRE, frontend, backend&hellip;   &hellip;you name it, we&rsquo;re probably hiring :)</p>

<p>Our mobile team, lead by <a href="https://www.linkedin.com/in/hannancs112/">Abdul</a>, is playing around with React Native
and works on a daily basis with Swift and the standard
Android toolkit (even though they&rsquo;ve been flirting with
Kotlin every now and then): their mission is to make
our mobile apps blazing fast, smooth and as crash-free as possible.</p>

<p>On the frontend side of things, our team
develops <a href="https://www.thinkwithgoogle.com/intl/en-145/which-brands-have-most-user-friendly-mobile-sites-united-arab-emirates-and-saudi-arabia/">amazing web UXes</a>
and internal tools used within the company: our frontenders
eat React for breakfast and are spearheaded by <a href="https://www.linkedin.com/in/shidhincr">Shidhin</a>, our
most senior frontend engineer.</p>

<p>On the backend, <a href="https://www.linkedin.com/in/carlesi">Carles</a>
and <a href="https://www.linkedin.com/in/ayham-alzoubi-06516a52/">Ayham</a>
lead a tight-knit team that focuses on delivering HTTP APIs for
our clients to consume: the team deals with scalability
and performance issues and solve problems that span across the
whole domain, mostly with NodeJS, Python and Go.</p>

<p>Last but not least, our SREs
build infrastructures for more than 100 services, all
deployed through Docker containers orchestrated by
Kubernetes. It is almost unbelievable to see what they
allow others teams to do, especially considering
the team is extremely small, as <a href="http://namshi.github.io/team/#Abdelrahman%20Shiddo">Abdelrahman</a> and
<a href="http://namshi.github.io/team/#Andrey%20Komarov">Andrey</a> are our only SREs.</p>

<p>Sounds interesting enough? Then drop us a line at <em>work-in-tech@namshi.com</em>
and let&rsquo;s have a chat!</p>

<p>Oh, I almost forgot &mdash; a couple more things before leaving:</p>

<ul>
<li>most of our engineers are quite senior, so we&rsquo;d like
to &ldquo;diversify&rdquo; and hire less experienced candidates:
juniors and intermediates are our ideal candidates as
of now. If you consider yourself a senior and would like
to apply, feel free to reach out, as we might be able to
work something out :)</li>
<li>I wrote about our hiring process a while ago but most
of it still stands, so I&rsquo;d recommend you to have a look at
our post &ldquo;<a href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/">Get that job at Namshi</a>&rdquo;</li>
</ul>


<p>Adios!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A new way to navigate around the Namshi android app]]></title>
    <link href="http://namshi.github.io/blog/2018/09/03/a-new-way-to-navigate-around-the-namshi-android-app/"/>
    <updated>2018-09-03T06:25:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/09/03/a-new-way-to-navigate-around-the-namshi-android-app</id>
    <content type="html"><![CDATA[<p>From a UX standpoint, it is really important to strike a good balance between usability and how information is organized within the application. Too much information might be overwhelming to the user, and an improper flow of the information will become a discouraging experience. Having a proper navigation pattern is vital as this helps the users to navigate between various hierarchies of structured or organized information.  One of the biggest challenges within the mobile application purview is in providing a proper navigation, especially due to the smaller size of mobile screens. Several navigational patterns have been designed but each has its own strengths and weaknesses.</p>

<!-- more -->


<p>Android Navigation Drawer (a.k.a Burger Menu or Side Menu) has been ruling Android apps UX for almost 5 years now. Google has made it so easy to implement that it became the primary choice of every app developer when it comes to app navigation. Almost all the apps developed by Google migrated to Navigation Drawer after it was released, so did the Namshi one.</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_07C9FE3356B59E821BA4395C1035CE40A82CC8DB34E1180E780172D6BED63FC6_1535430699961_NAMSHI-Android-Navigation-Drawer-small.gif" alt="Navigation pattern in NAMSHI Android App." /></p>

<p>As per good UX principles :
&ldquo;<strong>It is extremely important to present your users with the most important destinations within the app.</strong>&rdquo;</p>

<p>While Navigation drawer completely fulfills the above statement, There exist some fundamental problems with this navigation pattern.  Some of these problems are :</p>

<ol>
<li>Lower Discoverability</li>
<li>Less Efficient</li>
<li>Clash with Platform Navigation Patterns</li>
<li>Not Glanceable</li>
</ol>


<p>These problems are described in detail <a href="https://lmjabreu.com/post/why-and-how-to-avoid-hamburger-menus/">here</a></p>

<p>Side menu or a Navigation Drawer can hold relatively large amounts of heterogeneous contents. Apart from having a regular list of navigational items, it can also accommodate secondary information such as user profile details, or actions that are less frequently used but relevant under certain scenarios. One of the major advantages of having a Side menu or a Navigation Drawer is in its ability to save the screen real estate by taking the navigation away from the main screen, thereby making less overwhelming to the users but also can generally result in having poor visibility.</p>

<p>Another major downside of having a Side menu or a Navigation Drawer is that users tend to lose the context quickly as in which page/ destination they are currently in. This cannot be identified easily, as the navigation is hidden beyond the edges of the screen and always require a click of a button or a swipe. Such a limitation in providing a quick visual communication is considered non-desirable.</p>

<p>For an app like ours, with fewer top-level destinations, having a Navigation Drawer is kind of an overkill because there isn’t any secondary information displayed to the user other than the navigation. A fair amount of the screen remains, unused.</p>

<h2>Welcoming Bottom NavBar</h2>

<p>A good percentage of the users prefer to have a single-hand interaction with their mobile devices/ apps. Pressing on the Burger menu icon in the action bar or swiping a finger from the edge of the screen reveals the hidden Navigation Drawer. Most of the cases, using Navigation Drawer will require the use of your second hand.  Though this is a typical UX pattern followed in many play store apps, it is not really the best nor is necessary depending on the context of your app. It is imperative to have a consistent navigation and the flow within the app making sense to your users.</p>

<p>Bottom navigation is one of the best suitable navigation patterns, arguably due to its ergonomic placement on the screen. It provides quick and easy access to the various top-level destinations. As mentioned in the Google Material Design guidelines, it is recommended to use the new Bottom navigation when there are <strong>three</strong> to <strong>five</strong> top-level destinations thus making it ideal for the Namshi app, as it has five top-level destination pages (Home, Search, Wishlist, Shopping bag, and My Namshi).</p>

<h2>A little about the Namshi app Configuration</h2>

<p>Our app is highly configuration-driven. A set of configuration settings from our server, dictates the app on its various aspects such as the language of the displayed content, the home screen layout, content modules like images, gifs, videos, sliders, expandable/ scrolling lists, target for the user actions, showing quick alerts, arrangement of our products catalog, details in our checkout page, payment methods, our brand new delivery promises (<a href="http://tech.namshi.io/blog/2018/08/06/delivery-promises-in-the-wild/">read more</a>), region-specific business rules. Pretty much everything in the app… you name it, it’s configuration driven! Navigation too is no exception and will follow suit! A specific property in the app configuration decides how our users will navigate within the app. This makes the implementation of the new Bottom navigation much challenging as any new changes should not break the existing Navigation Drawer functionality.</p>

<h2>Implementing Bottom Navigation View</h2>

<p>Bottom Navigation View is available as part of the Android Design Support library and the corresponding dependency should be added in the app <code>build.gradle</code> file.</p>

<pre><code>dependencies {
  ...
  compile 'com.android.support:design:&lt;relevant.sdk.version&gt;'
  // This was added in version 26.1.0. Visit the android doc for more info.
}
</code></pre>

<p>Once this dependency is added, next would be to include the BottomNavigationView in your app layout. Add the BottomNavigationView to the root layout of your app.</p>

<pre><code>&lt;android.support.design.widget.BottomNavigationView
       android:id="@+id/namshi_bottom_navigation"
       android:layout_width="match_parent"
       android:layout_height="wrap_content"
       android:layout_gravity="bottom" /&gt;
</code></pre>

<blockquote><p>Having a CoordinatorLayout as the root will enable us to use <strong>bottom navigation behavior</strong>. This behavior will make the BottomNavigationView scroll aware by hiding/ showing it when users scroll through a list thereby giving more space for displaying contents.</p></blockquote>

<p><strong>Other Supported Attributes</strong>
Below are some of the supported attributes.</p>

<ul>
<li><strong>elevation</strong> &ndash; Controls the elevation of this view.</li>
<li><strong>itemIconTint</strong> &ndash; Single color or even a color selector &ndash;  Sets the color of the menu item icon depending on their states.</li>
<li><strong>itemTextColor</strong> &ndash; This attribute can be used to change the title text color of the menu item. Supports a single color or a color selector.</li>
</ul>


<p><strong>Setting Bottom navigation Menu Items</strong>
Adding menu items to a BottomNavigationView is similar to that of adding menu items to a NavigationView in a Navigation Drawer layout. Menu items can be defined in an xml menu resource file or can be added dynamically. Being configuration-driven, it makes more sense to dynamically add the menu items depending on the configuration, rather than to have it populated from a static menu resource file.</p>

<blockquote><p>BottomNavigationView supports up to five menu items and anything more than that will result in a Runtime exception, crashing the app. This is a typical scenario that can occur upon activity re-creation when menu items are added dynamically.</p></blockquote>

<p>See to it that a proper check is in place, so as to not exceed the limit of menu items in the BottomNavigationView. An alternative to this is to clear any existing menu items prior to populating it.</p>

<pre><code>fun addBottomNavigationMenuItems() {
  bottomNavigationView?.let { bnv -&gt;
      bnv.menu?.let { menu -&gt;
          menu.clear()
          // Add menu items to bnv here
      }
  }
}
</code></pre>

<p>BottomNavigationView has a lot of limitations compared to many 3rd party Bottom navigation libraries. One such main limitation is the lack of support for Action Views in menu items. Android provides custom view support for menu items by the means of Action Views. Unfortunately, BottomNavigationView tends to ignore the Action Views, making it hard to customize individual menu items. Setting an Action View on the BottomNavigationView menu items seems to have no effect by which it is drawn in the layout. Below code snippet illustrates adding a Search menu item dynamically to the BottomNavigationView.</p>

<pre><code>val menuSearch =
    bottomNavigationView.menu.add(
      Menu.NONE, R.id.bottom_nav_item_search, Menu.NONE, R.string.search)

menuSearch
  .setIcon(R.drawable.bnv_search_selector)
  .setActionView(View(context))
  .actionView.tag = arrayOf(FRAGMENT_PRODUCTS_SEARCH)
</code></pre>

<p>Even though BottomNavigationView ignores the Action Views, this can still be leveraged to make our new navigation aware of the destination pages. Every menu item has an Action View set to it, so that, the respective Action Views can hold a list of fragment tags that it represents. More about this is in the <strong>Fragment Awareness</strong> section, below.</p>

<h2>Event listeners</h2>

<p>Just like any other views, BottomNavigationView also has got a set of events and associated listeners to it. The one we are interested now is <strong>OnNavigationItemSelectedListener</strong>. Selecting any menu items will trigger the <strong>onNavigationItemSelected()</strong> event of this particular listener. This event will also pass along with it the selected menu item based on which, appropriate logic for the navigation is performed.</p>

<pre><code>override fun onNavigationItemSelected(item: MenuItem): Boolean {
  when (itemId) {
      ...
      R.id.bottom_nav_item_search -&gt; appMenuListener.displaySearchFragment()
      ...      
  }
}
</code></pre>

<h2>Fragment awareness and support for Deep links</h2>

<p>The Namshi android app follows a Single Activity and Multiple Fragments pattern and its architecture are highly decoupled. A helper class is responsible for performing all fragment transactions and this is in turn used by the AppMenuListener (a dagger2 dependency) which encapsulates the necessary logic for performing navigation to the appropriate destination page. When a user selects any particular navigation menu item, the corresponding event is triggered that invokes a specific action defined in the AppMenuListener.</p>

<p>Apart from this, users can still navigate to any destinations within the app by external means such as a Push Notification or even by Deep-links. In the Namshi android app, deep-links are resolved by a DeepLinkListener (yet another dagger2 dependency) which will perform the relevant routing, making use of the actions defined in the AppMenuListener. Implementing a consistent navigation across the app and to maintain the proper menu item states without changing this underlying implementation becomes challenging because, in such scenarios, navigation is not through but outside the bottom navigation.</p>

<p>In order to overcome this, our BottomNavigationView controller has implemented OnBackStackChangedListener of the FragmentManager class, which will trigger an event whenever a fragment is changed in the back stack. This will try to match the tag of the topmost fragment in the back stack to that stored in the navigation menu items.</p>

<pre><code>override fun onBackStackChanged() {
  clearMenuItemState()
  // NPE Check - if not detached from the activity
  val topFragment = FragmentHelper.getTopFragment(activity)
  topFragment?.let { fragment -&gt;
    changeMenuItemState(fragment.tag)
  }  
}

fun changeMenuItemState(fragmentTag : String ?) {
    ... // Clear previous menu states if required
    menu?.let {
      for (i in 0 until it.size()) {
          val menuItem = it.getItem(i)
          menuItem?.let { item -&gt;
              val tags = item.actionView?.tag as? Array&lt;String&gt; ?: null
              val index = tags?.indexOf(fragmentTag) ?: -1
              if (index &gt;= 0)
                ... // Change the menu item state and return
          }
      }
    }
}
</code></pre>

<p>Let’s see the new Bottom navigation in action!</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_07C9FE3356B59E821BA4395C1035CE40A82CC8DB34E1180E780172D6BED63FC6_1535456216606_ezgif.com-resize+2.gif" alt="" /></p>

<h2>Notification Bubble</h2>

<p>One of the most sought-after features for the Bottom navigation is to have a notification bubble with a notification count which is not supported by the BottomNavigationView out of the box. Using Action Views would have been the ideal approach for such use cases, but that is not an option here! Having that said, it is also not an impossible task either, to implement a simple Notification bubble to the menu items in the BottomNavigationView. Just a tiny tweak in the BottomNavigationView layout hierarchy can help us reach our goal! Every menu item in the BottomNavigationView is essentially a <strong>BottomNavigationItemView</strong> extending the android <strong>FrameLayout</strong>. There are no APIs available to interact with this directly. Below is a sample snippet for adding a notification bubble/ badge to any specific menu item in the BottomNavigationView.</p>

<pre><code>fun addNotificationBadge() {
  bottomNavigationView?.let {
      ... // Get the Menu View from the parent BottomNavigationView
      menuView?.let { mView -&gt;
        ... // Get the corresponding menu item index
        val menuItemView = mView.getChildAt(/*index*/) as? BottomNavigationItemView
        val bubbleView = LayoutInflater.from(context)
                        .inflate(R.layout.bottom_nav_bubble_layout, null)
        ... // Find the corresponding view to update the count
        menuItemView.addView(bubbleView)
      }
  }
}
</code></pre>

<p>Voila! Make sure to add the notification bubble during the initial setup of the BottomNavigationView but after the initialization of the menu items.</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_07C9FE3356B59E821BA4395C1035CE40A82CC8DB34E1180E780172D6BED63FC6_1535456573986_ezgif.com-gif-maker.gif" alt="Notification bubble in action" /></p>

<blockquote><p>It will be good to consider making the notification bubble layout as simple as possible so as to reduce the layout over-draws. Adhere to good practices, use flat rather than nested or intricate layouts!</p></blockquote>

<h2>Future enhancements</h2>

<p>During I/O 2018, Google introduced the new <strong>Navigation-components</strong> to the Android Architecture which will greatly simplify the way navigation is done within the app. This will help in implementing a consistent navigation between various destinations within your app in a disentangled way. Each destination can be a fragment, an activity, a navigation graph or a subgraph. Custom destinations are also supported. Navigation-components also support actions, type-safe arguments, deep-links and will also go well with the BottomNavigationView. Many of the problems and user requirements mentioned above can be addressed with this. One such important issue that this will solve, is building the stack of destination pages when a user navigates through a deep-link, which otherwise would have happened during manual navigation. Our app, being mostly a “Single Activity and Multiple Fragments app” can be easily migrated to the new Navigation Architecture with less effort. This promising new addition to the Android Architecture enforces conformance to the Architecture guidelines thereby facilitating a consistent and predictable navigation by decoupling the routing logic that otherwise is contained in the view layer, which can become quite tedious to maintain and modify in larger applications.
Another great feature to have with Bottom navigation is to introduce the <strong>Bottom Navigation Behavior</strong> which will show and hide the Bottom Navigation View when a user scrolls through a huge list just like our Products catalog page, giving more space for displaying the list contents.</p>

<h2>To wrap-up!</h2>

<p>Android BottomNavigationView has got several limitations and there are many 3rd party implementations overcoming them. Nevertheless, none of that has stopped us from using it in the Namshi android app. We at Namshi embrace new challenges that help us get better in delivering the best experience for our users. Apart from this fixed navigation pattern, the deep-links support provides quick access to any specific destinations within the app rather than to go through multiple levels, manually. Fragment awareness comes in handy, as this will make the Navigation menu items to be on the right state when the destination page is loaded. By using Bottom Navigation, the content of the app of becomes readily discoverable and it gets easy to do single-handed navigation.
Go ahead and download <a href="https://play.google.com/store/apps/details?id=com.namshi.android&amp;hl=en">Namshi App</a> from Google Play and let us know how the new navigation feels like!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How we improved our return process and increased customer satisfaction by 22%]]></title>
    <link href="http://namshi.github.io/blog/2018/08/16/improve-our-exchange-process/"/>
    <updated>2018-08-16T00:00:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/08/16/improve-our-exchange-process</id>
    <content type="html"><![CDATA[<p>One of the biggest challenges for e-commerce portals is to be able to deliver the same, or even a better, kind of experience physical retailers offer in terms of size exchanges. When you want to return a jacket at the Zara store next door, you simply walk to the store, ask for a larger size, and swap your return with the new, larger jacket — in case that size is out of stock you will immediately be refunded. In any case, it’s <a href="https://en.wikipedia.org/wiki/Gratification#Instant_and_delayed_gratification">instant gratification</a>.</p>

<!-- more -->


<p>Usually, in an e-com transaction, a 3rd party courier is involved in the delivery of the goods, and the same applies when customers want to return, or exchange an item they purchased.</p>

<p>This leads to an interesting dichotomy, as e-commerce should, in theory, ease the process: but by waiting for the courier to collect the original item and deliver it back to the store; let the store confirm the return is in good condition, hand the new item to the courier and wait for the courier to deliver it to you…the <strong>customer experience suffers</strong>. This process can take weeks, and can be definitely improved.</p>

<p>At the beginning of this year, we focused our attention towards our exchange process (when you bought an M but want to replace it with an L), in order to make it seamless for customers to exchange items they purchased at <a href="https://www.namshi.com">Namshi</a>. We believe we’ve made strides in this process and wanted to share with you the changes we’ve implemented, our rollout strategy and the challenges we’ve faced along the way.</p>

<p>The new process we rolled out allows customers to request a new size <strong>without having to place a new order</strong>, <strong>without having to worry about the new size going out of stock</strong>, and have it delivered to their doorstep, in some cases, <strong>in less than a day</strong>.</p>

<p>Let’s get to it.</p>

<h2>Our original exchange process:</h2>

<p>Our original exchange process had a pretty basic flow.  A customer would place an order with some items, and if they decided to return any item(s), a return would have to be initiated via the account section. Our driver would then head over to collect the items that needed to be returned. Once those items reached our warehouse, we would then refund the amount owed back either as <a href="https://www.namshi.com">Namshi</a> credit or as a credit / debit card refund. At this point, the customer could place a new order for the new size.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/exchange-size.JPG"></p>

<p>This approach seemed pretty dated as our customers suffered because of the extended time frame of the whole process, during which the size they wanted instead could have ran out of stock, but also because during this time, the price of the product may have fluctuated. This might result in them having to pay a higher price.</p>

<h2>So… We added exchanges!</h2>

<p>At first, It wasn’t clear how we were going to implement exchanges. We knew we had all the components for creating an exchange in place, so it was a matter of connecting the dots to produce a single process that makes it easy for the customer to create an exchange with just a few clicks.</p>

<p>Therefore, we had to make sure of a few things:</p>

<ol>
<li>We have the relevant replacement items in stock.</li>
<li>The returned item always reaches our warehouse before we release the new shipment.</li>
<li>The customer won’t have to pay anything extra, even if the exchange item’s price increased.</li>
<li>The customer’s wallet balance should never become negative.</li>
</ol>


<p>We created a new API that could handle both normal returns and exchanges. This API proxies all normal return requests to the returns service, while handling exchange requests also. In the case of exchanges, the API first creates the exchange order, this guarantees the stock to be reserved. Then a return request is created which is associated with the newly created exchange order. The customer just has to wait for the courier to come and pick up the original item. Once the item is picked and returned to the warehouse, we ship the exchange order.</p>

<p>For exchanges, we handled the payment of the exchange order via our customer wallet. Normally we charge the customer wallet as soon as an order is placed. However in this case, we hold on to charging the wallet until the returned item is refunded back to the wallet. This ensures that we only use the refunded money to pay for the exchanged item. This also prevents a customer’s wallet balance from becoming negative since we refund first then charge the wallet. These actions are clearly reflected in the customer’s credit section.</p>

<p>We also had to account for unhappy flows; For instance a customer may cancel the return, so there would be no item to be picked up. In this case we cancel the exchange item as well, because there may be no funds available in the customer’s wallet to cover for the new item. Also we can fairly assume that since the customer canceled the return, they probably changed their mind about the exchange.</p>

<p>Additionally, we created a cron job that is responsible for canceling any exchange orders if we don&rsquo;t receive the original item (for whatever reason) within 2 weeks of creating the exchange request.</p>

<p>We&rsquo;ve rolled out exchanges to our markets, sent out surveys and our customers were very satisfied with the new process. It was clearly a success story, but we wanted to do more! We thought to ourselves, so instead of waiting for the item to reach the warehouse to release the new item, why don&rsquo;t we do it at the customer&rsquo;s <strong>doorstep</strong>.</p>

<h2>How did we roll out doorstep exchanges?</h2>

<p>At the doorstep exchanges entailed our courier agent going to a customer’s delivery address, picking up the original item and handing over the new product in one go!</p>

<p>In order to do this, we built a flag in our systems to recognize these swap requests. Once this was done, just as with exchanges, we began to reserve items as soon as we received a request for a doorstep exchange. This shipment was released to the same courier agent who was expected to collect the original item.</p>

<p>Since at the door exchanges was a novel concept in the region, we conducted an extensive training process for our courier agents. We trained them to identify and match items so that items returned back to us matched the ones we were handing over to our customers. We also had to ensure that our agents could handle scenarios where our customers were only returning some items from an order, receiving other orders at the same time, changing their mind regarding their swap requests when the courier agent arrived etc.</p>

<p>Once we were confident that our in-house courier agents could handle doorstep exchanges, we began rolling it out incrementally to customers across UAE. We began with Sharjah, followed by Fujairah, Ajman, Ras al Khaimah, Al-Ain, Abu Dhabi and finally Dubai. We rolled out doorstep exchanges successfully across the UAE within the course of just 5 weeks!</p>

<h2>Feedback! Feedback! Feedback!</h2>

<p>The end goal is always customer satisfaction!</p>

<p>For this purpose, we ran 3 surveys to gauge how our customers felt about our original returns service, exchanges and at the doorstep exchanges.</p>

<p>We wanted to learn whether customers were satisfied with these services and also if there was anything we could do to improve these further.</p>

<h2>Returns:</h2>

<p><img class="center" src="http://namshi.github.io/images/posts/returns-chart.png"></p>

<p>We found out that our customers were pretty satisfied with the original returns process with a combined satisfaction rate of very satisfied and satisfied customers at 75%.</p>

<p>For those customers who expressed that they were dissatisfied with our service and if they gave us feedback as to why they were unhappy, we analyzed their responses to see if we could further improve the returns process and factor those suggestions in.</p>

<h2>Exchanges:</h2>

<p>Given that we just launched exchanges across all our markets, we were pretty excited to hear back from customers about how they felt about this new venture.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/exchanges-chart.png"></p>

<p>and voila!</p>

<p>Our customer satisfaction rate shot up to 88%.</p>

<p>Our customers loved this new feature! Exchanges now enabled us to reserve items for customers and ensure that they get the same deals, discounts and prices that they purchased their items for.</p>

<p>We received some feedback from customers regarding our process seeming too long. Our courier partner would collect the original item(s) from the customer and we would dispatch the exchange item(s) once we received the original one(s).</p>

<p>This feedback tied in neatly with our next initiative… At the door exchanges!!!</p>

<h2>At the door exchanges</h2>

<p>Once we launched doorstep exchanges, we ran another survey to see what our customers thought:</p>

<p><img class="center" src="http://namshi.github.io/images/posts/swaps-chart.png"></p>

<p>We reached a 92% satisfaction rate with at the doorstep exchanges.</p>

<p>Both regular exchanges and at the doorstep exchanges were a success with our customers!</p>

<h2>What we wanted to achieve:</h2>

<p>By enabling exchanges across Saudi Arabia, Kuwait, Oman and Bahrain, we succeeded in accomplishing a significant KPI we set for ourselves: boosting our customer satisfaction rate. While international exchanges did not improve our delivery time, we managed to make our customers happy by reserving products they liked and purchased in the sizes they wanted, ensured they continued to benefit from any deal or discount they purchased it with and if the price for that product went up, our customers weren’t obliged to pay the difference!</p>

<p>With at the doorstep exchanges, we went even further.  Not only did we further boost our customer satisfaction rate, we also managed to reduce overhead costs by having our couriers pick up the original item and drop off the exchange item in one trip. Our exchange delivery time went down from an average of 4.2 days to just 1.3 days in the UAE.</p>

<p>We’ve only been able to roll out doorstep within the UAE using our in-house carrier Last Mile. This is primarily because we had the capacity to train our courier agents on the swap process. Scaling this feature internationally would entail working with and training our courier partners to be able to conduct these swaps for us. This limitation prevents us from rolling this feature out internationally, but we would love to be able to work with our external courier partners to be able to do so!</p>

<p><em>This article has been a joint effort between the Software Engineers and Product Managers who planned and changed the process: <a href="http://namshi.github.io/team/#Ala%20Hawash">Ala</a>, Sakina Sagarwala and
<a href="http://namshi.github.io/team/#Ayham%20Alzoubi">Ayham</a>.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Delivery promises in the wild]]></title>
    <link href="http://namshi.github.io/blog/2018/08/06/delivery-promises-in-the-wild/"/>
    <updated>2018-08-06T11:57:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/08/06/delivery-promises-in-the-wild</id>
    <content type="html"><![CDATA[<p>We recently launched a new feature which we internally call <strong>“delivery promises”</strong>. This feature informs our users the expected delivery lead time of individual products, based on their location. Users select their location from a drop down list and a timer counts down to the next available delivery dispatch time. This allows users to know how much time they have to place an order to receive their item at the next earliest possible delivery date.</p>

<p><img class="center" src="http://namshi.github.io/images/dp.png"></p>

<!-- more -->


<p>E-commerce has made great technological strides in the last decade. There’s no doubt in anyone&rsquo;s mind that the paradigm shift of what the experience of  a “purchase” is has already taken place. E-commerce will only get larger, while brick &amp; mortar will continue to dwindle. Yet all of this innovation still fails to recreate the sensations of instant gratification most shoppers feel at the checkout aisle. This gap in the process can be taken advantage off. By giving users a determined and relatively quick delivery date such as same day or next day delivery, we can bridge the gap just enough to provide semi-instant gratification. This semi-instant gratification, is enough to pass off as a reward to entice users into completing the purchase within a certain time frame to remain eligible for it.</p>

<p>Yet, this feature is a double edged sword. On the one hand, you can increase conversion rates and customer satisfaction when everything works well. On the other, users are much more irate when delivery is not made at the expected times.</p>

<p>In order to test the success and impact of this project we had to benchmark it against a few <strong>KPI’s</strong>.</p>

<p>We decided the best would be to track how our:</p>

<ol>
<li>Products-added-to-cart % changed</li>
<li>The change in average session duration for users that checked out products</li>
<li>The overall conversion rate</li>
<li>The % of orders that got delivered within the promised date</li>
<li>The change in delivery related inquiries our customer service team received.</li>
</ol>


<p>We decided to roll out slowly, segmenting by platform and geographical region. We started first on our web mobile platform and then slowly rolled it out to our apps all within certain geographical regions where we could ensure a higher minimum delivery <strong>SLA</strong>.</p>

<p>Our goal for the UI was to make the expected delivery information instantly accessible and visible, without compromising on more important information like product image, description, price and available sizes. Keeping the natural flow of the page is critical.</p>

<p>To achieve this goal, we added the feature section right after the product image/details section; where we show 3 pieces of information:</p>

<ol>
<li>Live countdown timer that counts down to the next available delivery dispatch for that location.</li>
<li>City selection dropdown field for users to select their location.</li>
<li>Estimated delivery time as per the selected city</li>
</ol>


<p><img class="center" src="http://namshi.github.io/images/dp1.png"></p>

<p>We also added this information in our cart view popup to keep users engaged and informed about the expected delivery dates for their orders.</p>

<p><img class="center" src="http://namshi.github.io/images/dp2.png"></p>

<p>Initially, we wanted to add the feature to our checkout page too. However, we found that it won’t be possible because we currently take user delivery addresses in open input text fields. Users can enter any text to describe their locations including cities, hence, we could not query the expected delivery service without a properly formatted input which would be in the form of a predefined set of cities. Goes to show that something as simple as a field type could be a blocker for a feature to work!</p>

<p>One of the challenges we faced was to find a way to display the most accurate delivery information as fast as possible and also customizable on the product level.</p>

<p>Collaboration with the ops team and understanding their delivery challenges was critical in the development of this feature. Despite this only being a forecast, our users would view this as a promised commitment. If a customer reads and believes that his order will arrive the same day, receiving it late may result in a tremendous loss of good-will.</p>

<p>Due to this risk, we created an internal tool for our warehouse and operations team. This tool allows our teams to change the delivery lead time for different locations on the fly. It also allows for the changes in delivery cut-off times. At any point if we receive an overwhelming amount of orders they would be able to change the lead times and/or cut off times within seconds.</p>

<p>One important issue that we faced was with time zones. In order to provide an accurate delivery promise we need to know where the customer is located and where we have the product stored. Each one can be in different time zones which makes the logic harder. Imagine that you send a product from GMT+4 to your customer but they’re living in GMT+3, you know that the delivery will take 1 hour and you send it at 8 a.m. so you tell to your customer that he will receive it at 9 a.m. but actually he will receive it at 8 a.m. As your 9 a.m. is their 8 a.m.
One way to solve this is to tell the customer how long it will take instead of specifying the delivery date, for example: “in 1 hour and 15 minutes”, but for longer periods of time this becomes less useful. Another way is to yield this responsibility to the frontend as they know the actual timezone of the customer. So only sending the amount of time it will take for us to deliver, will allow for the front end to specify the delivery date perfectly to the user.</p>

<p>Another critical point for this feature is that it’s present in all parts of our customers critical path, so in addition to deciding how to implement it we had to rack our minds to decide where we needed to show it. Implementing this in our catalog proved challenging in terms of maintaining performance. In order to reduce the footprint we had to think carefully as to how we implemented and managed the cache. We did load testing to see how performance was affected. Our results showed that we increased the response time by between 1 to 5 milliseconds. This was not ideal, but still acceptable.</p>

<p><strong>We hope this feature helps you, and you get your packages on time!</strong></p>

<p><em>This post is a joint effort between the brains behind this feature: <a href="http://namshi.github.io/team#Carles%20Iborra">Carles Iborra Sanchez</a>,
<a href="http://namshi.github.io/team#Ammar%20Rayess">Ammar Rayess</a> and Razek Amir.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moving from Prometheus to StackDriver…  …and introducing the StackDriver Pushgateway]]></title>
    <link href="http://namshi.github.io/blog/2018/07/15/stackdriver-pushgateway/"/>
    <updated>2018-07-15T14:38:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/07/15/stackdriver-pushgateway</id>
    <content type="html"><![CDATA[<p>When running a business, being able to compare metrics to other time period helps to understand which way things are moving and take actions based on that. For example, a sudden decrease in conversion rate is something you would definitely want to monitor, and take action based on.</p>

<!-- more -->


<p>At Namshi, we are saving a bunch of &ldquo;business&rdquo; metrics and storing them in prometheus, with alerts based on conditions over those metrics (for example, <code>if hourly_visits &lt; X: trigger an alert</code>).</p>

<p><img class="center" src="http://namshi.github.io/images/posts/sd-metrics.png"></p>

<p>We have hundreds of applications and cronjobs, periodically sending metrics to prometheus using the pushgateway, which collects metrics and makes them available to prometheus.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/prometheus-metrics.png"></p>

<p>In order to send metrics from our crons etc we can simply curl to the pushgateway:</p>

<figure class='code'><pre><code class='language-bash'>echo &quot;my_metric 99&quot; | curl --data-binary @- http://PROMETHEUS_GATEWAY_ENDPOINT/metrics/job/my_job</code></pre></figure>


<p>The alerts are defined with <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/configmap">k8s configmaps</a>, such as:</p>

<figure class='code'><pre><code class='language-bash'>kind: ConfigMap
apiVersion: v1
metadata:
  namespace: kube-system
  name: foo-alert
  labels:
    role: alert
data:
  foo.rules.yaml: |
    groups:
    - name: foo
      rules:
      - alert: Foo cronjob is not running
        expr: (last_run{job=&quot;foo&quot;} - unix_ts) &gt; 86400
        for: 1h
        labels:
          some: thing
        annotations:
          summary: Foo cronjob not running
          description: Foo cronjob is not running, this will affect xyz, you can fix by doing a,b,c
          alertname: Foo cronjob not running</code></pre></figure>


<p>Everything has been running fine until we started facing some issues related to managing the infrastructure around prometheus, which is not funny: instead of spending time managing prometheus, we could shift our efforts towards our core business.</p>

<p>Google came up with <a href="https://cloud.google.com/monitoring/docs/">StackDriver</a>, which seems to fit our bill: SD has a monitoring service as well as and alerting service which allow us to send metrics and create alerts based on those metrics.
<img class="center" src="http://namshi.github.io/images/posts/sd-notifications.png"></p>

<p>To send business metrics to StackDriver, we would have needed to do the following for every single app in our cluster:</p>

<ul>
<li>mount google credentials</li>
<li>install StackDriver dependencies</li>
<li>structure the metrics as time series as mentioned here and send them back to SD.
For more details, <a href="https://cloud.google.com/monitoring/custom-metrics/creating-metrics">have a look at the documentation</a></li>
</ul>


<p>(if we were running on <a href="https://cloud.google.com/kubernetes-engine/">GKE</a> we could have avoided step #1, as Google auto-mounts credentials on its own instances)</p>

<p>At Namshi we have hundreds of services, and doing that for every service would have been painful: the solution we came up with was to create something similar to the prometheus pushgateway,
where we could just send the metrics to a gateway, and the gateway will then send those metrics back to StackDriver.
We built a &ldquo;StackDriver pushgateway&rdquo;, and the effort that took us to migrate all services to StackDriver was as simple as changing the endpoint of the gateway.</p>

<p>Interested by sending business metrics to StackDriver? Good news, as we open sourced the <a href="https://github.com/namshi/stackdriver-pushgateway">Stackdriver pushgateway</a>!</p>

<p>To start sending business metrics to StackDriver, here are the 3 simple steps:</p>

<ul>
<li>get credentials from google cloud console</li>
<li><a href="https://github.com/namshi/stackdriver-pushgateway/blob/master/index.js#L13">define your project id with an environment variable</a></li>
<li>deploy it and start sending metrics using simple http requests:</li>
</ul>


<figure class='code'><pre><code class='language-bash'>echo &quot;some_metric 99&quot; | curl --data-binary @- http://STACKDRIVER_GATEWAY_ENDPOINT/metrics/label1/value1/label2/value2</code></pre></figure>


<p>Have fun monitoring on StackDriver :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: a CyberSecurity engineer]]></title>
    <link href="http://namshi.github.io/blog/2018/07/04/currently-hiring-a-cybersecurity-engineer/"/>
    <updated>2018-07-04T06:28:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/07/04/currently-hiring-a-cybersecurity-engineer</id>
    <content type="html"><![CDATA[<p>Love penetration testing, DefCon, bug bounty programs and scrapping through lines
of code to find vulnerabilities? Then we might have the right opening for you!</p>

<!-- more -->


<p>Here at Namshi we&rsquo;re committed to continuously improve our security posture, by
either <a href="http://namshi.github.io/blog/2018/05/16/introducing-the-namshi-bug-bounty-program/">collaborating with security researchers across the globe</a> or with in-house expertise.</p>

<p>With this in mind, we would like to hire a security researcher that can help
us from this perspective: we see security as being a topic that will only gain additional
importance as time goes by, and we&rsquo;re committed to dedicating the right amount of time,
and money, to the cause :)</p>

<p>As a <strong>Security Engineer</strong>, you&rsquo;ll be tasked with running internal assessments, ranging
from <em>pentesting</em> our cloud infrastructure to social engineering around the office,
review our security policies and define the best strategy to improve our posture.
In addition to that, you will be actively collaborating with external researchers
through our HackerOne program, which is going to be directly under your responsibility.
On top of this, as the months will go by, you will probably spend time training
both our technical and non-technical staff to raise awareness and make sure we
got the basics covered.</p>

<p>Been into it since Kali was Backtrack? Spend time going through public bounty programs
to hack your way to a reward? Want to take on the responsibility of shaping Namshi&rsquo;s
defense? Then we’re definitely a match!</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application to <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few months back I wrote a small piece about <a href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: sr. backend engineers]]></title>
    <link href="http://namshi.github.io/blog/2018/07/03/currently-hiring-sr-backend-engineers/"/>
    <updated>2018-07-03T08:52:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/07/03/currently-hiring-sr-backend-engineers</id>
    <content type="html"><![CDATA[<p>Love microservices, NodeJS and distributed systems? Then we might have the right
opening for you!</p>

<!-- more -->


<p>Here at Namshi we&rsquo;re constantly trying to renovate our stack by using the best
from the open source ecosystem: from <a href="https://nodejs.org/en/">NodeJS</a> to <a href="https://kubernetes.io/">Kubernetes</a>, our stack bleeds with
interesting tools to work with.</p>

<p>As a Sr. Backend Engineer, you&rsquo;ll be tasked to work on a spectrum of services
ranging from our customer-facing APIs to tools that power our logistics infrastructure.
We are a very pragmatic and experienced team, so from time to time you will see
engineers busy TDDing on a feature, whereas other times we&rsquo;re <em>straight to live</em>.
We pride of being a heterogeneous team that&rsquo;s experienced to know how and when to
abstract.</p>

<p>We run a Service-Oriented architecture with 100+ microservices where JS plays a
huge part: <a href="https://stackshare.io/namshi">our stack is comprised of many different tools</a>
and we&rsquo;re always up to experimenting in light of new, harder challenges.</p>

<p>Some of the things our backend team has been working over the past few months:</p>

<ul>
<li><a href="http://namshi.github.io/blog/2017/05/28/rewriting-the-catalog-api/">rewriting one of our most sensitive APIs</a>, bringing the median response time down to 30ms</li>
<li>moving <a href="http://namshi.github.io/blog/2017/02/06/towards-high-availability-and-beyond/">wonky pieces of our infrastructure</a> towards high-availability</li>
<li>releasing some interesting open-source <a href="https://github.com/namshi/stackdriver-pushgateway">backend bits</a></li>
</ul>


<p>Most of our backend apps are built with NodeJS, although some of the apps
still kick it in Symfony2 or pythonic boots. With a fleet of 100+ microservices, we&rsquo;re
generally very busy trying to innovate as much as possible &mdash; and refactoring when
we need to pay our technical debt back.</p>

<p>Understand the HTTP protocol? Like deploying microservices on kubernetes? Async
programming doesn&rsquo;t scare you? Then we&rsquo;re definitely a match!</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application to <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few months back I wrote a small piece about <a href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing the Namshi Bug Bounty Program]]></title>
    <link href="http://namshi.github.io/blog/2018/05/16/introducing-the-namshi-bug-bounty-program/"/>
    <updated>2018-05-16T08:00:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/05/16/introducing-the-namshi-bug-bounty-program</id>
    <content type="html"><![CDATA[<p>Namshi believes that working with skilled security researchers across the globe
is crucial in identifying weaknesses in any technology &mdash; with that in mind, I
wanted to introduce our (currently private) <em>Bug Bounty Program</em> that&rsquo;s been in
place since a couple years.</p>

<!-- more -->


<h2>A bit of history&hellip;</h2>

<p>5 (long) years ago we responded to our very first vulnerability report,
submitted by a web developer whose better half had been using our services,
who noticed a small glitch in one of our webservices. Since then, we processed quite a
few (and luckily <em>not-so-many</em>) submissions, handing off rewards to researchers who
would submit valid reports.</p>

<p>The process had been quite unstructured until a couple years back, when
<a href="https://www.linkedin.com/in/borishajduk/">Boris</a> joined <a href="https://global-fashion-group.com/">GFG</a>,
at the time our majority stakeholder, and suggested we should try <a href="https://www.hackerone.com/">hackerone</a>
as it had been working well for other companies &mdash; needless to say, this was a
turning point for us, as we finally found a platform that could take care of
coordination with security researchers.</p>

<p>At that point we started phasing out the historical <code>security@namshi.com</code> email
address in favor of inviting researchers to our H1 program, which has definitely
helped us defining better boundaries (especially in terms of timeline, rewards and
scope of the program) between Namshi and the community of researchers out there.</p>

<h2>Our current program</h2>

<p>As mentioned, we run a (private) program on hackerone and, in parallel, process
submissions to <code>security@namshi.com</code> by asking whoever reaches out to us to
create an account on hackerone so that we can then move the conversation from
email to a proper bug bounty platform.</p>

<p>Our program defines a disclosure policy, list of exclusions and a brief legal
appendix to guide you through the process of submitting a vulnerability report
to Namshi. The list of exclusion also contains an associated list of behaviors / actions
that will result in your submission being ineligible for a bounty, such as:</p>

<ul>
<li>making threats</li>
<li>demanding payments / entry into the program in exchange for reports</li>
</ul>


<p>&hellip;and a few additional points. We do believe our program is fair and guarantees
a good balance between what we demand and what we offer, but we&rsquo;re always open
to suggestions, or questions, from your side. Feel free to reach out if
you think we should amend some of the points in our program.</p>

<p>In addition, I wanted to mention that we recognize that the only public information
available on our websites (<a href="https://support.namshi.com/hc/en-us/articles/207782049-Security">our security FAQ</a>),
is by no means exhaustive, and we plan on fixing it in the upcoming months:
that&rsquo;s where the next paragraph kicks in :)</p>

<h2>Future plans</h2>

<p>You might be wondering: &ldquo;why are you telling us about a private bug bounty program
that&rsquo;s been kept private and we don&rsquo;t know how to join? Is today the
lets-share-news-people-couldnt-care-less day?&rdquo;</p>

<p>We&rsquo;re sharing this because we want this to change, and we want to be more open
about some of our processes: <strong>our goal is to be able to make our program public in
the upcoming months</strong>, so that more and more researchers can help us making Namshi
a safer place on the web.</p>

<p>The traditional challenges with having public bug bounty programs are related to
the &ldquo;<em>signal vs noise</em>&rdquo; ratio as well as the fact that companies think the more they
keep in the dark, the less they&rsquo;ll expose &mdash; we don&rsquo;t share the same beliefs, and
are currently making a step to expand our program to more researchers, with the
ultimate goal of making it public. At the same time, our tech department is fairly small so we want
this transition to be as smooth as possible, hence the slow rollout &mdash; consider
this a canary release until everything is well-oiled and we&rsquo;re comfortable enough
with making the program public.</p>

<p>With this in mind, I&rsquo;d like to invite everyone who would like to take a look at
our program to mail us at <code>security@namshi.com</code> and share the email they use on
hackerone, so that we can invite you to the Namshi Bug Bounty program. As I
mentioned, this is a first step towards our program turning public in the upcoming
months.</p>

<p>Considering our goal to be more open and transparent, I would also like to take
a second to disclose some of our stats taken from hackerone:</p>

<ul>
<li>our <strong>minimum bounty is $50</strong></li>
<li>the total number of submissions is 67</li>
<li>we have <strong>resolved 27 reports</strong> (meaning the remaining are to be considered invalid, or part of the exclusions)</li>
<li>our average time to <strong>first response is 1 day</strong> (last 90d)</li>
<li>our average time to <strong>bounty is 3 days</strong> (last 90d)</li>
<li>our <strong>average bounty range is $120 &ndash; $150</strong></li>
<li>our <strong>top bounty range is $450 &ndash; $1000</strong></li>
</ul>


<p>Happy hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open Source UI libraries from our iOS Mobile team]]></title>
    <link href="http://namshi.github.io/blog/2018/04/17/open-source-ui-libraries-from-our-ios-mobile-team/"/>
    <updated>2018-04-17T07:08:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/04/17/open-source-ui-libraries-from-our-ios-mobile-team</id>
    <content type="html"><![CDATA[<p>Recently, the Namshi iOS app went through a UI overhaul which includes a new font, improved UX on a few screens and some attractive animations. Customers loved it, the team enjoyed working on it and, best of all, conversion rate increased.  To achieve this, we relied on a few open source libraries available through Cocoapods.</p>

<p>Some of the available open source UI components are very well written and while working with these, you will get a lot of inspiration. I won’t hesitate to mention <a href="https://github.com/Skyscanner/SkyFloatingLabelTextField/">SkyFloatinglabelTextField</a> from SkyScanner and <a href="https://github.com/xmartlabs/XLPagerTabStrip">XLPagerTabStrip</a> here. Sometimes, the UI requirements are very specific and UI libraries will not support the particular use-case you have. While working on the UI improvement for Namshi iOS app, we faced the same situation where we had to modify an existing library to tweak its looks.</p>

<!-- more -->


<p>So it was a combination of inspiration and custom requirements that resulted in two awesome UI components which we recently published on Cocoapods. Let me Introduce these libraries separately below :</p>

<h1>NMFloatLabelSearchField</h1>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522079824203_CocoaPodsSwift-feature.png" alt="" /> <span style="margin-left: 15px"><a href="http://cocoapods.org">www.cocoapods.org</a></span></p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522078748825_github.png" alt="" />  <span style="margin-left: 15px"><a href="https://github.com/namshi/NMFloatLabelSearchField">https://github.com/namshi/NMFloatLabelSearchField</a></span></p>

<h2>Case Study :</h2>

<p>We had a requirement to implement UITextFields on which hints float up when the user starts to type; the border can also be highlighted based on different delegate callbacks and on validation errors.</p>

<p>We found SkyFloatingLabelTextField which does that perfectly and supports RTL languages as well.  Here comes the challenge: we had a city suggestion field in the form which dynamically displays a suggestion list as user starts to type, and this feature is not supported in SkyFloatLabelTextField. So we started our search again and found one more library, SearchTextField. We went ahead with it and used both of them.</p>

<p>Soon we realized that the UX of the screen is not appealing as five fields (name, country code, city code, phone number and address) are having floating-placeholders but the city field looks like a fish out of water here. We at Namshi are always eager to make the UX smooth and appealing for our customers, so we decided to join the two third-party libraries’ functionality and combine them for our city-search-field.</p>

<h2>Solution:</h2>

<p>In the beginning, we extended the functionality of SearchTextField and added the code from SkyFloatingLabelTextfield to achieve FloatingLabelSearchField functionality. It worked well but we realized that we are not properly getting the textField delegate callbacks (didEndEditing never worked).
We looked into the open issues for SkyFloatingLabelTextField but there was none related to this. Then we looked for the open issues for SearchTextField and — voila! — we found an <a href="https://github.com/apasccon/SearchTextField/issues/36">open issue</a> in the library. We changed our strategy; extended the functionality of SkyFloatingLabelTextfield and added the code for SearchTextField in the our code. We faced few bugs and me managed to fix those  and…..
Yalla, it really worked!
Soon our app was in store with the awesome looking “Add New Address” screen with smooth user experience.</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522081067491_image_preview.png" alt="" /></p>

<h1>NMAnimatedTabbarItem</h1>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522079824203_CocoaPodsSwift-feature.png" alt="" />  <span style="margin-left: 15px"><a href="https://cocoapods.org/pods/NMAnimatedTabBarItem">https://cocoapods.org/pods/NMAnimatedTabBarItem</a></span></p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522078748825_github.png" alt="" /><span style="margin-left: 15px"><a href="https://github.com/namshi/NMAnimatedTabbarItem">https://github.com/namshi/NMAnimatedTabbarItem</a></span></p>

<h2>Case Study :</h2>

<p>The tabbar used in Namshi app was pretty basic, it looked like the tabbar from Apple&rsquo;s built-in apps when iOS 7 was released. We realized that almost all the major apps are incorporating some animations on tab bar so it was the right time to spice up UITabbar used in Namshi app.</p>

<p>We first started with <a href="https://github.com/Ramotion/animated-tab-bar">Ramotion</a> — this library is awesome! After playing with it for few hours, we realized that it has some deal breakers such as missing support  for RTL languages and has a problem putting tab items back into the correct position when you move to a screen which does not have a tabbar and try to come back to a screen which does. We forked the library, tried to solve the issues but gave up as, one after the other, new issues came up.</p>

<h2>Solution:</h2>

<p>We started by digging deep into Ramotion and we got the basic idea how they are animating Tabbar items. We used the same approach and made the whole thing much more simpler.</p>

<p>We created an open class NMAnimatedTabBarItem inherits from NSObject with a public method called animateTabBarItem.</p>

<p>We have to pass 3 arguments to this method, tabBar(UITabBarController.tabBar), tabIndex (Selected tabItemIndex) and finally animationType(NMAnimationtype).</p>

<p>NMAnimationtype could be:</p>

<ul>
<li>Bounce</li>
<li>Rotation</li>
<li>Transition</li>
<li>Frame</li>
</ul>


<p>For Bounce, Rotation and Transition tabbar item image required. For Frame animation we have to pass UIImage Array.</p>

<p><span style="text-align: center; display: block">
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522583517426_ezgif.com-resize.gif" alt="" />
</span></p>

<hr/>


<h1>Some Useful Links for Creating Custom Pods</h1>

<ul>
<li><a href="https://code.tutsplus.com/tutorials/creating-your-first-cocoapod--cms-24332">https://code.tutsplus.com/tutorials/creating-your-first-cocoapod&mdash;cms-24332</a></li>
<li><a href="https://guides.cocoapods.org/making/private-cocoapods.html">https://guides.cocoapods.org/making/private-cocoapods.html</a></li>
<li><a href="https://guides.cocoapods.org/making/specs-and-specs-repo.html">https://guides.cocoapods.org/making/specs-and-specs-repo.html</a></li>
<li><a href="https://medium.com/@shahabejaz/create-and-distribute-private-libraries-with-cocoapods-5b6507b57a03">https://medium.com/@shahabejaz/create-and-distribute-private-libraries-with-cocoapods-5b6507b57a03</a></li>
<li><a href="https://www.raywenderlich.com/99386/create-cocoapod-swift">https://www.raywenderlich.com/99386/create-cocoapod-swift</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Women in Tech @ Namshi: Noor Ali]]></title>
    <link href="http://namshi.github.io/blog/2018/03/25/women-in-tech-at-namshi-noor-ali/"/>
    <updated>2018-03-25T10:50:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/03/25/women-in-tech-at-namshi-noor-ali</id>
    <content type="html"><![CDATA[<p>Here at Namshi we have quite a bit of a <a href="http://namshi.github.io/team">diverse team</a> but, like many companies
out there, struggle with the gender gap in tech.</p>

<p>We, though, would like
to share the story and advices from the women who are part of our team, with the
hope that they&rsquo;ll inspire others to join us, or to simply give computer science, or
programming in general, a go.</p>

<!-- more -->


<p>Without further ado, let me introduce <a href="http://namshi.github.io/team#noor">Noor</a>, who:</p>

<blockquote><p>&hellip;is a telecom engineer with Masters in Computer Science from Karachi, Pakistan. She started her career as an iOS developer, enhancing her skills in Android and then Mac development. She is a diversified team player, a detail oriented resource, and a quick learner. She has keen interest in application development based on smart TV, smart watch, google glass apps, and wearable gadgets. She loves to spend time learning new technologies related to big data and mobile apps development.</p></blockquote>

<p><strong>Can you briefly tell us a bit about yourself?</strong></p>

<p><img class="center" src="http://namshi.github.io/images/noor.jpg" width="200"></p>

<p><em>I am an ordinary omnivert person who is telecommunications engineer by education and software engineer by profession. I am often considered as a backstage performer. I love to write blogs and do voluntarily work whenever I get time.</em></p>

<p><strong>How did you get into programming &amp; computer science?</strong></p>

<p><em>My final year project in Bachelors was on MATLAB which enhanced my programming and research skills, then later got chance to work on android platform. Based on programming concepts, got job as trainee iOS developer and hence the CS journey started. Later decided to continue education in computer science and did Masters in IT with thesis on NLP.</em></p>

<p><strong>What does your typical day at work look like?</strong></p>

<p><em>Like this:</em></p>

<p><img class="center" src="http://namshi.github.io/images/noor_at_work.jpg"></p>

<p><em>Jokes apart, besides working on the assigned tasks in office, I try to learn at least one thing new everyday. I manage my own sheet to track my progress.</em></p>

<p><strong>What is the most challenging project you worked on? The one that made you the proudest?</strong></p>

<p><em>All projects have different challenges and I am proud of every app I&rsquo;ve worked on. The one that made me proudest was my first mac app, LightUp. Because working on mac app was different from mobile apps, there were more challenges there like changing window size, menu controls, etc.</em></p>

<p><strong>What advice would you give to a woman considering a career in the tech industry? What do you wish you had known?</strong></p>

<p><em>Try to think out of the box and work smart, not hard.</em></p>

<p><strong>Thanks Noor &mdash; both for sharing your experience and keeping the Namshi mobile apps under
control! :)</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: a frontend engineer]]></title>
    <link href="http://namshi.github.io/blog/2018/01/07/currently-hiring-a-frontend-engineer/"/>
    <updated>2018-01-07T12:07:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/01/07/currently-hiring-a-frontend-engineer</id>
    <content type="html"><![CDATA[<p>Love React, React Native, the dom and webperf? Then we might have the right
opening for you!</p>

<!-- more -->


<p>It is no news that we&rsquo;ve been banking on the JS ecosystem
for a few years: from rolling out our first angular apps in 2013 to using React
Native in our android app, we&rsquo;ve been very busy trying to push our frontends
as far as possible.</p>

<p>We run a Service-Oriented architecture where JS plays a huge part: most of our
services are either SPAs or small NodeJS-backed APIs, and <strong>JavaScript is king</strong> at
Namshi.</p>

<p>We would like to work with someone who has a very strong background in the language,
who&rsquo;s been battling on the frontend for a few years and is not afraid to dive into
Node, if required.</p>

<p>Some of the things our frontend team has been working over the past few months:</p>

<ul>
<li>integrating React Native on our <a href="https://play.google.com/store/apps/details?id=com.namshi.android">android app</a></li>
<li><a href="http://namshi.github.io/blog/2017/05/02/rebuilding-our-mobile-website/">improving conversion rate on our mobile website by 20%</a></li>
<li>releasing some interesting open-sourced <a href="https://github.com/namshi/slim-slider">frontend</a> <a href="https://github.com/namshi/dollar-dom">bits</a></li>
</ul>


<p>Most of our frontend apps are built with React, although some of the older apps
still kick it in angular boots. With a fleet of 100+ microservices, we&rsquo;re
generally very busy trying to innovate as much as possible.</p>

<p>Understand the inner workings of virtual dom? Think redux is not a replacement
for components&#8217; state? Grasp how HTTP/2 helps frontend developers?
Then we&rsquo;re definitely a match!</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application at <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few weeks back I wrote a small piece about <a href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Spot Instances in Production]]></title>
    <link href="http://namshi.github.io/blog/2017/07/09/running-spot-instances-in-production/"/>
    <updated>2017-07-09T10:12:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/07/09/running-spot-instances-in-production</id>
    <content type="html"><![CDATA[<p>Around this time last year, we decided to try running subset of our customer-facing web traffic on spot instances.<br/>
This decision was solely based to reduce our AWS instance bill. We&rsquo;ve heard of people running workloads on spot instances but most of the workloads are usually long-running jobs where you don&rsquo;t mind if the instance gets terminated at any time. Running customer-facing apps is a completely different challenge where we can&rsquo;t afford any downtime of any sort.</p>

<!-- more -->


<h3>Background</h3>

<p>We are fully running <a href="https://kubernetes.io/">kubernetes</a> in production which makes it exciting for the challenge of how we can actually test chaos engineering in production with our microservices.<br/>
We chose <a href="https://coreos.com/os/docs/latest/booting-on-ecs.html">CoreOS Container Linux</a> as our preferred operating system because of faster bootup time and it does only 2 things for us: docker service (for running containers) and flannel networking (for inter-pod networking).<br/>
We use both launch configuration and autoscaling service to manage our fleet of spot instance.<br/></p>

<p>Some of the questions we asked oursleves on how to setup a robust infrastructure to support any kind of termination of the spot instances</p>

<ol>
<li>How do we gracefully reschedule the pods to other nodes before the spot instance goes down?</li>
<li>How do we handle the surge in price for one availability zone?</li>
<li>How do we handle the surge in price for the whole region?</li>
</ol>


<h3>How do we gracefully reschedule the pods to other nodes before the spot instance goes down?</h3>

<p>Gracefully rescheduling pods initially do seem straightforward until we started noticing some issues with image pulling from our private registry and the docker hosts. This usually happens as a result of spike requests if more than ten (10) images of around 200MB size are being pulled at the same time. There is <a href="https://kubernetes.io/docs/user-guide/kubectl/v1.6/#drain">kubectl drain</a> which works pretty well but not for us because of the issue mentioned earlier.</p>

<p>Luckily, AWS introduced <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html">spot instance termination notice</a> which is a 2-min window to do cleanups before the spot-instance is terminated, we wrote a simple golang binary which watches the instance metadata for the termination notice and does the following within the 2-min grace:</p>

<ul>
<li>Detach the instance from the ELB (if applicable)</li>
<li>Mark the instance as unschedulable</li>
<li>Delete the pods with a sleep in-between of 10secs (This should take care of approximately 20pods, which is a very rare case for us)</li>
</ul>


<p>This binary is managed by a systemd service</p>

<figure class='code'><pre><code class='language-bash'>---
coreos:
  units:
    - name: spot-terminate-cleaner.service
      command: start
      content: |
        [Unit]
        Description=Graceful cleanup of spot instances before termination
        Requires=network-online.target
        After=network-online.target
        ConditionPathExists=/etc/spot

        [Service]
        ExecStart=/opt/bin/nm-tools spot-shutdown
        Restart=always
        RestartSec=10</code></pre></figure>


<h3>How do we handle the surge in price for one availability zone?</h3>

<p>It is advisable to run the spot-instances in at least two availability zones to cope with surge in price in one of the availability zones. If there is a price surge above the bidding price in one zone and the spot instances are terminated, autoscaling group service automatically launches the same number of terminated instances in the zone(s) with bidding price higher than the current spot price. With this, we achieve something close zero-downtime during the re-scaling activity.<br/></p>

<p><img class="center" src="http://namshi.github.io/images/spot-stage-1.png" width="500" title="price surge in one availability zone" ></p>

<br/><br/>


<p>This also poses another challenge when the spot price drops below the bidding price in the previously affected region. What happens is that two instances launched back in <code>eu-west-1b</code> while the same number of instances are terminated to balance the autoscaling desired capacity. In this activity, we are going to lose instances abruptly, but luckily AWS autocaling service has a feature called <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/lifecycle-hooks.html">lifecycle hooks</a>.<br/></p>

<p>To avoid abrupty autoscaling termination, we added a lifecycle hook for <code>autoscaling:EC2_INSTANCE_TERMINATING</code> transition state with the notification target as SQS. This sends an event containing the instance to be terminated to the SQS. We now have a python script (can be converted to a lambda function) which:</p>

<ul>
<li>Consumes the SQS message</li>
<li>Detach the instance from the ELB (if applicable)</li>
<li>Mark the instance as unschedulable</li>
<li>Delete the pods with a sleep in-between of 10secs (This should take care of approximately 20pods, which is a very rare case for us)</li>
<li>Delete the SQS message once the task is completed</li>
</ul>


<p>All the tasks above are completed within 2-min window to match the spot-instance termination notice period.</p>

<h3>How do we handle the surge in price for the whole region?</h3>

<p>We use <a href="https://sensuapp.org/">Sensu</a> as part of our monitoring stack and developed a simple sensu (ruby) check which compares the current spot price from AWS API against our bidding price used in the launch configuration. We do mark the check state as <strong>warning</strong> when the spot price is within the warning and critical threshold for all the zones in the region and the check is only marked as <strong>critical</strong> if the spot price is higher than our critical threshold in all the zones in the region. When the check state is critical, there is an auto-remediation script which switches the launch configuration of the autoscaling group for the spot instances from spot to on-demand (the script clones the current launch configuration, removes the spot price and replaces the launch config in the autoscaling group). With this, we don&rsquo;t end up with no running instances.</p>

<figure class='code'><pre><code class='language-bash'>{
  &quot;checks&quot;: {
    &quot;lc_spot_price_check&quot;: {
      &quot;command&quot;: &quot;/etc/sensu/plugins-custom/check-lc-spot-price.rb -n namshi-spot -r :::aws.region:::&quot;,
      &quot;subscribers&quot;: [ &quot;aws&quot; ],
      &quot;interval&quot;: 60,
      &quot;refresh&quot;: 14400,
      &quot;handlers&quot;: [ &quot;default&quot;, &quot;ses&quot;, &quot;remediator&quot; ],
      &quot;remediation&quot;: {
        &quot;lc_spot_price_check_remediation&quot;: {
          &quot;occurrences&quot;: [1, 2],
          &quot;severities&quot;: [2]
        }
      }
    },
    &quot;lc_spot_price_check_remediation&quot;: {
      &quot;command&quot;: &quot;sudo /usr/bin/salt-call spot_price.update_spot_asg namshi-spot ondemand=True&quot;,
      &quot;subscribers&quot;: [],
      &quot;handlers&quot;: [ &quot;default&quot;, &quot;ses&quot; ],
      &quot;interval&quot;: 10,
      &quot;publish&quot;: false
    }
  }
}
</code></pre></figure>




<br/><br/>


<p>So far, this has been working well for over a year without any major issues and we have been able to save between 35% and 45% on the instance cost since then.<br/>
Hope you can give it a try and feedbacks are appreciated.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[70% faster: rewriting the API that serves most of our traffic]]></title>
    <link href="http://namshi.github.io/blog/2017/05/28/rewriting-the-catalog-api/"/>
    <updated>2017-05-28T18:37:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/05/28/rewriting-the-catalog-api</id>
    <content type="html"><![CDATA[<p>At the beginning of 2017, we decided to revamp our catalog API which is one of the main parts of our infrastructure, as it’s the API that serves 60 to 70% of our overall traffic.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_main.png"></p>

<!-- more -->


<p>The catalog API provides a way to access our product offering. Broadly, it serves three categories of data:</p>

<ul>
<li>static pages (<a href="https://en-ae.namshi.com/women/">https://en-ae.namshi.com/women/</a>)</li>
<li>product details (<a href="https://en-ae.namshi.com/buy-anaya-patchwork-detail-kaftan-for-women-kaftans-263349.html">https://en-ae.namshi.com/buy-anaya-patchwork-detail-kaftan-for-women-kaftans-263349.html</a>)</li>
<li>product listing with search and suggestions (<a href="https://en-ae.namshi.com/women-clothing-arabian_clothing/">https://en-ae.namshi.com/women-clothing-arabian_clothing/</a>)</li>
</ul>


<p>Static pages, which are HTML files prepared by our content team, are stored on the file system. The product details are a set of product-specific information; the bulk of that information is stored in Redis so that we only have to go to the database to fetch stock availability for a particular product (as we want that to be real-time and extremely accurate). Product search and suggestions are powered by Solr, using keys based on product category, brand and so on.</p>

<p>We had two main goals for the rewrite: better performance and more ease of extensibility. In this post, we talk about how we managed to achieve those goals and our overall journey moving the products catalog API from our legacy PHP application to a Node.js microservice.</p>

<h2>Why did we decide to rewrite it?</h2>

<p>Our catalog API was built on top of our initial, chubby <a href="http://symfony.com/blog/going-soa-with-symfony2-a-year-and-a-half-down-the-road">API layer powered by Symfony2</a> — a single repository hosting a few other functionalities of our architecture, like checkouts and customer profiles, all deployed as a single building block.</p>

<p>As the months went by, we decided to shift towards microservices and go for a rewrite because:</p>

<ul>
<li>a new, clean implementation is free from other dependencies, not tied to our shared API layer.</li>
<li>we could move away from PHP: as much as the language and platform have evolved since we started using it (we started with PHP 5.3, the PSR-0…those times!), we feel that other platforms provide a <a href="https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/">“nicer” development experience</a><a href="https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/">.</a></li>
<li>we’re very bullish on <a href="http://www.grpc.io/">gRPC</a> as the next-gen standard for communicating among microservices, and that wasn’t easy to support with our legacy implementation. Furthermore, even though that’s bound to change, you cannot build gRPC servers in PHP as only the client-side part is implemented.</li>
</ul>


<p>We could go on and mention a whole bunch of other reasons but, fundamentally, it all boils down to the fact that we needed to <strong>move away from our shared API layer</strong>. It served its purpose very well, allowing us to do <a href="https://en.wikipedia.org/wiki/Rapid_application_development">RAD</a> with very little overhead, unified deployments and shared dependencies. As the number of services grew larger and larger we decided to shift the complexity from the code (imagine maintaining an app with many responsibilities) to the architecture (imagine maintaining X apps with 1 responsibility): time to extract the beast!</p>

<p><em>(if you are interested in why we didn’t start with microservices to begin with, we’d recommend having a look at</em> <em><em><a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html"><em>Microservices: not a free lunch</em></a> </em>on High Scalability and</em> <a href="https://martinfowler.com/articles/microservice-trade-offs.html"><em>Microservice tradeoffs</em></a> <em>by Martin Fowler)</em></p>

<h2>Why NodeJs?</h2>

<p>We’ve banked on JavaScript for quite some time, as we realized it’s the <em>lingua franca</em> that everyone’s able to speak. Software engineers get comfortable fairly quickly with it, and with ES6 and async/await (which we use through <code>node --harmony-async-await</code>), the language looks less of a weirdo 😃</p>

<p>Another reason to pick it was the fact that NodeJS is quite fast, especially for I/O heavy applications because it naturally handles I/O in a non-blocking manner, giving us a high throughput.</p>

<p>How fast? Well, <strong>fast enough</strong>.</p>

<p>We look at milliseconds, not microseconds, when we want to optimize the performance of our services, so having a platform that lets us efficiently schedule work <a href="https://bytearcher.com/articles/parallel-vs-concurrent/">concurrently</a> is all we need. The fact that we’re running in a “VM” (as opposed to the request-response-death model of traditional PHP deployments) lets us do some performance optimizations with objects we need to re-use across requests — and we will explain those in detail later in this post. Let’s just say that we want a platform that can serve a sizable chunk of our HTTP requests <strong>within 20ms or less</strong>, and NodeJS does it very well.</p>

<p>What we think JS sucks at is that <strong>large codebases tend to become unmaintainable</strong>, so we’ve made it our goal to <strong>never end up with a large JavaScript codebase</strong>. Most of our applications are microservices deployed on Docker containers, and re-writing good chunks of them won’t require more than a few weeks: we believe this leads to manageable JS applications, without needing Typescript, 100% test coverage &amp; the likes.</p>

<p>Our answer to how to grow a JS codebase? <strong>Don’t grow it, split it</strong>!</p>

<h2>Design</h2>

<p><strong>Architecture</strong></p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_architecture.png"></p>

<p>The architecture consists of a cluster of Node.js applications running within docker containers each of which are capped to 1 GB of RAM and 50% of 1 CPU core. We use Kubernetes to handle auto-scaling of our application. We have a Kubernetes configuration that handles automatically scaling our application once the CPU usage reaches 40% of 1 CPU core. We also have a Redis cluster (in <a href="https://aws.amazon.com/elasticache">ElastiCache</a>) alongside a <a href="http://tech.namshi.io/blog/2017/02/06/towards-high-availability-and-beyond/">highly available S</a><a href="http://tech.namshi.io/blog/2017/02/06/towards-high-availability-and-beyond/">olr cluster</a>.</p>

<p>Sidecar is a container running beside each instance of our catalog API, responsible for downloading the static HTML files from Amazon’s S3 when we want to update our static pages. It first downloads them to a shared volume and then notifies the catalog API by creating an update lock file: the application is always checking for the existence of this lock file and, once it finds it, it will clear the internally cached static files.  You can checkout our open source <a href="https://github.com/namshi/s3-sidecar">s3-sidecar</a>.</p>

<h2>The tools we use</h2>

<h3>Memoization</h3>

<p>A lot of our requests generate high number of cache misses, primarily because of small differences between requests, and we used to have a reverse proxy layer, powered by Varnish, that would serve cached results to around 20/25% of the requests. In order to simplify our architecture we decided to remove this layer (all in all, we didn’t have a high hit-rate) and use application level cache (through <a href="https://github.com/medikoo/memoizee">memoizee</a>) extensively, caching data used to service the request rather than caching the response itself.
For example, we preload some data which doesn’t change frequently, then save it in memory and update it at intervals — this reduces the number of times we need to call external systems such as Redis, and speeds up the response time. Worth to note that we also use <code>memoizee</code> to cache our Solr request and, as much as we thought of putting Varnish in front of Solr, we eventually realized we didn’t need such complexity.</p>

<h3>Redis Pooling</h3>

<p>Instead of creating a new connection to Redis every time we need data, we created a connection pool to manage and reuse connection to Redis: the pool will keep a minimum number of open connections, and make sure we don’t exceed the maximum number of connections set in our configuration. This way we can keep less connections open, and scale them up fairly quickly when the app gets hammered by more traffic.</p>

<p>(<em>We used the</em> <a href="https://github.com/coopernurse/node-pool"><em>generic-pool</em></a> <em>module to avoid re-inventing the wheel 😃 )</em></p>

<h3>Redis Client Proxy</h3>

<p>In order to centralize error, timeout and response handling when we interact with Redis, we added a proxy layer on top of the widely used <a href="https://github.com/NodeRedis/node_redis">redis module</a>, so that acquiring a connection, executing an operation and releasing the connection are abstracted away, with a promise-based interface: we released this as an open source <a href="https://github.com/namshi/node-redis-wrapper">redis wrapper</a> that contains both pooling connections and the proxying calls to redis.</p>

<h2>Going live</h2>

<p>You know how live deployment should be? <strong>Boring as hell</strong>, and we’ve embraced this philosophy when rolling out this new API: the adrenaline of clicking the red button and rolling out the service at once is tempting, but the software engineer in you knows that it’s best to go live incrementally, fully prepared, aware of all the risks and ready to yawn as everything goes as expected.</p>

<p>Before going live, we decided to take a dual approach at benchmarking: first we would make sure that responses were “fast enough”, then that they were “scalable enough”.</p>

<h3>Being “fast enough”</h3>

<p>It’s generally easy to think of the operations a piece of code is doing and say “hey, this shouldn’t take more than 5 milliseconds”, and that’s what we exactly did: we simply rolled out to staging fairly early on and started doing some load testing with <a href="https://github.com/tsenart/vegeta">vegeta</a>.</p>

<p>After looking at the results coming from vegeta, we would then analyze them and figure out if they seemed reasonable to us: does <code>GET /some-content</code> involve calling Redis a couple times? Then it shouldn’t take more than 5 milliseconds. Does <code>GET /product1.html</code> need to fetch stock data from a slower DB? Then we should definitely be within 20/30 milliseconds. Is node taking more than 15 milliseconds on a particular route? Then we probably need to look at the way our code is organized, search for unneeded loops, and optimize.</p>

<p>NewRelic was instrumental during this phase, as we were able to see if we were hitting other layers too many times:</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_newrelic.png"></p>

<p>Why is Redis taking 10 milliseconds? Are we hitting it multiple times? Can we batch requests together and instead of sending 3 <code>HGET</code> we simply issue 1 <code>HMGET</code>? Those were the kind of things we were looking at the time. By doing so, we optimized chunks of our code and were ready to take it to the next level.</p>

<blockquote><p><strong>A note on the computational cost of abstractions</strong></p>

<p>Lodash is a very popular JavaScript library that provides generic abstractions to solve various problems. One of them is the “<a href="https://lodash.com/docs/4.17.4#pick">pick</a>” function which is used to pick a property from an object.</p>

<p>It turns out that this convenient abstraction comes at a cost.</p>

<p>Normally getting a property value from an object in JavaScript cost O(1) on the average case, but lodash’s pick’s implementation costs a O(n) on all cases where n is the length of properties within the object; in our case,
we were looping over hundreds of products and the delay in performance was not acceptable, so we opted to lose the abstraction provided by lodash in this regard.</p></blockquote>

<h3>Being “scalable enough”</h3>

<p>Now, we’re no fools (or at least we like to believe so!), so we were sure that doing a bunch of “static” benchmarks with vegeta wouldn’t really tell us how the application would behave in production, where the amount of traffic and the variety of requests are very different.</p>

<p>We started testing the “elasticity” of the app: take down all instances but one and start bombing it with incremental traffic, so we can observe how it reacts to an increase in traffic. We did so with a <a href="https://github.com/odino/quick-load-incremental">silly bash script</a> that would send X requests for a few minutes, give the service a break, then send 2X requests, 3X etc. This showed that the app could easily adapt to different levels of traffic, and we could focus on the next step.</p>

<p>Even though we now realized the app could take on a higher load without suffering too much, our tests were still too unrealistic: we were probing a few, known URLs, whereas live traffic would be spread across many different URLs — products with 1 size, multiple sizes, products with many different related products, categories with very few products, categories with a plethora of products and so on. <strong>Replaying live traffic was a must</strong>.</p>

<p>Luckily, we discovered <a href="https://goreplay.org/">goreplay</a> a couple years back and fell in love with it. It lets you replay TCP traffic from one host to another one, without much overhead (it doesn’t act as a proxy, it just analyzes network packets and replays them, kind of a <a href="https://github.com/buger/goreplay/wiki/Capturing-and-replaying-traffic">tcpdump on steroids</a>). We then scaled up our staging cluster and replayed most of our live traffic to staging, observed the metric and let the replay run for hours and eventually days, until we were comfortable that the new app could sustain the live traffic very well.</p>

<p>We finally decided to deploy the application to production, but did not switch everything to the new API in one go as that could have brought down our entire website in case there were any issues that we hadn’t caught in the previous stages. So we went for the <strong>boring partial deployments</strong> approach: we kept the old app running and we started progressively switching traffic to the new app.</p>

<p>First, we picked the country with the least amount of traffic, then monitored the app, fixed the small bugs that would occur and repeated that same process for each one of the countries we serve until all the traffic was switched to the new app — the whole process took about two weeks.
Yeah, it’s boring.</p>

<h2>Results</h2>

<p>Now comes the time to show what we were able to achieve in terms of performance improvement. In the old application, our average response time was around 82 milliseconds.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_1.png"></p>

<p>In the new application we managed to achieve an average response time of around 27 milliseconds — that is a 67% performance improvement:</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_2.png" title="" ></p>

<p>Since averages can be misleading let’s look at the percentile graph of the new application’s response time data.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_3.png"></p>

<p>What the graph above tells us is that 50% (red line) of our requests are served under 20 milliseconds and 95% (yellow line) of them are served below 100 milliseconds.</p>

<p>Using an histogram we also see the same pattern.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_4.png"></p>

<p>Basically, according to the histogram above, 20% of our requests are served within less than 10 milliseconds, and 53% of them are served within 20 milliseconds.</p>

<p>Now let’s look at the improvements in terms of resources utilization: as indicated in the graph below, our old PHP application used to consume about 25% of 2 CPU cores and 4 GB of memory. We went live with the new application on April 12, hence the considerable drop in resource consumption that you see in the graph.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_5.png"></p>

<p>The new application however as you can see in the graph uses way less resources. The graph below is for one of our host, which serves around 1000 rpm (requests per minute), and uses half a CPU (<a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/">capped by k8s</a>) with a memory limit of 1 GB. You would agree  that’s a huge improvement on the old application!</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_6.png"></p>

<h2>What’s Next?</h2>

<p>We are really happy with what we have achieved so far with the rewrite of the catalog&rsquo;s API. As we move forward, we would like to keep improving it — as we do for all of our codebase — by introducing appropriate tools and technologies. For example we would like to upgrade to node 8 so that we can take advantages of some nice features such as <code>async</code>  and <code>await</code> (without relying on harmony flags). We are also exploring the idea of using gRPC in order to improve how we do distributed systems overall.</p>

<p>If what you read here sounds interesting to you and you would like to build cool stuff with us, <a href="http://tech.namshi.io/blog/2017/03/09/currently-hiring-backend-mobile-developers-dubai/">please come join us</a>.</p>

<p><em>This article has been a joint effort between the backenders that revamped our
catalog API between February and April 2017: <a href="http://tech.namshi.io/team/#Ayham%20Alzoubi">Ayham</a> and <a href="http://tech.namshi.io/team/#Joe%20Jean">Joe</a>.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rebuilding our mobile website: Express & React meet fun & profit]]></title>
    <link href="http://namshi.github.io/blog/2017/05/02/rebuilding-our-mobile-website/"/>
    <updated>2017-05-02T18:37:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/05/02/rebuilding-our-mobile-website</id>
    <content type="html"><![CDATA[<p>Late last year we decided to give our mobile website a new look, coupled with a new “engine” in order to optimize our mobile experience on the web. Most of our users visit Namshi from mobile devices and we wanted to give them better usability, performance and overall smoother experience.</p>

<!-- more -->


<p>When we started approaching the mobile landscape, 4 years back, we decided to fully commit to an SPA that worked well but showed some limitations, namely the inability to perform server-side rendering, which was somewhat critical in terms of search engine optimization and first render: we solved the former by routing bots’ traffic to our desktop website (a traditional server-side app), but the latter proved hard to solve, as the client would have to download our entire app before being able to understand what page and layout it should render. In the meantime, Google decided to roll the “<em>mobile-friendly</em>” badge on their mobile SERPs, which forced us to look for alternatives.</p>

<p>A year and a half down the line, facing mixed results in terms of conversion rate and usability, we decided to review our implementation and build a small isomorphic app that would be able to render both on the client and the server, but this approach had 2 major flaws: first off, we didn’t look at neither our UX nor UI to figure out if there was anything we could do to make the user’s experience better and, second, we over-engineered our stack. Back then React just started garnering attention and, unsure if <em>that</em> would be the way the community would build “frontend” apps 3/5 years later, we decided to write a very small custom-made isomorphic framework that turned way more complicated than we originally thought.</p>

<p>At Namshi, we’re very big on simplicity and &ldquo;<em>back to the basics”</em> but, as you see, that’s also thanks to <strong>lessons we learned the hard way</strong>.</p>

<p>Flash-forward to Q4 2016, we looked at our mobile website and our metrics combined and decided it was time to completely re-think our approach: 2 of our engineers quickly hacked together a prototype within less than a week and, after discussing it with our PM team, we decided it was worth a shot.</p>

<p>The Falafel Project was born. Sounds like a joke but that’s what we actually called it :)</p>

<h2>Fundamental ideas</h2>

<p>The project kicked off by embracing 3 very important ideas:</p>

<ul>
<li>most of Namshi’s  traffic is served through our mobile apps (<a href="https://itunes.apple.com/us/app/namshi-online-fashion-shopping/id840127349?mt=8">iOS</a> + <a href="https://play.google.com/store/apps/details?id=com.namshi.android">Android</a>). We should probably <strong>mimic the app as much as possible</strong><strong>.</strong></li>
<li>The journey of the user is defined by very few, key components: landing pages, product listing pages, product detail pages, cart and checkout. We want to make sure we waste no time presenting these pages to the user, and <strong>server-side rendering</strong> gives that to us</li>
<li>If we want this webapp to look like it’s 2017, client-side interactions are unavoidable: <strong>picking React</strong>, given its rise in the frontend community and the fact that it’s a library, rather than a framework, was a no-brainer</li>
</ul>


<p><img class="center" src="http://namshi.github.io/images/posts/web-mobile-demo.gif" title="" ></p>

<h2>Re-writing the styles</h2>

<p><img class="center" src="http://namshi.github.io/images/posts/css-code.png" title="" ></p>

<p>We trashed the old css and rewrote it from scratch following the <a href="http://getbem.com/">BEM</a> way of doing things, which allowed us to separate styles per page and also have some of them shared between pages.
The total size of the minified styles was 18kb, now it is <strong>10kb:</strong> almost half of our css is gone!</p>

<h2>RTL styles</h2>

<p>It&rsquo;s always painful to handle direction in css, especially considering that things could have been much easier if <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Logical_Properties">logical properties</a> where introduced, but yet we still use the old techniques until we can fully dump rules overriding.</p>

<p>For example:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-css'>/**
 flex-start, flex-end logical properties will change according to the
 direction: rtl : ltr;
**/
.element {
 display: flex;
 align-items: flex-start;
 justify:-content: flex-start;
}
/**
 opposite to: text-align, css-transforms, floats, margins, paddings ..etc
 which we need to override manually.
**/</code></pre></figure>


<p>We kept the arabic styles in separate files, i.e <code>list.scss / list-rtl.scss</code> where the <code>*-rtls.scss</code> will only override rules in the main file.
That worked for us really well and was a substantial increase in code maintainability.</p>

<h2>Enhanced UX leveraging on mobile browsers</h2>

<p>We took a decision to ditch SPAs in favor of lightning-fast server-side rendered pages.</p>

<p>Despite that, we took advantage of a very interesting feature on modern mobile browsers:
if you tap on a link, they kinda fade the newly painted page over it so if there are common visual components you won’t feel the page load.</p>

<p>Strange, right? Have a look:</p>

<div align="center">
<iframe width="276" height="500" src="https://www.youtube.com/embed/WIOe1ID3ocM" frameborder="0" allowfullscreen></iframe>
</div>


<p>So how we can use it for our own good?
We came up with idea of a “<strong>Shadow Product”:</strong>  When a user taps on a product while on the catalog listing page, we delay the tap event for 10ms and we show a fake preview of what the next product page will look like. Simple and dirty, but looks great!</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>on(&apos;click&apos;, &apos;body&apos;, &apos;.is-shadow-product&apos;, e =&gt; {      
 .... code that extracts content from clicked product
 this.setState({ data: data, show: true });      
 setTimeout(function () {        
   window.location.href = href;      
 }, 10);
})</code></pre></figure>


<p>The problem with this approach is that we need to handle the <a href="https://developer.mozilla.org/en-US/docs/Working_with_BFCache">back-forward cache</a> of some browsers:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>// Prevent backforward cache in iOS devices
if(config.get(&apos;deviceOS&apos;) === &apos;iOS&apos;){
  window.addEventListener(&apos;pagehide&apos;, function(e) {
    let shadowProduct = document.querySelector(&apos;.is-transitional&apos;);
    shadowProduct &amp;&amp; shadowProduct.classList.remove(&apos;is-transitional&apos;);
  });
}</code></pre></figure>


<h2>NO jQuery</h2>

<p>Late, but we eventually joined the party! We stripped jQuery off  80% of our pages and we replaced with some vanilla utilities like the following:</p>

<ul>
<li><strong>On</strong> :</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>  export function on(eventType, parent, selector, fn){
    let el = document.querySelector(parent);  
    if(!el || !eventType || !selectorParent || !selector  || !fn ) {   
      return null;
    }

    el.addEventListener(eventType, function(e) {   
     .... logic to target the child on the event bubbling.
   })
  }, false);
</code></pre></figure>


<ul>
<li><strong>Scroll to, Scroll To Top and Scroll To Bottom:</strong></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>function animateScroll() {    
  var step = (dest - parent.scrollTop) /  steps--;    
  parent.scrollTop = parent.scrollTop + step;    
  if(steps === 0 ){      
    frame &amp;&amp;  cancelAnimationFrame &amp;&amp; cancelAnimationFrame(frame);       
    return    
  }     
 frame = requestAnimationFrame &amp;&amp;    
 requestAnimationFrame(animateScroll);   
}</code></pre></figure>


<hr />

<ul>
<li><strong>Image Carousel:</strong></li>
</ul>


<p>We crafted our own slider (<a href="https://medium.com/@MohamedAmin88/slim-slider-yet-another-javascript-slider-2f2069bb72e5">read the full story here</a>):</p>

<p><img class="center" src="http://namshi.github.io/images/posts/slim-slider.gif" title="" ></p>

<h2>Low Fat React: Preact!</h2>

<p>Though we chose SSR, we were not building a static news website. You can imagine how much client side interactions an E-commerce mobile website has. Our previous mobile website was a tailor made isomorphic app, and we had lot of lessons learned from it. Moreover, performance was a key focus area for our new website, hence we kept some design decisions for all the client-side stuff. These includes:</p>

<ul>
<li>Our website should be interactive under 5s.

<ul>
<li>Should have a great rendering performance. Animations and transitions should be ~60FPS.</li>
<li>Total client-side scripts should be less than 100KB ( including any frameworks / library ).</li>
<li>Build re-usable client-side components.</li>
</ul>
</li>
</ul>


<p>By considering all the above, we wanted something lightweight and with good rendering performance.</p>

<p>We initially ruled jQuery out of the list and thought of creating all client-side components in vanilla js, however, we found that managing the UI state was bit hard with that approach. Moreover, we really liked the redux architecture and keeping a single store for managing the whole UI state.</p>

<p>React was the hottest choice for our expectations but, at the same time, we wanted a lightweight library. Then we came across <strong>Preact</strong>, a 3KB React alternative which offered the same API and great performance.</p>

<p>We built most of our components in Preact and re-used them across pages. Although we liked the redux architecture, we didn&rsquo;t really use Redux on our website. Instead, we built a micro-redux which has a global store for managing the whole UI state and is connected to all Preact components. This helped us to manage the UI state in a single store and synchronizing updates in every part of the page.</p>

<h2>Simplifying the DOM states</h2>

<p>Managing state is one of the crucial parts of  &ldquo;react like&rdquo; development, especially state shared between components (Shared State) can be difficult to manage. We have good libraries that achieves this efficiently &mdash; ie. <a href="http://redux.js.org/">Redux</a> and <a href="https://mobx.js.org/">Mobx</a> that we use on some of our SPAs.</p>

<p>In the new mobile website, our approach is a bit different because each page is SSR and we have very less shared state: we try to reduce client-side code to the minimum, to keep things simple and less bloated.</p>

<p>We have one store which is the single source of truth. To keep things simple every component has it own actions as part of the component, and we only focus on resolving all data into the store and the store automatically updates the state of the components. Unlike most redux implementations, where reducers are used to update the current state based on the actions,  every update always produces a “next state“ without reference to the current state.</p>

<h2>Webpack, Code splitting and Preloading techniques</h2>

<p><img class="center" src="http://namshi.github.io/images/posts/chunk-size.png" title="" ></p>

<p><strong>Code splitting: eat only what you need</strong></p>

<p>Code splitting was a crucial part for our website. Traditionally, we used to bundle all our JavaScript assets into one single file, and loaded it in every page. At that time it was a very performance-friendly approach, as the browser gets all the assets with a <strong>single HTTP request</strong>.</p>

<p>With HTTP2, things changed — multiple round-trips are avoided by channelling multiple requests through a single connection. Knowing this, sending a large bundle (which includes code that&rsquo;s not needed in the current page) would negatively impact the page’s performance so we decided to split our code based on the routes ( different pages ).</p>

<p>We chose Webpack2 for bundling and code-splitting. As we said earlier, we generate js bundles ( aka chunks in webpack terminology ) for each page. We used Webpack&rsquo;s <a href="https://webpack.js.org/plugins/commons-chunk-plugin/">CommonsChunkPlugin</a> to generate a vendor bundle and common code shared between the page level bundles. This helped us to keep smallest JavaScript payload for each page. Furthermore, the vendor chunk and common chunk will change less frequently and can be cached by the browser for most requests, enabling faster transitions between pages.</p>

<p><strong>Reduce bundling and nested dependencies</strong></p>

<p>Webpack2 supports <a href="https://webpack.js.org/guides/tree-shaking/">Tree-shaking</a> out of the box, which helped us reduce the bundle size by ~20% by only including the required modules.</p>

<p>For example, we used some lodash utilities in our client-side code. Without Tree-shaking, the whole of lodash would have been imported into our bundles, thus the size would&rsquo;ve been much bigger. Webpack2 will instead generate the bundle only with the code that’s actually used.</p>

<p><strong>Preload, Prefetch</strong></p>

<p>We also took advantage of the latest browser features for attaining better page load speed. These includes the <code>dns-prefetch</code> for prefetching for resolving domain names, <code>link-preload</code> for loading the CSS and JS assets at the same time HTML is parsed. We also used <code>link-prerender</code> in our catalog listing page pagination to make the transition between pagination much faster.</p>

<p>Notice the <strong>Green Line</strong> ( which indicates the first paint ):</p>

<p><strong>Before</strong></p>

<p><img class="center" src="http://namshi.github.io/images/posts/before-preload.png" title="" ></p>

<p><strong>After</strong></p>

<p><img class="center" src="http://namshi.github.io/images/posts/after-preload.png" title="" ></p>

<h2>Goodbye good old image sprites</h2>

<p>Thanks to HTTP/2, making HTTP requests is cheaper than ever: multiplexing reduces the connection overhead as multiple requests can be tunneled through the same connections, and extended header compression (<a href="https://http2.github.io/http2-spec/compression.html">HPACK</a>) makes it so that those requests are lighter than ever.</p>

<p>This doesn’t mean sprites won’t give you any advantage: as always, making 10 HTTP requests instead of 1 is generally heavier, but with HTTP/2 you don’t “feel” it as much. Another argument <em>pro</em> sprites is that by combining images together we end up allowing the compression algorithm (ie. GZIP/DEFLATE) to better optimize the size of the final, combined image.</p>

<p>All in all, though, we eventually decided not to worry about these and live a less complicated life because:</p>

<ul>
<li>We generally bundle all required images into one sprite, whereas each page might just need 2/3 of them: this means that instead of downloading 100% of your images on the first page load we only require 20/30% of them</li>
<li>Maintaining sprites is no fun at all: if there’s a way to eliminate work and be <em>on par</em> with our previous implementation, then we’re definitely going to cut it short</li>
</ul>


<h2>Results</h2>

<p>Numbers, since we went live in mid-February, have been astounding. Even though web traffic is a small chunk of our overall traffic, it’s been way better than we could ever imagine:</p>

<ul>
<li><strong>conversion rate is up ~20%</strong>, meaning that the overall shopping experience is smoother (worth to note that some of the countries we serve have spikes in conversion of +30/70%)</li>
<li><strong>bounce rate is down 15%</strong>, which indicates that our first impression (load time, UI, etc) has definitely improved</li>
<li>the <strong>average time on page is up 50%</strong>, and the <strong>average session duration up 37%</strong>, meaning users enjoy spending time on the site way more than before</li>
<li>the <strong>average document load time &amp; average document interactive time are both down</strong> <strong>54%</strong> (4+ seconds vs 1.9), which means that…   …well, we really screwed it up with the previous app :)</li>
</ul>


<p>Take this numbers with a pinch of salt, as we mentioned in the introduction of this article, we started from a very disadvantageous point — the performance of the old mobile website was quite disappointing — and, at the same time, Namshi grows and optimizes on a daily basis, so better numbers are expected regardless.</p>

<p>Last but not least, one for the server-side freaks.
In this article, we spoke a lot about frontend optimizations and the likes, but I want to share an image to show the performance of our server-side rendering process:</p>

<p><img class="center" src="http://namshi.github.io/images/posts/web-mobile-results.png" title="" ></p>

<p>As you see, our <strong>average response time is around 40ms</strong> — but you shouldn’t  care, as <a href="https://www.dynatrace.com/blog/why-averages-suck-and-percentiles-are-great/">averages make for a terrible KPI</a>.</p>

<p>Percentiles are really what you want to look at:</p>

<ul>
<li>the <strong>median is at around 25ms</strong>, meaning half of our requests are served within that time</li>
<li>the <strong>95th percentile is at around 120ms</strong>, which is still incredibly great, considering that the website fetches the data it displays from an internal API, and that involves an external HTTP call</li>
</ul>


<p>See you next time!</p>

<p><em>This article is a joint effort between the 3 frontend musketeers of Namshi:
<a href="http://tech.namshi.io/team/#Shidhin%20CR">Shidhin</a>, <a href="http://tech.namshi.io/team/#Mohamed%20Amin">Amin</a> and <a href="http://tech.namshi.io/team/#Gabriel%20Izebhigie">Gabriel</a></em>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: backend and mobile engineers]]></title>
    <link href="http://namshi.github.io/blog/2017/03/09/currently-hiring-backend-mobile-developers-dubai/"/>
    <updated>2017-03-09T06:49:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/03/09/currently-hiring-backend-mobile-developers-dubai</id>
    <content type="html"><![CDATA[<p>We&rsquo;re currently looking for some help in a couple areas of our tech team &mdash; why
don&rsquo;t <strong>you</strong> join us?</p>

<!-- more -->


<h2>Mobile</h2>

<p>Getting into the specifics, we&rsquo;ve been working with an external mobile team (3rd party)
that wrote our apps from scratch, setup an efficient testing &amp; CI strategy and a
very solid deployment workflow &mdash; as a matter of fact, we&rsquo;re very proud of our
crash rate on both platforms, with android leading at 0.05%.</p>

<p>We are comfortable with the quality of our apps and the pace of development but,
in order to take them to the next level, it&rsquo;s clear to us that we need our own
team to do that: commitment, communication and going the extra-mile are definitely
different when you&rsquo;re part of the organization.</p>

<p>On the long run the team is going to be comprised of a few engineers and a lead,
so we&rsquo;d initially like to start with:</p>

<ul>
<li>1 <strong>lead mobile developer</strong>, who should ideally have good experience on both platforms</li>
<li>1 <strong>senior iOS developer</strong></li>
<li>1 <strong>senior android developer</strong></li>
</ul>


<p>The <strong>lead mobile engineer</strong> should ideally be a very hands-on, seasoned mobile
engineer with experience leading / forming a team &mdash; he will need to
help building the team, setting the right direction, overseeing development
on both platforms and coordinating with other teams (ie. backend
or product management) on feature development and aligning priorities. We expect
him to spend around 50% of his time on development (this is still a <em>hands-on</em> position),
and the other 50% on the team, teaching practices, reviewing pull requests and so on.</p>

<p>We expect from <strong>senior engineers</strong> to be able to write clean, testable code that&rsquo;s
hard to break &mdash; a few years (4+) of experience are definitely needed (say, you
should have bumped into <code>@autoreleasepool</code> before ;&ndash;)) and you
should be very familiar with different design patterns (Delegate, Facade, etc),
concepts such as mock objects and various tools to support your workflow (ie. CI
pipelines).</p>

<h2>Backend</h2>

<p>We could definitely use some help in our backend team :)</p>

<p>Even though we&rsquo;re not in a rough spot, we would like to be able to expand
our pipeline and be able to add even more seniority to the team: our usual &ldquo;backend problem&rdquo;
is that we have lots of things we&rsquo;d like to work on / experiment with but not a lot
of engineers, thus we eventually end up giving those projects up or delaying them
too much.</p>

<p>The main technologies you would be working with are:</p>

<ul>
<li>NodeJS</li>
<li>MySQL</li>
<li>Redis</li>
<li>Solr</li>
<li>Golang</li>
<li>Symfony2</li>
<li>a bit of frontend with either Angular or React</li>
</ul>


<p>all of these in the context of our microservice-based SOA: we currently employ
50+ service in production, mostly deployed in Docker containers through Google&rsquo;s
<a href="https://kubernetes.io/">Kubernetes</a>.</p>

<p>Here we would keep in consideration candidates for both a <strong>lead</strong> and a
<strong>senior</strong> position: the current team is working well and we haven&rsquo;t felt the
need to hire a lead engineer over the past few months, but we&rsquo;re open to the
idea if we find the right candidate.</p>

<p>Needless to say, both position would be <strong>quite hands-on</strong> :)</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application at <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few weeks back I wrote a small piece about <a href="http://tech.namshi.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Upgrading our search server towards high availability and beyond]]></title>
    <link href="http://namshi.github.io/blog/2017/02/06/towards-high-availability-and-beyond/"/>
    <updated>2017-02-06T12:00:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/02/06/towards-high-availability-and-beyond</id>
    <content type="html"><![CDATA[<p>In this post, we are going to highlight how and why we did a solr upgrade from solr v3 to solr-cloud v6 with no downtime.</p>

<!-- more -->


<p>We have adopted solr v3 as our search server since the beginning because solr has a nice schema and a very responsive search indexer.
The old indexer was running on one solr server and whenever we needed to change the schema or trigger a full import we had to follow these steps:</p>

<ol>
<li>Unload the core<code>[SOLR_URL]/admin/cores?action=UNLOAD&amp;core=[CORE_NAME]</code></li>
<li>Recreate the core with new schema changes, if any: <code>[SOLR_URL]/admin/cores?action=CREATE&amp;name=[CORE_NAME]&amp;config=[solrconfig.xml]&amp;schema=[schema.xml]</code></li>
<li>Delete and then then re-import all documents</li>
<li>Commit the updates <code>[SOLR_URL]/update?commit=true</code> to see it effective</li>
</ol>


<p>The major drawback with this approach is that if the solr machine down it takes time to boot up another machine and re-import all the products again.</p>

<h2>How do we handle our solr updates?</h2>

<h3>Partial imports:</h3>

<p>Happens periodically: get the latest updates from DB and then update/delete only the changed documents in the given time frame.</p>

<h3>Full imports:</h3>

<p>Happens on request or on schema update: clear the indexer completely then insert all available documents.</p>

<p><img src="http://www.employeescreen.com/wp-content/uploads/2015/06/Upgrade-e1434047810231.jpg" alt="time to upgrade" /></p>

<p><a href="http://lucene.apache.org/solr/features.html">Solr has lots of improvements</a> and by using Solr-cloud in case of any solr instance failure we are not screwed.
The new structure is a solr cluster, and contains 3 zookeeper nodes with 2 solr cloud nodes.
<img src="http://namshi.github.io/images/solr-cluster.png" alt="Solr cluster!" /></p>

<h2>How do we handle the solr clients app during transition with confidence and no downtime on live environment?</h2>

<ul>
<li>We built a nodeJS service to handle periodic solr imports. The <a href="https://www.npmjs.com/package/zindex">Zindex library</a> is used to import data from mySQL (backend source) to solr.</li>
<li>We kept the old solr server running side by side with the new solr on live environment.</li>
<li>We made a change in our product catalog API that allowed us to return a response using the new or old solr, by simply using a special parameter. This allowed us to compare results coming from the old and new solr.</li>
<li>Finally, we switched catalog requests to use the new solr one locale at a time till all supported locales were served with the new solr.</li>
</ul>


<h2>During the upgrade we faced some challenges &ndash; we are listing them below and how we dealt with them:</h2>

<h3>How to revert unwanted updates?</h3>

<p>After a full import we tried to run some validations to accept or reject the import, since <a href="https://wiki.apache.org/solr/UpdateXmlMessages#A.22rollback.22">solr supports rollbacks!</a>
But we were disappointed because <a href="https://issues.apache.org/jira/browse/SOLR-4896">solr cloud mode doesn&rsquo;t support rollbacks</a>
We solved this issue by <strong>saving the import in temporary files, running validations on these files, then commit</strong></p>

<h3>How to swap collections?</h3>

<p>Another issue we faced was that during the full imports the product count in our catalog API decreased significantly, then increased slowly till the import finished.
The reason behind this is that we were deleting all products during the full import, then re-adding the products so solr  would show updates as fast as possible.
To solve this issue we were thinking about <a href="https://wiki.apache.org/solr/CoreAdmin#SWAP">swapping</a> but this, again, was not supported in solr cloud
So instead we used collections alias &ndash; every time we need to do a full import we <strong>create a new collection and after the updates and validations are done, we change the alias and delete the old collection</strong>.</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-sh'>## Get the current collection OM-1

curl [SOLR_HOST]/solr/admin/collections?action=LIST

#
#{
#  &quot;responseHeader&quot;: {
#    &quot;status&quot;: 0,
#    &quot;QTime&quot;: 0
#  },
# &quot;collections&quot;: [
#    &quot;OM-1&quot;
#  ]
#}

## Create the new collection OM-2
curl [SOLR_HOST]//solr/admin/collections?Action=CREATE&amp;name:OM-2

## Create the new data file and post it to the new collection
curl -XPOST -d @updates.json [SOLR_HOST]/solr/OM-2/update

##  Override the alias to point to the new collection OM-2
curl [SOLR_HOST]/solr/admin/collections?action=CREATEALIAS&amp;collections=OM-2&amp;name=OM

## Delete the old collection
curl [SOLR_HOST]/solr/admin/collections?action=DELETE&amp;name=OM-1&amp;wt=json</code></pre></figure>


<h3>How to do a full import for all collections without causing high CPU usage?</h3>

<p>In our architecture we have a collection for each country and since all countries share similar documents with small variations, like price, we use one mysql source and fork the backend to import updates for each country <a href="https://www.npmjs.com/package/zindex">(see Zindex)</a>
When we pushed updates for all countries in parallel, the solr CPU usage spiked and in order to solve this, we had to <strong>do the update synchronously with <a href="https://github.com/tj/co">co</a></strong></p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>  return prepareSolr(availableCountries, options).then(() =&gt; {
    return co(function* () {
      for(var i = 0; i &lt; availableCountries.length; i++) {
        var country = availableCountries[i];
        var result = yield importProducts(country, options);
        logger.info(`Solr Import has been finished for country ${country} with result`, result);
      }
    }).then(()=&gt;{
        logger.info(`All solr countries finished!`);
    })</code></pre></figure>


<p><img src="http://namshi.github.io/images/solr-cpu-usage-spike.png" alt="CPU usage went down!" /></p>

<h3>How to maintain solr cluster well?</h3>

<p>Just like most of our services, we <strong><a href="https://www.docker.com/">dockerize it</a></strong>. We have a monitoring script that checks the container status and another one that checks the app status e.g zookeeper replication status and solr ping, if any check fails we get an alert and apply the necessary fix.</p>

<p><img src="http://img.photobucket.com/albums/v418/bawanaal/MissionAccomplished.gif" alt="Mission Accomplished" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Get that job at Namshi]]></title>
    <link href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/"/>
    <updated>2016-12-06T10:54:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi</id>
    <content type="html"><![CDATA[<p>Inspired by <a href="https://hautelook.github.io/jekyll/update/2015/04/01/get-that-job-at-hautelook.html">HauteLook</a> who,
in turn, were inspired by <a href="http://steve-yegge.blogspot.ae/2008/03/get-that-job-at-google.html">Steve Yegge</a>,
I decided to write a small article that briefly describes what we&rsquo;re looking for
when interviewing potential candidates.</p>

<!-- more -->


<h2>The process</h2>

<p>Our recruitment process tends to be quite lean (with a few exceptions :)):</p>

<ul>
<li>a first, introductory chat with me to get to know each other (<em>45m</em>)</li>
<li>a chat with someone from our HR department, so that the candidate gets a solid overview on our company, the culture, benefits and so on. This is also very helpful for people who are relocating, as it&rsquo;s the best time to ask anything about working in Dubai and so on (<em>1h</em>)</li>
<li>a more technical interview with someone from our <a href="http://namshi.github.io/team">tech team</a> (usually 2 of our senior engineers) (<em>1/2h</em>)</li>
</ul>


<p>Additionally, depending on the candidate and the position, there <strong>might</strong> be a
few additional steps required:</p>

<ul>
<li>coding challenge (<em>no deadlines, should take up to 2 hours of your time</em>)</li>
<li>additional technical screening with me (<em>1h</em>)</li>
<li>chat with one of our managing directors (<em>45m</em>)</li>
</ul>


<p>So you can generally assume that, after 3 positive interviews (&frac34; hours in total), you
could theoretically receive an offer letter.</p>

<p>Expect the whole process to take around 3 weeks.</p>

<h2>Backend</h2>

<p>You should be familiar with minimalist frameworks like Express or Silex, as that&rsquo;s
how we build 99% of our services nowadays. We&rsquo;re not big on any particular language,
but if you worked with Node that&rsquo;s definitely a plus, as well as understanding
async programming.</p>

<p>Being familiar with a shell is kind of a must, as we want people who can poke
around with Linux and are aware of the potential of the &ldquo;<em>do one thing and do it well</em>&rdquo;
philosophy.</p>

<p>The HTTP protocol (both 1.1 and 2) is another must as that&rsquo;s what we speak each
and every day &mdash; you will be mainly tasked to write applications that talk to
other services through HTTP. Knowing what changes with HTTP/2 and why that&rsquo;s
great shows the kind of awareness we&rsquo;re looking for.</p>

<p>We&rsquo;re not big on algorithms and data structures but that doesn&rsquo;t mean you
shouldn&rsquo;t be able to understand them &mdash; having some basic knowledge of Big O
is always appreciated, as well as understanding how to pick a data structure in
order to make the most out of it.</p>

<p>We use both relational and non-relational databases, and you should be
comfortable with a few names here (mostly MySQL and Redis). On MySQL, questions
about race conditions, locking and <code>ALTER TABLE</code> might come up.</p>

<h2>Frontend</h2>

<p>This position is all about JS &mdash; forget CSS, forget HTML: 99% of this position
will mean JavaScript.</p>

<p>Callbacks? Promises? async / await? Breakfast for you :)</p>

<p>You should be familiar with technologies like Angular 1 and React, and how they
work behind the curtain. We could ask you to write a simpler, smaller version of
redux so you&rsquo;d better understand how these libraries work.
For example, knowing that virtual DOM makes things faster won&rsquo;t cut it &mdash; why,
how and thanks to what data structure will.</p>

<p>We also have a keen eye on performance, and you should too: understanding what
changes HTTP/2 brings to frontend engineering is a must, as well as knowing basic
rules for performance optimization (<code>webpack -p</code> anyone?). We aren&rsquo;t super-fussy
about the more advanced stuff, but if you mention tree-shaking and friends we
won&rsquo;t mind :)</p>

<p>You should be familiar with methodologies such as BEM as you will be required to
discuss what&rsquo;s the best approach to structure our styles for the long run.
We also like to sometimes use CSS animations, so knowing how to make them perform
better, especially for mobile browsers, is highly appreciated.</p>

<h2>Mobile</h2>

<p>As a Mobile Engineer, we expect that you have full proficiency in developing apps
for Android and/or iOS i.e. from creating a new project in
Xcode / Android studio to publishing of app in Google Play and App Store.</p>

<p>We expect that you have  good knowledge about Java (Android)
or Objective C / Swift (iOS). If you know all of these
languages, most likely you are the rockstar we want to hire :)
We recently  introduced Kotlin and React-Native in our apps:
if you have hands-on experience on these it&rsquo;s surely a bonus!</p>

<p>And last but not the least: the Namshi apps are known for their blazing fast
responsive UI, stability and the features that every online shopper
wish to have. To take it to the next level, we use lot of CI tools,
automated builds, Build Optimization for stores, Automatic Distribution to testers.
Analytics, Crash Reporting etc etc. We expect that you are familiar
with the tools and techniques to support our workflow.</p>

<h2>SRE</h2>

<p>You should be very familiar with AWS or similar providers ie. Google Cloud, and
have some sort of experience with containers and orchestrators &mdash;
we use Kubernetes but if you worked with Mesos / Swarm we won&rsquo;t really mind.
A good answer to &ldquo;<em>Why would you want to use an init system inside a container?</em>&rdquo;
will definitely speed up the hiring process :)</p>

<p>Be big on Linux, as we expect you to be a ninja there &mdash; utilities
like <code>awk</code>, <code>sed</code> and so on should be music to your ears.</p>

<p>You should be familiar with one scripting language (make it python, ruby, php, bash)
and be open to jump into code, as you might be required to provide bugfixes on
some of our services, or implement system-related features. In general, the more
you can code the happier everyone is!</p>

<p>A keen eye on security is a big plus &mdash; we&rsquo;re a small team and we need brilliant
people who are going to take into account the problems that might happen when
using (or <strong>not using</strong>) a particular technology, pattern or methodology.</p>

<p>We are also big fans of automation and, in some sense, immutable infrastructures.
Know the basics.</p>

<h2>And we also generally look for&hellip;</h2>

<ul>
<li>automated testing is king here: despite the fact that we don&rsquo;t try to cover
100% of the use-cases, we rely on automated tests a lot. Knowing how to write
them, and what methodologies to use to make tests more maintainable is a must.</li>
<li>it would be great to see some of your code &mdash; github is a fan-favorite here :)</li>
<li>people who like <a href="https://en.wikipedia.org/wiki/Shawarma">shawarma</a></li>
</ul>


<p>What are you waiting for? Drop everything and <del>order some shawarma</del> <a href="http://namshi.github.io/join-us/">apply now</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Browser geolocation: the good, the bad and the ugly]]></title>
    <link href="http://namshi.github.io/blog/2016/11/13/browser-geolocation-the-good-the-bad-and-the-ugly/"/>
    <updated>2016-11-13T18:37:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/11/13/browser-geolocation-the-good-the-bad-and-the-ugly</id>
    <content type="html"><![CDATA[<p>We&rsquo;re a little late to the party &mdash; but we&rsquo;re here, amongst those who are
playing around with the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Geolocation/Using_geolocation">geolocation API</a>
provided by browsers.</p>

<p>Without further ado, let me get straight to our feedback on one the nicest web
APIs that have been standardized in recent times.</p>

<!-- more -->


<h2>Background</h2>

<p>We&rsquo;ve always been looking for ways to ease our checkout workflow, as a simpler
process usually means happier customers, and the ability to automagically
detect the device&rsquo;s location lets us take away from our customers the burden
of having to manually fill forms:</p>

<div align="center">
  <video src="http://namshi.github.io/videos/geolocation.webm" controls autoplay loop></video>
</div>


<p>Now that you&rsquo;ve seen it in action let&rsquo;s dig a little bit on what we found out
while implementing this little thing of beauty.</p>

<h2>The good</h2>

<p>First off, let me start by saying that, luckily, browser support is
<a href="http://caniuse.com/#feat=geolocation">widespread</a>, as the only major browser
that is currently lacking support is Opera Mini (not a biggie).</p>

<p>Detecting the user&rsquo;s location is also quite simple:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>var opts = {
  enableHighAccuracy: true,
  maximumAge        : 1000,
  timeout           : 1000
};

function onSuccess(position) {
  console.log(position.coords.latitude, position.coords.longitude)
}

function onError(err) {
  console.log(err)
}

navigator.geolocation.getCurrentPosition(onSuccess, onError, opts);</code></pre></figure>


<p>If this is the first time you&rsquo;re trying to access the device&rsquo;s position the
browser will show a popup to inform the user the website&rsquo;s trying to access the
device&rsquo;s location, so that he or she can accept or decline. The rest is history :)</p>

<p><strong>Takeaway</strong>: this is going to sound like a typical 80/20 story &mdash; it takes no
time to get most done, and a proportially long time to sort the wonky details
out. Regardless, the experience has been pretty positive.</p>

<h2>The bad</h2>

<p>Detecting the device&rsquo;s location turns out pretty handy on desktop devices, as
you can safely assume they won&rsquo;t move around :) Phones and tablets, on the
other hand, will probably be used around so there&rsquo;s a good chance that the
customer might move away / be away from the destination.</p>

<p>The problem is that on desktop you don&rsquo;t really get a very accurate position as
the geolocation service the browser uses won&rsquo;t have any GPS triangulation
available, so you&rsquo;re left with heuristics based on <a href="http://stackoverflow.com/questions/1668304/how-does-google-calculate-my-location-on-a-desktop">IP address mapping and previous
information about nearby networks</a>.</p>

<p><strong>Takeaway</strong>: we went mobile-first and decided to ignore desktop devices for now
(coming soon!).</p>

<p>In addition, error callbacks aren&rsquo;t as accurate as they are supposed to be: on
android, for example, if the user doesn&rsquo;t have the GPS enabled, you might get a
very cryptic error such as &ldquo;<em>User denied geolocation</em>&rdquo; &mdash; which isn&rsquo;t really
what&rsquo;s happening.</p>

<p><strong>Takeway</strong>: don&rsquo;t really rely on the error callbacks to distinguish between
errors, as they&rsquo;re not 100% reliable across all platforms. Consider any error as
a general failure, indicating that something might have gone wrong:</p>

<ul>
<li>the user didn&rsquo;t accept the geolocation request</li>
<li>the geolocation request failed for some reason</li>
<li>the GPS wasn&rsquo;t turned on</li>
<li>apocalypse just happened :)</li>
</ul>


<p>Last but not least, we were very surprised that geolocation depended on the GPS
being manually turned on, at least on Android. I don&rsquo;t know how
many android users go around with their GPS turned on but I bet it&rsquo;s a pretty
small percentage considering how it affects battery usage. We thought the
browser could temporarily turn the GPS on on its own, but that isn&rsquo;t the case. On
iOS, for some reason, it seems the percentage of users having <em>location services</em>
enabled is quite higher, thus the impact isn&rsquo;t as high.</p>

<p><strong>Takeaway</strong>: be prepared to help users figure out what&rsquo;s wrong &mdash; give them
clear instructions on what steps are required to successfully geolocate them:</p>

<ul>
<li>location services / GPS must be on</li>
<li>internet access (well&hellip;)</li>
<li>accept the geolocation request</li>
</ul>


<h2>The ugly</h2>

<p>Oh boy, we didn&rsquo;t see this coming.</p>

<p>Follow me on this simple workflow on an android phone:</p>

<ul>
<li>trigger a geolocation request, but with the GPS off</li>
<li>request fails for obvious reasons</li>
<li>enable GPS</li>
<li>trigger a new geolocation request</li>
</ul>


<p>What in the world would you expect to happen?</p>

<p>Surprise, it doesn&rsquo;t work. And guess what, if you refresh the page an trigger
the request again everything&rsquo;s good &mdash; so somehow chrome isn&rsquo;t really able to
&ldquo;recover&rdquo; from a failed request until the page is refreshed. Go figure.</p>

<p>Of course, triggering a full page reload on our checkout is out of question, as
that distracts the user away and delays the checkout process, so we looked around
for alternative solutions and thought of giving iframes a try &mdash; surprisingly,
it worked. Go figure.</p>

<p>The idea is very simple &mdash; once the user clicks on the &ldquo;<em>Detect my location</em>&rdquo;
button we load an invisible iframe that triggers the geolocation request:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>getCurrentPosition = function(){
  return new Promise((resolve, reject) =&gt; {
    var ifr = document.createElement(&apos;iframe&apos;);
    ifr.style.opacity = &apos;0&apos;;
    ifr.style.pointerEvents = &apos;none&apos;;
    ifr.src = window.location.origin + &apos;/geo.html&apos;;

    document.body.appendChild(ifr);

    ifr.contentWindow.addEventListener(&apos;message&apos;, function(message){
      message = JSON.parse(message.data);
      document.body.removeChild(ifr);

      if(message.type === &apos;success&apos;){
        resolve(message.data);
      } else {
        reject(message.data);
      }
    });
  ]})
};</code></pre></figure>


<p>(the above code got trimmed for the sake of brevity)</p>

<p>As you might have figured, we listen for a message from the iframe, which is
responsible for getting the users&#8217; location and sending it to us:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-html'>&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;title&gt;Geolocation&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;script type=&quot;text/javascript&quot;&gt;
    var triggerGeolocationRequest = function(){
      var options = {
        enableHighAccuracy: true,
        timeout: 1000,
        maximumAge: 1000
      };

      var result;

      window.navigator.geolocation.getCurrentPosition(function(position){
        var result = {
          type: &apos;success&apos;,
          data: {lat: position.coords.latitude, lng: position.coords.longitude}
        };

        window.postMessage(JSON.stringify(result), window.location.origin);
      }, null, options)
    };

    window.addEventListener(&apos;load&apos;, triggerGeolocationRequest);
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre></figure>


<p>(the above code got trimmed for the sake of brevity)</p>

<p>And that does the job: the browser sees the iframe as a brand new page, thus
is able to overcome this wonky issue. Again, go figure.</p>

<p><strong>Takeaway</strong>: iframes, rescuing lazy web developers since 1997.</p>

<h2>All in all&hellip;</h2>

<p>Our feedback is generally positive, as customers have started to use it from day
1 at a good rate (~10% of our mobile checkouts is &ldquo;geolocated&rdquo;). There are a few
quirks here and there but if you survived IE6 then this is really going to feel
like a piece of cake.</p>

<p>A big &ldquo;thanks&rdquo; goes to my partners in crime <a href="http://namshi.github.io/team/#Mohamed%20Amin">Mohamed</a>, <a href="http://namshi.github.io/team/#Gabriel%20Izebhigie">Gabriel</a>, <a href="http://namshi.github.io/team/#Shidhin%20CR">Shidhin</a>, <a href="http://namshi.github.io/team/#Razan%20Bilwani">Razan</a> and
<a href="http://namshi.github.io/team/#Yomna%20Sabry">Yomna</a>, the real masterminds behind this new feature :)</p>

<p>Au revoir!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Welcome Gabriel!]]></title>
    <link href="http://namshi.github.io/blog/2016/10/31/welcome-gabriel/"/>
    <updated>2016-10-31T12:32:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/10/31/welcome-gabriel</id>
    <content type="html"><![CDATA[<p>Fresh new vibes in the tech team as we have a new joiner who likes to hack with
JavaScript on the browser!</p>

<!-- more -->


<p><img class="left" src="http://namshi.github.io/images/gabriel.jpg" width="200"></p>

<p>Gabriel is a Frontend Engineer, who holds a B.Sc in Engineering from University
of Ibadan Nigeria.</p>

<p>He loves to build products that are functional, beautiful and easy to use.
His main focus is Frontend development (a lot of Javascript, HTML, CSS, Sass…)
and some UX to go with it (on the server NodeJS and basic PHP).</p>

<p>He loves challenging myself to do more and push beyond the limits.
His best quote is “<em>if you do it right, it would last forever – Massimo Vignelli</em>”</p>

<p>Welcome amongst the Namshees!</p>
]]></content>
  </entry>
  
</feed>
