<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tech @ Namshi.com]]></title>
  <link href="http://namshi.github.io/atom.xml" rel="self"/>
  <link href="http://namshi.github.io/"/>
  <updated>2018-07-15T10:41:49+00:00</updated>
  <id>http://namshi.github.io/</id>
  <author>
    <name><![CDATA[Namshi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Moving from Prometheus to StackDriver…  …and introducing the StackDriver Pushgateway]]></title>
    <link href="http://namshi.github.io/blog/2018/07/15/stackdriver-pushgateway/"/>
    <updated>2018-07-15T14:38:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/07/15/stackdriver-pushgateway</id>
    <content type="html"><![CDATA[<p>When running a business, being able to compare metrics to other time period helps to understand which way things are moving and take actions based on that. For example, a sudden decrease in conversion rate is something you would definitely want to monitor, and take action based on.</p>

<!-- more -->


<p>At Namshi, we are saving a bunch of &ldquo;business&rdquo; metrics and storing them in prometheus, with alerts based on conditions over those metrics (for example, <code>if hourly_visits &lt; X: trigger an alert</code>).</p>

<p><img class="center" src="http://namshi.github.io/images/posts/sd-metrics.png"></p>

<p>We have hundreds of applications and cronjobs, periodically sending metrics to prometheus using the pushgateway, which collects metrics and makes them available to prometheus.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/prometheus-metrics.png"></p>

<p>In order to send metrics from our crons etc we can simply curl to the pushgateway:</p>

<figure class='code'><pre><code class='language-bash'>echo &quot;my_metric 99&quot; | curl --data-binary @- http://PROMETHEUS_GATEWAY_ENDPOINT/metrics/job/my_job</code></pre></figure>


<p>The alerts are defined with <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/configmap">k8s configmaps</a>, such as:</p>

<figure class='code'><pre><code class='language-bash'>kind: ConfigMap
apiVersion: v1
metadata:
  namespace: kube-system
  name: foo-alert
  labels:
    role: alert
data:
  foo.rules.yaml: |
    groups:
    - name: foo
      rules:
      - alert: Foo cronjob is not running
        expr: (last_run{job=&quot;foo&quot;} - unix_ts) &gt; 86400
        for: 1h
        labels:
          some: thing
        annotations:
          summary: Foo cronjob not running
          description: Foo cronjob is not running, this will affect xyz, you can fix by doing a,b,c
          alertname: Foo cronjob not running</code></pre></figure>


<p>Everything has been running fine until we started facing some issues related to managing the infrastructure around prometheus, which is not funny: instead of spending time managing prometheus, we could shift our efforts towards our core business.</p>

<p>Google came up with <a href="https://cloud.google.com/monitoring/docs/">StackDriver</a>, which seems to fit our bill: SD has a monitoring service as well as and alerting service which allow us to send metrics and create alerts based on those metrics.
<img class="center" src="http://namshi.github.io/images/posts/sd-notifications.png"></p>

<p>To send business metrics to StackDriver, we would have needed to do the following for every single app in our cluster:</p>

<ul>
<li>mount google credentials</li>
<li>install StackDriver dependencies</li>
<li>structure the metrics as time series as mentioned here and send them back to SD.
For more details, <a href="https://cloud.google.com/monitoring/custom-metrics/creating-metrics">have a look at the documentation</a></li>
</ul>


<p>(if we were running on <a href="https://cloud.google.com/kubernetes-engine/">GKE</a> we could have avoided step #1, as Google auto-mounts credentials on its own instances)</p>

<p>At Namshi we have hundreds of services, and doing that for every service would have been painful: the solution we came up with was to create something similar to the prometheus pushgateway,
where we could just send the metrics to a gateway, and the gateway will then send those metrics back to StackDriver.
We built a &ldquo;StackDriver pushgateway&rdquo;, and the effort that took us to migrate all services to StackDriver was as simple as changing the endpoint of the gateway.</p>

<p>Interested by sending business metrics to StackDriver? Good news, as we open sourced the <a href="https://github.com/namshi/stackdriver-pushgateway">Stackdriver pushgateway</a>!</p>

<p>To start sending business metrics to StackDriver, here are the 3 simple steps:</p>

<ul>
<li>get credentials from google cloud console</li>
<li><a href="https://github.com/namshi/stackdriver-pushgateway/blob/master/index.js#L13">define your project id with an environment variable</a></li>
<li>deploy it and start sending metrics using simple http requests:</li>
</ul>


<figure class='code'><pre><code class='language-bash'>echo &quot;some_metric 99&quot; | curl --data-binary @- http://STACKDRIVER_GATEWAY_ENDPOINT/metrics/label1/value1/label2/value2</code></pre></figure>


<p>Have fun monitoring on StackDriver :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: a CyberSecurity engineer]]></title>
    <link href="http://namshi.github.io/blog/2018/07/04/currently-hiring-a-cybersecurity-engineer/"/>
    <updated>2018-07-04T06:28:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/07/04/currently-hiring-a-cybersecurity-engineer</id>
    <content type="html"><![CDATA[<p>Love penetration testing, DefCon, bug bounty programs and scrapping through lines
of code to find vulnerabilities? Then we might have the right opening for you!</p>

<!-- more -->


<p>Here at Namshi we&rsquo;re committed to continuously improve our security posture, by
either <a href="http://namshi.github.io/blog/2018/05/16/introducing-the-namshi-bug-bounty-program/">collaborating with security researchers across the globe</a> or with in-house expertise.</p>

<p>With this in mind, we would like to hire a security researcher that can help
us from this perspective: we see security as being a topic that will only gain additional
importance as time goes by, and we&rsquo;re committed to dedicating the right amount of time,
and money, to the cause :)</p>

<p>As a <strong>Security Engineer</strong>, you&rsquo;ll be tasked with running internal assessments, ranging
from <em>pentesting</em> our cloud infrastructure to social engineering around the office,
review our security policies and define the best strategy to improve our posture.
In addition to that, you will be actively collaborating with external researchers
through our HackerOne program, which is going to be directly under your responsibility.
On top of this, as the months will go by, you will probably spend time training
both our technical and non-technical staff to raise awareness and make sure we
got the basics covered.</p>

<p>Been into it since Kali was Backtrack? Spend time going through public bounty programs
to hack your way to a reward? Want to take on the responsibility of shaping Namshi&rsquo;s
defense? Then we’re definitely a match!</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application to <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few months back I wrote a small piece about <a href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: sr. backend engineers]]></title>
    <link href="http://namshi.github.io/blog/2018/07/03/currently-hiring-sr-backend-engineers/"/>
    <updated>2018-07-03T08:52:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/07/03/currently-hiring-sr-backend-engineers</id>
    <content type="html"><![CDATA[<p>Love microservices, NodeJS and distributed systems? Then we might have the right
opening for you!</p>

<!-- more -->


<p>Here at Namshi we&rsquo;re constantly trying to renovate our stack by using the best
from the open source ecosystem: from <a href="https://nodejs.org/en/">NodeJS</a> to <a href="https://kubernetes.io/">Kubernetes</a>, our stack bleeds with
interesting tools to work with.</p>

<p>As a Sr. Backend Engineer, you&rsquo;ll be tasked to work on a spectrum of services
ranging from our customer-facing APIs to tools that power our logistics infrastructure.
We are a very pragmatic and experienced team, so from time to time you will see
engineers busy TDDing on a feature, whereas other times we&rsquo;re <em>straight to live</em>.
We pride of being a heterogeneous team that&rsquo;s experienced to know how and when to
abstract.</p>

<p>We run a Service-Oriented architecture with 100+ microservices where JS plays a
huge part: <a href="https://stackshare.io/namshi">our stack is comprised of many different tools</a>
and we&rsquo;re always up to experimenting in light of new, harder challenges.</p>

<p>Some of the things our backend team has been working over the past few months:</p>

<ul>
<li><a href="http://namshi.github.io/blog/2017/05/28/rewriting-the-catalog-api/">rewriting one of our most sensitive APIs</a>, bringing the median response time down to 30ms</li>
<li>moving <a href="http://namshi.github.io/blog/2017/02/06/towards-high-availability-and-beyond/">wonky pieces of our infrastructure</a> towards high-availability</li>
<li>releasing some interesting open-source <a href="https://github.com/namshi/stackdriver-pushgateway">backend bits</a></li>
</ul>


<p>Most of our backend apps are built with NodeJS, although some of the apps
still kick it in Symfony2 or pythonic boots. With a fleet of 100+ microservices, we&rsquo;re
generally very busy trying to innovate as much as possible &mdash; and refactoring when
we need to pay our technical debt back.</p>

<p>Understand the HTTP protocol? Like deploying microservices on kubernetes? Async
programming doesn&rsquo;t scare you? Then we&rsquo;re definitely a match!</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application to <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few months back I wrote a small piece about <a href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing the Namshi Bug Bounty Program]]></title>
    <link href="http://namshi.github.io/blog/2018/05/16/introducing-the-namshi-bug-bounty-program/"/>
    <updated>2018-05-16T08:00:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/05/16/introducing-the-namshi-bug-bounty-program</id>
    <content type="html"><![CDATA[<p>Namshi believes that working with skilled security researchers across the globe
is crucial in identifying weaknesses in any technology &mdash; with that in mind, I
wanted to introduce our (currently private) <em>Bug Bounty Program</em> that&rsquo;s been in
place since a couple years.</p>

<!-- more -->


<h2>A bit of history&hellip;</h2>

<p>5 (long) years ago we responded to our very first vulnerability report,
submitted by a web developer whose better half had been using our services,
who noticed a small glitch in one of our webservices. Since then, we processed quite a
few (and luckily <em>not-so-many</em>) submissions, handing off rewards to researchers who
would submit valid reports.</p>

<p>The process had been quite unstructured until a couple years back, when
<a href="https://www.linkedin.com/in/borishajduk/">Boris</a> joined <a href="https://global-fashion-group.com/">GFG</a>,
at the time our majority stakeholder, and suggested we should try <a href="https://www.hackerone.com/">hackerone</a>
as it had been working well for other companies &mdash; needless to say, this was a
turning point for us, as we finally found a platform that could take care of
coordination with security researchers.</p>

<p>At that point we started phasing out the historical <code>security@namshi.com</code> email
address in favor of inviting researchers to our H1 program, which has definitely
helped us defining better boundaries (especially in terms of timeline, rewards and
scope of the program) between Namshi and the community of researchers out there.</p>

<h2>Our current program</h2>

<p>As mentioned, we run a (private) program on hackerone and, in parallel, process
submissions to <code>security@namshi.com</code> by asking whoever reaches out to us to
create an account on hackerone so that we can then move the conversation from
email to a proper bug bounty platform.</p>

<p>Our program defines a disclosure policy, list of exclusions and a brief legal
appendix to guide you through the process of submitting a vulnerability report
to Namshi. The list of exclusion also contains an associated list of behaviors / actions
that will result in your submission being ineligible for a bounty, such as:</p>

<ul>
<li>making threats</li>
<li>demanding payments / entry into the program in exchange for reports</li>
</ul>


<p>&hellip;and a few additional points. We do believe our program is fair and guarantees
a good balance between what we demand and what we offer, but we&rsquo;re always open
to suggestions, or questions, from your side. Feel free to reach out if
you think we should amend some of the points in our program.</p>

<p>In addition, I wanted to mention that we recognize that the only public information
available on our websites (<a href="https://support.namshi.com/hc/en-us/articles/207782049-Security">our security FAQ</a>),
is by no means exhaustive, and we plan on fixing it in the upcoming months:
that&rsquo;s where the next paragraph kicks in :)</p>

<h2>Future plans</h2>

<p>You might be wondering: &ldquo;why are you telling us about a private bug bounty program
that&rsquo;s been kept private and we don&rsquo;t know how to join? Is today the
lets-share-news-people-couldnt-care-less day?&rdquo;</p>

<p>We&rsquo;re sharing this because we want this to change, and we want to be more open
about some of our processes: <strong>our goal is to be able to make our program public in
the upcoming months</strong>, so that more and more researchers can help us making Namshi
a safer place on the web.</p>

<p>The traditional challenges with having public bug bounty programs are related to
the &ldquo;<em>signal vs noise</em>&rdquo; ratio as well as the fact that companies think the more they
keep in the dark, the less they&rsquo;ll expose &mdash; we don&rsquo;t share the same beliefs, and
are currently making a step to expand our program to more researchers, with the
ultimate goal of making it public. At the same time, our tech department is fairly small so we want
this transition to be as smooth as possible, hence the slow rollout &mdash; consider
this a canary release until everything is well-oiled and we&rsquo;re comfortable enough
with making the program public.</p>

<p>With this in mind, I&rsquo;d like to invite everyone who would like to take a look at
our program to mail us at <code>security@namshi.com</code> and share the email they use on
hackerone, so that we can invite you to the Namshi Bug Bounty program. As I
mentioned, this is a first step towards our program turning public in the upcoming
months.</p>

<p>Considering our goal to be more open and transparent, I would also like to take
a second to disclose some of our stats taken from hackerone:</p>

<ul>
<li>our <strong>minimum bounty is $50</strong></li>
<li>the total number of submissions is 67</li>
<li>we have <strong>resolved 27 reports</strong> (meaning the remaining are to be considered invalid, or part of the exclusions)</li>
<li>our average time to <strong>first response is 1 day</strong> (last 90d)</li>
<li>our average time to <strong>bounty is 3 days</strong> (last 90d)</li>
<li>our <strong>average bounty range is $120 &ndash; $150</strong></li>
<li>our <strong>top bounty range is $450 &ndash; $1000</strong></li>
</ul>


<p>Happy hacking!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open Source UI libraries from our iOS Mobile team]]></title>
    <link href="http://namshi.github.io/blog/2018/04/17/open-source-ui-libraries-from-our-ios-mobile-team/"/>
    <updated>2018-04-17T07:08:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/04/17/open-source-ui-libraries-from-our-ios-mobile-team</id>
    <content type="html"><![CDATA[<p>Recently, the Namshi iOS app went through a UI overhaul which includes a new font, improved UX on a few screens and some attractive animations. Customers loved it, the team enjoyed working on it and, best of all, conversion rate increased.  To achieve this, we relied on a few open source libraries available through Cocoapods.</p>

<p>Some of the available open source UI components are very well written and while working with these, you will get a lot of inspiration. I won’t hesitate to mention <a href="https://github.com/Skyscanner/SkyFloatingLabelTextField/">SkyFloatinglabelTextField</a> from SkyScanner and <a href="https://github.com/xmartlabs/XLPagerTabStrip">XLPagerTabStrip</a> here. Sometimes, the UI requirements are very specific and UI libraries will not support the particular use-case you have. While working on the UI improvement for Namshi iOS app, we faced the same situation where we had to modify an existing library to tweak its looks.</p>

<!-- more -->


<p>So it was a combination of inspiration and custom requirements that resulted in two awesome UI components which we recently published on Cocoapods. Let me Introduce these libraries separately below :</p>

<h1>NMFloatLabelSearchField</h1>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522079824203_CocoaPodsSwift-feature.png" alt="" /> <span style="margin-left: 15px"><a href="http://cocoapods.org">www.cocoapods.org</a></span></p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522078748825_github.png" alt="" />  <span style="margin-left: 15px"><a href="https://github.com/namshi/NMFloatLabelSearchField">https://github.com/namshi/NMFloatLabelSearchField</a></span></p>

<h2>Case Study :</h2>

<p>We had a requirement to implement UITextFields on which hints float up when the user starts to type; the border can also be highlighted based on different delegate callbacks and on validation errors.</p>

<p>We found SkyFloatingLabelTextField which does that perfectly and supports RTL languages as well.  Here comes the challenge: we had a city suggestion field in the form which dynamically displays a suggestion list as user starts to type, and this feature is not supported in SkyFloatLabelTextField. So we started our search again and found one more library, SearchTextField. We went ahead with it and used both of them.</p>

<p>Soon we realized that the UX of the screen is not appealing as five fields (name, country code, city code, phone number and address) are having floating-placeholders but the city field looks like a fish out of water here. We at Namshi are always eager to make the UX smooth and appealing for our customers, so we decided to join the two third-party libraries’ functionality and combine them for our city-search-field.</p>

<h2>Solution:</h2>

<p>In the beginning, we extended the functionality of SearchTextField and added the code from SkyFloatingLabelTextfield to achieve FloatingLabelSearchField functionality. It worked well but we realized that we are not properly getting the textField delegate callbacks (didEndEditing never worked).
We looked into the open issues for SkyFloatingLabelTextField but there was none related to this. Then we looked for the open issues for SearchTextField and — voila! — we found an <a href="https://github.com/apasccon/SearchTextField/issues/36">open issue</a> in the library. We changed our strategy; extended the functionality of SkyFloatingLabelTextfield and added the code for SearchTextField in the our code. We faced few bugs and me managed to fix those  and…..
Yalla, it really worked!
Soon our app was in store with the awesome looking “Add New Address” screen with smooth user experience.</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522081067491_image_preview.png" alt="" /></p>

<h1>NMAnimatedTabbarItem</h1>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522079824203_CocoaPodsSwift-feature.png" alt="" />  <span style="margin-left: 15px"><a href="https://cocoapods.org/pods/NMAnimatedTabBarItem">https://cocoapods.org/pods/NMAnimatedTabBarItem</a></span></p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522078748825_github.png" alt="" /><span style="margin-left: 15px"><a href="https://github.com/namshi/NMAnimatedTabbarItem">https://github.com/namshi/NMAnimatedTabbarItem</a></span></p>

<h2>Case Study :</h2>

<p>The tabbar used in Namshi app was pretty basic, it looked like the tabbar from Apple&rsquo;s built-in apps when iOS 7 was released. We realized that almost all the major apps are incorporating some animations on tab bar so it was the right time to spice up UITabbar used in Namshi app.</p>

<p>We first started with <a href="https://github.com/Ramotion/animated-tab-bar">Ramotion</a> — this library is awesome! After playing with it for few hours, we realized that it has some deal breakers such as missing support  for RTL languages and has a problem putting tab items back into the correct position when you move to a screen which does not have a tabbar and try to come back to a screen which does. We forked the library, tried to solve the issues but gave up as, one after the other, new issues came up.</p>

<h2>Solution:</h2>

<p>We started by digging deep into Ramotion and we got the basic idea how they are animating Tabbar items. We used the same approach and made the whole thing much more simpler.</p>

<p>We created an open class NMAnimatedTabBarItem inherits from NSObject with a public method called animateTabBarItem.</p>

<p>We have to pass 3 arguments to this method, tabBar(UITabBarController.tabBar), tabIndex (Selected tabItemIndex) and finally animationType(NMAnimationtype).</p>

<p>NMAnimationtype could be:</p>

<ul>
<li>Bounce</li>
<li>Rotation</li>
<li>Transition</li>
<li>Frame</li>
</ul>


<p>For Bounce, Rotation and Transition tabbar item image required. For Frame animation we have to pass UIImage Array.</p>

<p><span style="text-align: center; display: block">
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_ED3A3F43C1A3C37015D225DDB70A39423F77B009324EF3510BD4811463D17DED_1522583517426_ezgif.com-resize.gif" alt="" />
</span></p>

<hr/>


<h1>Some Useful Links for Creating Custom Pods</h1>

<ul>
<li><a href="https://code.tutsplus.com/tutorials/creating-your-first-cocoapod--cms-24332">https://code.tutsplus.com/tutorials/creating-your-first-cocoapod&mdash;cms-24332</a></li>
<li><a href="https://guides.cocoapods.org/making/private-cocoapods.html">https://guides.cocoapods.org/making/private-cocoapods.html</a></li>
<li><a href="https://guides.cocoapods.org/making/specs-and-specs-repo.html">https://guides.cocoapods.org/making/specs-and-specs-repo.html</a></li>
<li><a href="https://medium.com/@shahabejaz/create-and-distribute-private-libraries-with-cocoapods-5b6507b57a03">https://medium.com/@shahabejaz/create-and-distribute-private-libraries-with-cocoapods-5b6507b57a03</a></li>
<li><a href="https://www.raywenderlich.com/99386/create-cocoapod-swift">https://www.raywenderlich.com/99386/create-cocoapod-swift</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Women in Tech @ Namshi: Noor Ali]]></title>
    <link href="http://namshi.github.io/blog/2018/03/25/women-in-tech-at-namshi-noor-ali/"/>
    <updated>2018-03-25T10:50:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/03/25/women-in-tech-at-namshi-noor-ali</id>
    <content type="html"><![CDATA[<p>Here at Namshi we have quite a bit of a <a href="http://namshi.github.io/team">diverse team</a> but, like many companies
out there, struggle with the gender gap in tech.</p>

<p>We, though, would like
to share the story and advices from the women who are part of our team, with the
hope that they&rsquo;ll inspire others to join us, or to simply give computer science, or
programming in general, a go.</p>

<!-- more -->


<p>Without further ado, let me introduce <a href="http://namshi.github.io/team#noor">Noor</a>, who:</p>

<blockquote><p>&hellip;is a telecom engineer with Masters in Computer Science from Karachi, Pakistan. She started her career as an iOS developer, enhancing her skills in Android and then Mac development. She is a diversified team player, a detail oriented resource, and a quick learner. She has keen interest in application development based on smart TV, smart watch, google glass apps, and wearable gadgets. She loves to spend time learning new technologies related to big data and mobile apps development.</p></blockquote>

<p><strong>Can you briefly tell us a bit about yourself?</strong></p>

<p><img class="center" src="http://namshi.github.io/images/noor.jpg" width="200"></p>

<p><em>I am an ordinary omnivert person who is telecommunications engineer by education and software engineer by profession. I am often considered as a backstage performer. I love to write blogs and do voluntarily work whenever I get time.</em></p>

<p><strong>How did you get into programming &amp; computer science?</strong></p>

<p><em>My final year project in Bachelors was on MATLAB which enhanced my programming and research skills, then later got chance to work on android platform. Based on programming concepts, got job as trainee iOS developer and hence the CS journey started. Later decided to continue education in computer science and did Masters in IT with thesis on NLP.</em></p>

<p><strong>What does your typical day at work look like?</strong></p>

<p><em>Like this:</em></p>

<p><img class="center" src="http://namshi.github.io/images/noor_at_work.jpg"></p>

<p><em>Jokes apart, besides working on the assigned tasks in office, I try to learn at least one thing new everyday. I manage my own sheet to track my progress.</em></p>

<p><strong>What is the most challenging project you worked on? The one that made you the proudest?</strong></p>

<p><em>All projects have different challenges and I am proud of every app I&rsquo;ve worked on. The one that made me proudest was my first mac app, LightUp. Because working on mac app was different from mobile apps, there were more challenges there like changing window size, menu controls, etc.</em></p>

<p><strong>What advice would you give to a woman considering a career in the tech industry? What do you wish you had known?</strong></p>

<p><em>Try to think out of the box and work smart, not hard.</em></p>

<p><strong>Thanks Noor &mdash; both for sharing your experience and keeping the Namshi mobile apps under
control! :)</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: a frontend engineer]]></title>
    <link href="http://namshi.github.io/blog/2018/01/07/currently-hiring-a-frontend-engineer/"/>
    <updated>2018-01-07T12:07:00+00:00</updated>
    <id>http://namshi.github.io/blog/2018/01/07/currently-hiring-a-frontend-engineer</id>
    <content type="html"><![CDATA[<p>Love React, React Native, the dom and webperf? Then we might have the right
opening for you!</p>

<!-- more -->


<p>It is no news that we&rsquo;ve been banking on the JS ecosystem
for a few years: from rolling out our first angular apps in 2013 to using React
Native in our android app, we&rsquo;ve been very busy trying to push our frontends
as far as possible.</p>

<p>We run a Service-Oriented architecture where JS plays a huge part: most of our
services are either SPAs or small NodeJS-backed APIs, and <strong>JavaScript is king</strong> at
Namshi.</p>

<p>We would like to work with someone who has a very strong background in the language,
who&rsquo;s been battling on the frontend for a few years and is not afraid to dive into
Node, if required.</p>

<p>Some of the things our frontend team has been working over the past few months:</p>

<ul>
<li>integrating React Native on our <a href="https://play.google.com/store/apps/details?id=com.namshi.android">android app</a></li>
<li><a href="http://namshi.github.io/blog/2017/05/02/rebuilding-our-mobile-website/">improving conversion rate on our mobile website by 20%</a></li>
<li>releasing some interesting open-sourced <a href="https://github.com/namshi/slim-slider">frontend</a> <a href="https://github.com/namshi/dollar-dom">bits</a></li>
</ul>


<p>Most of our frontend apps are built with React, although some of the older apps
still kick it in angular boots. With a fleet of 100+ microservices, we&rsquo;re
generally very busy trying to innovate as much as possible.</p>

<p>Understand the inner workings of virtual dom? Think redux is not a replacement
for components&#8217; state? Grasp how HTTP/2 helps frontend developers?
Then we&rsquo;re definitely a match!</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application at <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few weeks back I wrote a small piece about <a href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Spot Instances in Production]]></title>
    <link href="http://namshi.github.io/blog/2017/07/09/running-spot-instances-in-production/"/>
    <updated>2017-07-09T10:12:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/07/09/running-spot-instances-in-production</id>
    <content type="html"><![CDATA[<p>Around this time last year, we decided to try running subset of our customer-facing web traffic on spot instances.<br/>
This decision was solely based to reduce our AWS instance bill. We&rsquo;ve heard of people running workloads on spot instances but most of the workloads are usually long-running jobs where you don&rsquo;t mind if the instance gets terminated at any time. Running customer-facing apps is a completely different challenge where we can&rsquo;t afford any downtime of any sort.</p>

<!-- more -->


<h3>Background</h3>

<p>We are fully running <a href="https://kubernetes.io/">kubernetes</a> in production which makes it exciting for the challenge of how we can actually test chaos engineering in production with our microservices.<br/>
We chose <a href="https://coreos.com/os/docs/latest/booting-on-ecs.html">CoreOS Container Linux</a> as our preferred operating system because of faster bootup time and it does only 2 things for us: docker service (for running containers) and flannel networking (for inter-pod networking).<br/>
We use both launch configuration and autoscaling service to manage our fleet of spot instance.<br/></p>

<p>Some of the questions we asked oursleves on how to setup a robust infrastructure to support any kind of termination of the spot instances</p>

<ol>
<li>How do we gracefully reschedule the pods to other nodes before the spot instance goes down?</li>
<li>How do we handle the surge in price for one availability zone?</li>
<li>How do we handle the surge in price for the whole region?</li>
</ol>


<h3>How do we gracefully reschedule the pods to other nodes before the spot instance goes down?</h3>

<p>Gracefully rescheduling pods initially do seem straightforward until we started noticing some issues with image pulling from our private registry and the docker hosts. This usually happens as a result of spike requests if more than ten (10) images of around 200MB size are being pulled at the same time. There is <a href="https://kubernetes.io/docs/user-guide/kubectl/v1.6/#drain">kubectl drain</a> which works pretty well but not for us because of the issue mentioned earlier.</p>

<p>Luckily, AWS introduced <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html">spot instance termination notice</a> which is a 2-min window to do cleanups before the spot-instance is terminated, we wrote a simple golang binary which watches the instance metadata for the termination notice and does the following within the 2-min grace:</p>

<ul>
<li>Detach the instance from the ELB (if applicable)</li>
<li>Mark the instance as unschedulable</li>
<li>Delete the pods with a sleep in-between of 10secs (This should take care of approximately 20pods, which is a very rare case for us)</li>
</ul>


<p>This binary is managed by a systemd service</p>

<figure class='code'><pre><code class='language-bash'>---
coreos:
  units:
    - name: spot-terminate-cleaner.service
      command: start
      content: |
        [Unit]
        Description=Graceful cleanup of spot instances before termination
        Requires=network-online.target
        After=network-online.target
        ConditionPathExists=/etc/spot

        [Service]
        ExecStart=/opt/bin/nm-tools spot-shutdown
        Restart=always
        RestartSec=10</code></pre></figure>


<h3>How do we handle the surge in price for one availability zone?</h3>

<p>It is advisable to run the spot-instances in at least two availability zones to cope with surge in price in one of the availability zones. If there is a price surge above the bidding price in one zone and the spot instances are terminated, autoscaling group service automatically launches the same number of terminated instances in the zone(s) with bidding price higher than the current spot price. With this, we achieve something close zero-downtime during the re-scaling activity.<br/></p>

<p><img class="center" src="http://namshi.github.io/images/spot-stage-1.png" width="500" title="price surge in one availability zone" ></p>

<br/><br/>


<p>This also poses another challenge when the spot price drops below the bidding price in the previously affected region. What happens is that two instances launched back in <code>eu-west-1b</code> while the same number of instances are terminated to balance the autoscaling desired capacity. In this activity, we are going to lose instances abruptly, but luckily AWS autocaling service has a feature called <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/lifecycle-hooks.html">lifecycle hooks</a>.<br/></p>

<p>To avoid abrupty autoscaling termination, we added a lifecycle hook for <code>autoscaling:EC2_INSTANCE_TERMINATING</code> transition state with the notification target as SQS. This sends an event containing the instance to be terminated to the SQS. We now have a python script (can be converted to a lambda function) which:</p>

<ul>
<li>Consumes the SQS message</li>
<li>Detach the instance from the ELB (if applicable)</li>
<li>Mark the instance as unschedulable</li>
<li>Delete the pods with a sleep in-between of 10secs (This should take care of approximately 20pods, which is a very rare case for us)</li>
<li>Delete the SQS message once the task is completed</li>
</ul>


<p>All the tasks above are completed within 2-min window to match the spot-instance termination notice period.</p>

<h3>How do we handle the surge in price for the whole region?</h3>

<p>We use <a href="https://sensuapp.org/">Sensu</a> as part of our monitoring stack and developed a simple sensu (ruby) check which compares the current spot price from AWS API against our bidding price used in the launch configuration. We do mark the check state as <strong>warning</strong> when the spot price is within the warning and critical threshold for all the zones in the region and the check is only marked as <strong>critical</strong> if the spot price is higher than our critical threshold in all the zones in the region. When the check state is critical, there is an auto-remediation script which switches the launch configuration of the autoscaling group for the spot instances from spot to on-demand (the script clones the current launch configuration, removes the spot price and replaces the launch config in the autoscaling group). With this, we don&rsquo;t end up with no running instances.</p>

<figure class='code'><pre><code class='language-bash'>{
  &quot;checks&quot;: {
    &quot;lc_spot_price_check&quot;: {
      &quot;command&quot;: &quot;/etc/sensu/plugins-custom/check-lc-spot-price.rb -n namshi-spot -r :::aws.region:::&quot;,
      &quot;subscribers&quot;: [ &quot;aws&quot; ],
      &quot;interval&quot;: 60,
      &quot;refresh&quot;: 14400,
      &quot;handlers&quot;: [ &quot;default&quot;, &quot;ses&quot;, &quot;remediator&quot; ],
      &quot;remediation&quot;: {
        &quot;lc_spot_price_check_remediation&quot;: {
          &quot;occurrences&quot;: [1, 2],
          &quot;severities&quot;: [2]
        }
      }
    },
    &quot;lc_spot_price_check_remediation&quot;: {
      &quot;command&quot;: &quot;sudo /usr/bin/salt-call spot_price.update_spot_asg namshi-spot ondemand=True&quot;,
      &quot;subscribers&quot;: [],
      &quot;handlers&quot;: [ &quot;default&quot;, &quot;ses&quot; ],
      &quot;interval&quot;: 10,
      &quot;publish&quot;: false
    }
  }
}
</code></pre></figure>




<br/><br/>


<p>So far, this has been working well for over a year without any major issues and we have been able to save between 35% and 45% on the instance cost since then.<br/>
Hope you can give it a try and feedbacks are appreciated.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[70% faster: rewriting the API that serves most of our traffic]]></title>
    <link href="http://namshi.github.io/blog/2017/05/28/rewriting-the-catalog-api/"/>
    <updated>2017-05-28T18:37:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/05/28/rewriting-the-catalog-api</id>
    <content type="html"><![CDATA[<p>At the beginning of 2017, we decided to revamp our catalog API which is one of the main parts of our infrastructure, as it’s the API that serves 60 to 70% of our overall traffic.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_main.png"></p>

<!-- more -->


<p>The catalog API provides a way to access our product offering. Broadly, it serves three categories of data:</p>

<ul>
<li>static pages (<a href="https://en-ae.namshi.com/women/">https://en-ae.namshi.com/women/</a>)</li>
<li>product details (<a href="https://en-ae.namshi.com/buy-anaya-patchwork-detail-kaftan-for-women-kaftans-263349.html">https://en-ae.namshi.com/buy-anaya-patchwork-detail-kaftan-for-women-kaftans-263349.html</a>)</li>
<li>product listing with search and suggestions (<a href="https://en-ae.namshi.com/women-clothing-arabian_clothing/">https://en-ae.namshi.com/women-clothing-arabian_clothing/</a>)</li>
</ul>


<p>Static pages, which are HTML files prepared by our content team, are stored on the file system. The product details are a set of product-specific information; the bulk of that information is stored in Redis so that we only have to go to the database to fetch stock availability for a particular product (as we want that to be real-time and extremely accurate). Product search and suggestions are powered by Solr, using keys based on product category, brand and so on.</p>

<p>We had two main goals for the rewrite: better performance and more ease of extensibility. In this post, we talk about how we managed to achieve those goals and our overall journey moving the products catalog API from our legacy PHP application to a Node.js microservice.</p>

<h2>Why did we decide to rewrite it?</h2>

<p>Our catalog API was built on top of our initial, chubby <a href="http://symfony.com/blog/going-soa-with-symfony2-a-year-and-a-half-down-the-road">API layer powered by Symfony2</a> — a single repository hosting a few other functionalities of our architecture, like checkouts and customer profiles, all deployed as a single building block.</p>

<p>As the months went by, we decided to shift towards microservices and go for a rewrite because:</p>

<ul>
<li>a new, clean implementation is free from other dependencies, not tied to our shared API layer.</li>
<li>we could move away from PHP: as much as the language and platform have evolved since we started using it (we started with PHP 5.3, the PSR-0…those times!), we feel that other platforms provide a <a href="https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/">“nicer” development experience</a><a href="https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/">.</a></li>
<li>we’re very bullish on <a href="http://www.grpc.io/">gRPC</a> as the next-gen standard for communicating among microservices, and that wasn’t easy to support with our legacy implementation. Furthermore, even though that’s bound to change, you cannot build gRPC servers in PHP as only the client-side part is implemented.</li>
</ul>


<p>We could go on and mention a whole bunch of other reasons but, fundamentally, it all boils down to the fact that we needed to <strong>move away from our shared API layer</strong>. It served its purpose very well, allowing us to do <a href="https://en.wikipedia.org/wiki/Rapid_application_development">RAD</a> with very little overhead, unified deployments and shared dependencies. As the number of services grew larger and larger we decided to shift the complexity from the code (imagine maintaining an app with many responsibilities) to the architecture (imagine maintaining X apps with 1 responsibility): time to extract the beast!</p>

<p><em>(if you are interested in why we didn’t start with microservices to begin with, we’d recommend having a look at</em> <em><em><a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html"><em>Microservices: not a free lunch</em></a> </em>on High Scalability and</em> <a href="https://martinfowler.com/articles/microservice-trade-offs.html"><em>Microservice tradeoffs</em></a> <em>by Martin Fowler)</em></p>

<h2>Why NodeJs?</h2>

<p>We’ve banked on JavaScript for quite some time, as we realized it’s the <em>lingua franca</em> that everyone’s able to speak. Software engineers get comfortable fairly quickly with it, and with ES6 and async/await (which we use through <code>node --harmony-async-await</code>), the language looks less of a weirdo 😃</p>

<p>Another reason to pick it was the fact that NodeJS is quite fast, especially for I/O heavy applications because it naturally handles I/O in a non-blocking manner, giving us a high throughput.</p>

<p>How fast? Well, <strong>fast enough</strong>.</p>

<p>We look at milliseconds, not microseconds, when we want to optimize the performance of our services, so having a platform that lets us efficiently schedule work <a href="https://bytearcher.com/articles/parallel-vs-concurrent/">concurrently</a> is all we need. The fact that we’re running in a “VM” (as opposed to the request-response-death model of traditional PHP deployments) lets us do some performance optimizations with objects we need to re-use across requests — and we will explain those in detail later in this post. Let’s just say that we want a platform that can serve a sizable chunk of our HTTP requests <strong>within 20ms or less</strong>, and NodeJS does it very well.</p>

<p>What we think JS sucks at is that <strong>large codebases tend to become unmaintainable</strong>, so we’ve made it our goal to <strong>never end up with a large JavaScript codebase</strong>. Most of our applications are microservices deployed on Docker containers, and re-writing good chunks of them won’t require more than a few weeks: we believe this leads to manageable JS applications, without needing Typescript, 100% test coverage &amp; the likes.</p>

<p>Our answer to how to grow a JS codebase? <strong>Don’t grow it, split it</strong>!</p>

<h2>Design</h2>

<p><strong>Architecture</strong></p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_architecture.png"></p>

<p>The architecture consists of a cluster of Node.js applications running within docker containers each of which are capped to 1 GB of RAM and 50% of 1 CPU core. We use Kubernetes to handle auto-scaling of our application. We have a Kubernetes configuration that handles automatically scaling our application once the CPU usage reaches 40% of 1 CPU core. We also have a Redis cluster (in <a href="https://aws.amazon.com/elasticache">ElastiCache</a>) alongside a <a href="http://tech.namshi.io/blog/2017/02/06/towards-high-availability-and-beyond/">highly available S</a><a href="http://tech.namshi.io/blog/2017/02/06/towards-high-availability-and-beyond/">olr cluster</a>.</p>

<p>Sidecar is a container running beside each instance of our catalog API, responsible for downloading the static HTML files from Amazon’s S3 when we want to update our static pages. It first downloads them to a shared volume and then notifies the catalog API by creating an update lock file: the application is always checking for the existence of this lock file and, once it finds it, it will clear the internally cached static files.  You can checkout our open source <a href="https://github.com/namshi/s3-sidecar">s3-sidecar</a>.</p>

<h2>The tools we use</h2>

<h3>Memoization</h3>

<p>A lot of our requests generate high number of cache misses, primarily because of small differences between requests, and we used to have a reverse proxy layer, powered by Varnish, that would serve cached results to around 20/25% of the requests. In order to simplify our architecture we decided to remove this layer (all in all, we didn’t have a high hit-rate) and use application level cache (through <a href="https://github.com/medikoo/memoizee">memoizee</a>) extensively, caching data used to service the request rather than caching the response itself.
For example, we preload some data which doesn’t change frequently, then save it in memory and update it at intervals — this reduces the number of times we need to call external systems such as Redis, and speeds up the response time. Worth to note that we also use <code>memoizee</code> to cache our Solr request and, as much as we thought of putting Varnish in front of Solr, we eventually realized we didn’t need such complexity.</p>

<h3>Redis Pooling</h3>

<p>Instead of creating a new connection to Redis every time we need data, we created a connection pool to manage and reuse connection to Redis: the pool will keep a minimum number of open connections, and make sure we don’t exceed the maximum number of connections set in our configuration. This way we can keep less connections open, and scale them up fairly quickly when the app gets hammered by more traffic.</p>

<p>(<em>We used the</em> <a href="https://github.com/coopernurse/node-pool"><em>generic-pool</em></a> <em>module to avoid re-inventing the wheel 😃 )</em></p>

<h3>Redis Client Proxy</h3>

<p>In order to centralize error, timeout and response handling when we interact with Redis, we added a proxy layer on top of the widely used <a href="https://github.com/NodeRedis/node_redis">redis module</a>, so that acquiring a connection, executing an operation and releasing the connection are abstracted away, with a promise-based interface: we released this as an open source <a href="https://github.com/namshi/node-redis-wrapper">redis wrapper</a> that contains both pooling connections and the proxying calls to redis.</p>

<h2>Going live</h2>

<p>You know how live deployment should be? <strong>Boring as hell</strong>, and we’ve embraced this philosophy when rolling out this new API: the adrenaline of clicking the red button and rolling out the service at once is tempting, but the software engineer in you knows that it’s best to go live incrementally, fully prepared, aware of all the risks and ready to yawn as everything goes as expected.</p>

<p>Before going live, we decided to take a dual approach at benchmarking: first we would make sure that responses were “fast enough”, then that they were “scalable enough”.</p>

<h3>Being “fast enough”</h3>

<p>It’s generally easy to think of the operations a piece of code is doing and say “hey, this shouldn’t take more than 5 milliseconds”, and that’s what we exactly did: we simply rolled out to staging fairly early on and started doing some load testing with <a href="https://github.com/tsenart/vegeta">vegeta</a>.</p>

<p>After looking at the results coming from vegeta, we would then analyze them and figure out if they seemed reasonable to us: does <code>GET /some-content</code> involve calling Redis a couple times? Then it shouldn’t take more than 5 milliseconds. Does <code>GET /product1.html</code> need to fetch stock data from a slower DB? Then we should definitely be within 20/30 milliseconds. Is node taking more than 15 milliseconds on a particular route? Then we probably need to look at the way our code is organized, search for unneeded loops, and optimize.</p>

<p>NewRelic was instrumental during this phase, as we were able to see if we were hitting other layers too many times:</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_newrelic.png"></p>

<p>Why is Redis taking 10 milliseconds? Are we hitting it multiple times? Can we batch requests together and instead of sending 3 <code>HGET</code> we simply issue 1 <code>HMGET</code>? Those were the kind of things we were looking at the time. By doing so, we optimized chunks of our code and were ready to take it to the next level.</p>

<blockquote><p><strong>A note on the computational cost of abstractions</strong></p>

<p>Lodash is a very popular JavaScript library that provides generic abstractions to solve various problems. One of them is the “<a href="https://lodash.com/docs/4.17.4#pick">pick</a>” function which is used to pick a property from an object.</p>

<p>It turns out that this convenient abstraction comes at a cost.</p>

<p>Normally getting a property value from an object in JavaScript cost O(1) on the average case, but lodash’s pick’s implementation costs a O(n) on all cases where n is the length of properties within the object; in our case,
we were looping over hundreds of products and the delay in performance was not acceptable, so we opted to lose the abstraction provided by lodash in this regard.</p></blockquote>

<h3>Being “scalable enough”</h3>

<p>Now, we’re no fools (or at least we like to believe so!), so we were sure that doing a bunch of “static” benchmarks with vegeta wouldn’t really tell us how the application would behave in production, where the amount of traffic and the variety of requests are very different.</p>

<p>We started testing the “elasticity” of the app: take down all instances but one and start bombing it with incremental traffic, so we can observe how it reacts to an increase in traffic. We did so with a <a href="https://github.com/odino/quick-load-incremental">silly bash script</a> that would send X requests for a few minutes, give the service a break, then send 2X requests, 3X etc. This showed that the app could easily adapt to different levels of traffic, and we could focus on the next step.</p>

<p>Even though we now realized the app could take on a higher load without suffering too much, our tests were still too unrealistic: we were probing a few, known URLs, whereas live traffic would be spread across many different URLs — products with 1 size, multiple sizes, products with many different related products, categories with very few products, categories with a plethora of products and so on. <strong>Replaying live traffic was a must</strong>.</p>

<p>Luckily, we discovered <a href="https://goreplay.org/">goreplay</a> a couple years back and fell in love with it. It lets you replay TCP traffic from one host to another one, without much overhead (it doesn’t act as a proxy, it just analyzes network packets and replays them, kind of a <a href="https://github.com/buger/goreplay/wiki/Capturing-and-replaying-traffic">tcpdump on steroids</a>). We then scaled up our staging cluster and replayed most of our live traffic to staging, observed the metric and let the replay run for hours and eventually days, until we were comfortable that the new app could sustain the live traffic very well.</p>

<p>We finally decided to deploy the application to production, but did not switch everything to the new API in one go as that could have brought down our entire website in case there were any issues that we hadn’t caught in the previous stages. So we went for the <strong>boring partial deployments</strong> approach: we kept the old app running and we started progressively switching traffic to the new app.</p>

<p>First, we picked the country with the least amount of traffic, then monitored the app, fixed the small bugs that would occur and repeated that same process for each one of the countries we serve until all the traffic was switched to the new app — the whole process took about two weeks.
Yeah, it’s boring.</p>

<h2>Results</h2>

<p>Now comes the time to show what we were able to achieve in terms of performance improvement. In the old application, our average response time was around 82 milliseconds.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_1.png"></p>

<p>In the new application we managed to achieve an average response time of around 27 milliseconds — that is a 67% performance improvement:</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_2.png" title="" ></p>

<p>Since averages can be misleading let’s look at the percentile graph of the new application’s response time data.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_3.png"></p>

<p>What the graph above tells us is that 50% (red line) of our requests are served under 20 milliseconds and 95% (yellow line) of them are served below 100 milliseconds.</p>

<p>Using an histogram we also see the same pattern.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_4.png"></p>

<p>Basically, according to the histogram above, 20% of our requests are served within less than 10 milliseconds, and 53% of them are served within 20 milliseconds.</p>

<p>Now let’s look at the improvements in terms of resources utilization: as indicated in the graph below, our old PHP application used to consume about 25% of 2 CPU cores and 4 GB of memory. We went live with the new application on April 12, hence the considerable drop in resource consumption that you see in the graph.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_5.png"></p>

<p>The new application however as you can see in the graph uses way less resources. The graph below is for one of our host, which serves around 1000 rpm (requests per minute), and uses half a CPU (<a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/">capped by k8s</a>) with a memory limit of 1 GB. You would agree  that’s a huge improvement on the old application!</p>

<p><img class="center" src="http://namshi.github.io/images/posts/catalog_api_results_6.png"></p>

<h2>What’s Next?</h2>

<p>We are really happy with what we have achieved so far with the rewrite of the catalog&rsquo;s API. As we move forward, we would like to keep improving it — as we do for all of our codebase — by introducing appropriate tools and technologies. For example we would like to upgrade to node 8 so that we can take advantages of some nice features such as <code>async</code>  and <code>await</code> (without relying on harmony flags). We are also exploring the idea of using gRPC in order to improve how we do distributed systems overall.</p>

<p>If what you read here sounds interesting to you and you would like to build cool stuff with us, <a href="http://tech.namshi.io/blog/2017/03/09/currently-hiring-backend-mobile-developers-dubai/">please come join us</a>.</p>

<p><em>This article has been a joint effort between the backenders that revamped our
catalog API between February and April 2017: <a href="http://tech.namshi.io/team/#Ayham%20Alzoubi">Ayham</a> and <a href="http://tech.namshi.io/team/#Joe%20Jean">Joe</a>.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rebuilding our mobile website: Express & React meet fun & profit]]></title>
    <link href="http://namshi.github.io/blog/2017/05/02/rebuilding-our-mobile-website/"/>
    <updated>2017-05-02T18:37:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/05/02/rebuilding-our-mobile-website</id>
    <content type="html"><![CDATA[<p>Late last year we decided to give our mobile website a new look, coupled with a new “engine” in order to optimize our mobile experience on the web. Most of our users visit Namshi from mobile devices and we wanted to give them better usability, performance and overall smoother experience.</p>

<!-- more -->


<p>When we started approaching the mobile landscape, 4 years back, we decided to fully commit to an SPA that worked well but showed some limitations, namely the inability to perform server-side rendering, which was somewhat critical in terms of search engine optimization and first render: we solved the former by routing bots’ traffic to our desktop website (a traditional server-side app), but the latter proved hard to solve, as the client would have to download our entire app before being able to understand what page and layout it should render. In the meantime, Google decided to roll the “<em>mobile-friendly</em>” badge on their mobile SERPs, which forced us to look for alternatives.</p>

<p>A year and a half down the line, facing mixed results in terms of conversion rate and usability, we decided to review our implementation and build a small isomorphic app that would be able to render both on the client and the server, but this approach had 2 major flaws: first off, we didn’t look at neither our UX nor UI to figure out if there was anything we could do to make the user’s experience better and, second, we over-engineered our stack. Back then React just started garnering attention and, unsure if <em>that</em> would be the way the community would build “frontend” apps 3/5 years later, we decided to write a very small custom-made isomorphic framework that turned way more complicated than we originally thought.</p>

<p>At Namshi, we’re very big on simplicity and &ldquo;<em>back to the basics”</em> but, as you see, that’s also thanks to <strong>lessons we learned the hard way</strong>.</p>

<p>Flash-forward to Q4 2016, we looked at our mobile website and our metrics combined and decided it was time to completely re-think our approach: 2 of our engineers quickly hacked together a prototype within less than a week and, after discussing it with our PM team, we decided it was worth a shot.</p>

<p>The Falafel Project was born. Sounds like a joke but that’s what we actually called it :)</p>

<h2>Fundamental ideas</h2>

<p>The project kicked off by embracing 3 very important ideas:</p>

<ul>
<li>most of Namshi’s  traffic is served through our mobile apps (<a href="https://itunes.apple.com/us/app/namshi-online-fashion-shopping/id840127349?mt=8">iOS</a> + <a href="https://play.google.com/store/apps/details?id=com.namshi.android">Android</a>). We should probably <strong>mimic the app as much as possible</strong><strong>.</strong></li>
<li>The journey of the user is defined by very few, key components: landing pages, product listing pages, product detail pages, cart and checkout. We want to make sure we waste no time presenting these pages to the user, and <strong>server-side rendering</strong> gives that to us</li>
<li>If we want this webapp to look like it’s 2017, client-side interactions are unavoidable: <strong>picking React</strong>, given its rise in the frontend community and the fact that it’s a library, rather than a framework, was a no-brainer</li>
</ul>


<p><img class="center" src="http://namshi.github.io/images/posts/web-mobile-demo.gif" title="" ></p>

<h2>Re-writing the styles</h2>

<p><img class="center" src="http://namshi.github.io/images/posts/css-code.png" title="" ></p>

<p>We trashed the old css and rewrote it from scratch following the <a href="http://getbem.com/">BEM</a> way of doing things, which allowed us to separate styles per page and also have some of them shared between pages.
The total size of the minified styles was 18kb, now it is <strong>10kb:</strong> almost half of our css is gone!</p>

<h2>RTL styles</h2>

<p>It&rsquo;s always painful to handle direction in css, especially considering that things could have been much easier if <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Logical_Properties">logical properties</a> where introduced, but yet we still use the old techniques until we can fully dump rules overriding.</p>

<p>For example:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-css'>/**
 flex-start, flex-end logical properties will change according to the
 direction: rtl : ltr;
**/
.element {
 display: flex;
 align-items: flex-start;
 justify:-content: flex-start;
}
/**
 opposite to: text-align, css-transforms, floats, margins, paddings ..etc
 which we need to override manually.
**/</code></pre></figure>


<p>We kept the arabic styles in separate files, i.e <code>list.scss / list-rtl.scss</code> where the <code>*-rtls.scss</code> will only override rules in the main file.
That worked for us really well and was a substantial increase in code maintainability.</p>

<h2>Enhanced UX leveraging on mobile browsers</h2>

<p>We took a decision to ditch SPAs in favor of lightning-fast server-side rendered pages.</p>

<p>Despite that, we took advantage of a very interesting feature on modern mobile browsers:
if you tap on a link, they kinda fade the newly painted page over it so if there are common visual components you won’t feel the page load.</p>

<p>Strange, right? Have a look:</p>

<div align="center">
<iframe width="276" height="500" src="https://www.youtube.com/embed/WIOe1ID3ocM" frameborder="0" allowfullscreen></iframe>
</div>


<p>So how we can use it for our own good?
We came up with idea of a “<strong>Shadow Product”:</strong>  When a user taps on a product while on the catalog listing page, we delay the tap event for 10ms and we show a fake preview of what the next product page will look like. Simple and dirty, but looks great!</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>on(&apos;click&apos;, &apos;body&apos;, &apos;.is-shadow-product&apos;, e =&gt; {      
 .... code that extracts content from clicked product
 this.setState({ data: data, show: true });      
 setTimeout(function () {        
   window.location.href = href;      
 }, 10);
})</code></pre></figure>


<p>The problem with this approach is that we need to handle the <a href="https://developer.mozilla.org/en-US/docs/Working_with_BFCache">back-forward cache</a> of some browsers:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>// Prevent backforward cache in iOS devices
if(config.get(&apos;deviceOS&apos;) === &apos;iOS&apos;){
  window.addEventListener(&apos;pagehide&apos;, function(e) {
    let shadowProduct = document.querySelector(&apos;.is-transitional&apos;);
    shadowProduct &amp;&amp; shadowProduct.classList.remove(&apos;is-transitional&apos;);
  });
}</code></pre></figure>


<h2>NO jQuery</h2>

<p>Late, but we eventually joined the party! We stripped jQuery off  80% of our pages and we replaced with some vanilla utilities like the following:</p>

<ul>
<li><strong>On</strong> :</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>  export function on(eventType, parent, selector, fn){
    let el = document.querySelector(parent);  
    if(!el || !eventType || !selectorParent || !selector  || !fn ) {   
      return null;
    }

    el.addEventListener(eventType, function(e) {   
     .... logic to target the child on the event bubbling.
   })
  }, false);
</code></pre></figure>


<ul>
<li><strong>Scroll to, Scroll To Top and Scroll To Bottom:</strong></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>function animateScroll() {    
  var step = (dest - parent.scrollTop) /  steps--;    
  parent.scrollTop = parent.scrollTop + step;    
  if(steps === 0 ){      
    frame &amp;&amp;  cancelAnimationFrame &amp;&amp; cancelAnimationFrame(frame);       
    return    
  }     
 frame = requestAnimationFrame &amp;&amp;    
 requestAnimationFrame(animateScroll);   
}</code></pre></figure>


<hr />

<ul>
<li><strong>Image Carousel:</strong></li>
</ul>


<p>We crafted our own slider (<a href="https://medium.com/@MohamedAmin88/slim-slider-yet-another-javascript-slider-2f2069bb72e5">read the full story here</a>):</p>

<p><img class="center" src="http://namshi.github.io/images/posts/slim-slider.gif" title="" ></p>

<h2>Low Fat React: Preact!</h2>

<p>Though we chose SSR, we were not building a static news website. You can imagine how much client side interactions an E-commerce mobile website has. Our previous mobile website was a tailor made isomorphic app, and we had lot of lessons learned from it. Moreover, performance was a key focus area for our new website, hence we kept some design decisions for all the client-side stuff. These includes:</p>

<ul>
<li>Our website should be interactive under 5s.

<ul>
<li>Should have a great rendering performance. Animations and transitions should be ~60FPS.</li>
<li>Total client-side scripts should be less than 100KB ( including any frameworks / library ).</li>
<li>Build re-usable client-side components.</li>
</ul>
</li>
</ul>


<p>By considering all the above, we wanted something lightweight and with good rendering performance.</p>

<p>We initially ruled jQuery out of the list and thought of creating all client-side components in vanilla js, however, we found that managing the UI state was bit hard with that approach. Moreover, we really liked the redux architecture and keeping a single store for managing the whole UI state.</p>

<p>React was the hottest choice for our expectations but, at the same time, we wanted a lightweight library. Then we came across <strong>Preact</strong>, a 3KB React alternative which offered the same API and great performance.</p>

<p>We built most of our components in Preact and re-used them across pages. Although we liked the redux architecture, we didn&rsquo;t really use Redux on our website. Instead, we built a micro-redux which has a global store for managing the whole UI state and is connected to all Preact components. This helped us to manage the UI state in a single store and synchronizing updates in every part of the page.</p>

<h2>Simplifying the DOM states</h2>

<p>Managing state is one of the crucial parts of  &ldquo;react like&rdquo; development, especially state shared between components (Shared State) can be difficult to manage. We have good libraries that achieves this efficiently &mdash; ie. <a href="http://redux.js.org/">Redux</a> and <a href="https://mobx.js.org/">Mobx</a> that we use on some of our SPAs.</p>

<p>In the new mobile website, our approach is a bit different because each page is SSR and we have very less shared state: we try to reduce client-side code to the minimum, to keep things simple and less bloated.</p>

<p>We have one store which is the single source of truth. To keep things simple every component has it own actions as part of the component, and we only focus on resolving all data into the store and the store automatically updates the state of the components. Unlike most redux implementations, where reducers are used to update the current state based on the actions,  every update always produces a “next state“ without reference to the current state.</p>

<h2>Webpack, Code splitting and Preloading techniques</h2>

<p><img class="center" src="http://namshi.github.io/images/posts/chunk-size.png" title="" ></p>

<p><strong>Code splitting: eat only what you need</strong></p>

<p>Code splitting was a crucial part for our website. Traditionally, we used to bundle all our JavaScript assets into one single file, and loaded it in every page. At that time it was a very performance-friendly approach, as the browser gets all the assets with a <strong>single HTTP request</strong>.</p>

<p>With HTTP2, things changed — multiple round-trips are avoided by channelling multiple requests through a single connection. Knowing this, sending a large bundle (which includes code that&rsquo;s not needed in the current page) would negatively impact the page’s performance so we decided to split our code based on the routes ( different pages ).</p>

<p>We chose Webpack2 for bundling and code-splitting. As we said earlier, we generate js bundles ( aka chunks in webpack terminology ) for each page. We used Webpack&rsquo;s <a href="https://webpack.js.org/plugins/commons-chunk-plugin/">CommonsChunkPlugin</a> to generate a vendor bundle and common code shared between the page level bundles. This helped us to keep smallest JavaScript payload for each page. Furthermore, the vendor chunk and common chunk will change less frequently and can be cached by the browser for most requests, enabling faster transitions between pages.</p>

<p><strong>Reduce bundling and nested dependencies</strong></p>

<p>Webpack2 supports <a href="https://webpack.js.org/guides/tree-shaking/">Tree-shaking</a> out of the box, which helped us reduce the bundle size by ~20% by only including the required modules.</p>

<p>For example, we used some lodash utilities in our client-side code. Without Tree-shaking, the whole of lodash would have been imported into our bundles, thus the size would&rsquo;ve been much bigger. Webpack2 will instead generate the bundle only with the code that’s actually used.</p>

<p><strong>Preload, Prefetch</strong></p>

<p>We also took advantage of the latest browser features for attaining better page load speed. These includes the <code>dns-prefetch</code> for prefetching for resolving domain names, <code>link-preload</code> for loading the CSS and JS assets at the same time HTML is parsed. We also used <code>link-prerender</code> in our catalog listing page pagination to make the transition between pagination much faster.</p>

<p>Notice the <strong>Green Line</strong> ( which indicates the first paint ):</p>

<p><strong>Before</strong></p>

<p><img class="center" src="http://namshi.github.io/images/posts/before-preload.png" title="" ></p>

<p><strong>After</strong></p>

<p><img class="center" src="http://namshi.github.io/images/posts/after-preload.png" title="" ></p>

<h2>Goodbye good old image sprites</h2>

<p>Thanks to HTTP/2, making HTTP requests is cheaper than ever: multiplexing reduces the connection overhead as multiple requests can be tunneled through the same connections, and extended header compression (<a href="https://http2.github.io/http2-spec/compression.html">HPACK</a>) makes it so that those requests are lighter than ever.</p>

<p>This doesn’t mean sprites won’t give you any advantage: as always, making 10 HTTP requests instead of 1 is generally heavier, but with HTTP/2 you don’t “feel” it as much. Another argument <em>pro</em> sprites is that by combining images together we end up allowing the compression algorithm (ie. GZIP/DEFLATE) to better optimize the size of the final, combined image.</p>

<p>All in all, though, we eventually decided not to worry about these and live a less complicated life because:</p>

<ul>
<li>We generally bundle all required images into one sprite, whereas each page might just need 2/3 of them: this means that instead of downloading 100% of your images on the first page load we only require 20/30% of them</li>
<li>Maintaining sprites is no fun at all: if there’s a way to eliminate work and be <em>on par</em> with our previous implementation, then we’re definitely going to cut it short</li>
</ul>


<h2>Results</h2>

<p>Numbers, since we went live in mid-February, have been astounding. Even though web traffic is a small chunk of our overall traffic, it’s been way better than we could ever imagine:</p>

<ul>
<li><strong>conversion rate is up ~20%</strong>, meaning that the overall shopping experience is smoother (worth to note that some of the countries we serve have spikes in conversion of +30/70%)</li>
<li><strong>bounce rate is down 15%</strong>, which indicates that our first impression (load time, UI, etc) has definitely improved</li>
<li>the <strong>average time on page is up 50%</strong>, and the <strong>average session duration up 37%</strong>, meaning users enjoy spending time on the site way more than before</li>
<li>the <strong>average document load time &amp; average document interactive time are both down</strong> <strong>54%</strong> (4+ seconds vs 1.9), which means that…   …well, we really screwed it up with the previous app :)</li>
</ul>


<p>Take this numbers with a pinch of salt, as we mentioned in the introduction of this article, we started from a very disadvantageous point — the performance of the old mobile website was quite disappointing — and, at the same time, Namshi grows and optimizes on a daily basis, so better numbers are expected regardless.</p>

<p>Last but not least, one for the server-side freaks.
In this article, we spoke a lot about frontend optimizations and the likes, but I want to share an image to show the performance of our server-side rendering process:</p>

<p><img class="center" src="http://namshi.github.io/images/posts/web-mobile-results.png" title="" ></p>

<p>As you see, our <strong>average response time is around 40ms</strong> — but you shouldn’t  care, as <a href="https://www.dynatrace.com/blog/why-averages-suck-and-percentiles-are-great/">averages make for a terrible KPI</a>.</p>

<p>Percentiles are really what you want to look at:</p>

<ul>
<li>the <strong>median is at around 25ms</strong>, meaning half of our requests are served within that time</li>
<li>the <strong>95th percentile is at around 120ms</strong>, which is still incredibly great, considering that the website fetches the data it displays from an internal API, and that involves an external HTTP call</li>
</ul>


<p>See you next time!</p>

<p><em>This article is a joint effort between the 3 frontend musketeers of Namshi:
<a href="http://tech.namshi.io/team/#Shidhin%20CR">Shidhin</a>, <a href="http://tech.namshi.io/team/#Mohamed%20Amin">Amin</a> and <a href="http://tech.namshi.io/team/#Gabriel%20Izebhigie">Gabriel</a></em>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: backend and mobile engineers]]></title>
    <link href="http://namshi.github.io/blog/2017/03/09/currently-hiring-backend-mobile-developers-dubai/"/>
    <updated>2017-03-09T06:49:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/03/09/currently-hiring-backend-mobile-developers-dubai</id>
    <content type="html"><![CDATA[<p>We&rsquo;re currently looking for some help in a couple areas of our tech team &mdash; why
don&rsquo;t <strong>you</strong> join us?</p>

<!-- more -->


<h2>Mobile</h2>

<p>Getting into the specifics, we&rsquo;ve been working with an external mobile team (3rd party)
that wrote our apps from scratch, setup an efficient testing &amp; CI strategy and a
very solid deployment workflow &mdash; as a matter of fact, we&rsquo;re very proud of our
crash rate on both platforms, with android leading at 0.05%.</p>

<p>We are comfortable with the quality of our apps and the pace of development but,
in order to take them to the next level, it&rsquo;s clear to us that we need our own
team to do that: commitment, communication and going the extra-mile are definitely
different when you&rsquo;re part of the organization.</p>

<p>On the long run the team is going to be comprised of a few engineers and a lead,
so we&rsquo;d initially like to start with:</p>

<ul>
<li>1 <strong>lead mobile developer</strong>, who should ideally have good experience on both platforms</li>
<li>1 <strong>senior iOS developer</strong></li>
<li>1 <strong>senior android developer</strong></li>
</ul>


<p>The <strong>lead mobile engineer</strong> should ideally be a very hands-on, seasoned mobile
engineer with experience leading / forming a team &mdash; he will need to
help building the team, setting the right direction, overseeing development
on both platforms and coordinating with other teams (ie. backend
or product management) on feature development and aligning priorities. We expect
him to spend around 50% of his time on development (this is still a <em>hands-on</em> position),
and the other 50% on the team, teaching practices, reviewing pull requests and so on.</p>

<p>We expect from <strong>senior engineers</strong> to be able to write clean, testable code that&rsquo;s
hard to break &mdash; a few years (4+) of experience are definitely needed (say, you
should have bumped into <code>@autoreleasepool</code> before ;&ndash;)) and you
should be very familiar with different design patterns (Delegate, Facade, etc),
concepts such as mock objects and various tools to support your workflow (ie. CI
pipelines).</p>

<h2>Backend</h2>

<p>We could definitely use some help in our backend team :)</p>

<p>Even though we&rsquo;re not in a rough spot, we would like to be able to expand
our pipeline and be able to add even more seniority to the team: our usual &ldquo;backend problem&rdquo;
is that we have lots of things we&rsquo;d like to work on / experiment with but not a lot
of engineers, thus we eventually end up giving those projects up or delaying them
too much.</p>

<p>The main technologies you would be working with are:</p>

<ul>
<li>NodeJS</li>
<li>MySQL</li>
<li>Redis</li>
<li>Solr</li>
<li>Golang</li>
<li>Symfony2</li>
<li>a bit of frontend with either Angular or React</li>
</ul>


<p>all of these in the context of our microservice-based SOA: we currently employ
50+ service in production, mostly deployed in Docker containers through Google&rsquo;s
<a href="https://kubernetes.io/">Kubernetes</a>.</p>

<p>Here we would keep in consideration candidates for both a <strong>lead</strong> and a
<strong>senior</strong> position: the current team is working well and we haven&rsquo;t felt the
need to hire a lead engineer over the past few months, but we&rsquo;re open to the
idea if we find the right candidate.</p>

<p>Needless to say, both position would be <strong>quite hands-on</strong> :)</p>

<h2>Apply now!</h2>

<p>What are you waiting for? Send your application at <code>work-in-tech@namshi.com</code> and
let&rsquo;s have a chat!</p>

<p>P.S. A few weeks back I wrote a small piece about <a href="http://tech.namshi.io/blog/2016/12/06/get-that-job-at-namshi/">Namshi&rsquo;s hiring process and <em>desiderata</em></a>,
give it a look!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Upgrading our search server towards high availability and beyond]]></title>
    <link href="http://namshi.github.io/blog/2017/02/06/towards-high-availability-and-beyond/"/>
    <updated>2017-02-06T12:00:00+00:00</updated>
    <id>http://namshi.github.io/blog/2017/02/06/towards-high-availability-and-beyond</id>
    <content type="html"><![CDATA[<p>In this post, we are going to highlight how and why we did a solr upgrade from solr v3 to solr-cloud v6 with no downtime.</p>

<!-- more -->


<p>We have adopted solr v3 as our search server since the beginning because solr has a nice schema and a very responsive search indexer.
The old indexer was running on one solr server and whenever we needed to change the schema or trigger a full import we had to follow these steps:</p>

<ol>
<li>Unload the core<code>[SOLR_URL]/admin/cores?action=UNLOAD&amp;core=[CORE_NAME]</code></li>
<li>Recreate the core with new schema changes, if any: <code>[SOLR_URL]/admin/cores?action=CREATE&amp;name=[CORE_NAME]&amp;config=[solrconfig.xml]&amp;schema=[schema.xml]</code></li>
<li>Delete and then then re-import all documents</li>
<li>Commit the updates <code>[SOLR_URL]/update?commit=true</code> to see it effective</li>
</ol>


<p>The major drawback with this approach is that if the solr machine down it takes time to boot up another machine and re-import all the products again.</p>

<h2>How do we handle our solr updates?</h2>

<h3>Partial imports:</h3>

<p>Happens periodically: get the latest updates from DB and then update/delete only the changed documents in the given time frame.</p>

<h3>Full imports:</h3>

<p>Happens on request or on schema update: clear the indexer completely then insert all available documents.</p>

<p><img src="http://www.employeescreen.com/wp-content/uploads/2015/06/Upgrade-e1434047810231.jpg" alt="time to upgrade" /></p>

<p><a href="http://lucene.apache.org/solr/features.html">Solr has lots of improvements</a> and by using Solr-cloud in case of any solr instance failure we are not screwed.
The new structure is a solr cluster, and contains 3 zookeeper nodes with 2 solr cloud nodes.
<img src="http://namshi.github.io/images/solr-cluster.png" alt="Solr cluster!" /></p>

<h2>How do we handle the solr clients app during transition with confidence and no downtime on live environment?</h2>

<ul>
<li>We built a nodeJS service to handle periodic solr imports. The <a href="https://www.npmjs.com/package/zindex">Zindex library</a> is used to import data from mySQL (backend source) to solr.</li>
<li>We kept the old solr server running side by side with the new solr on live environment.</li>
<li>We made a change in our product catalog API that allowed us to return a response using the new or old solr, by simply using a special parameter. This allowed us to compare results coming from the old and new solr.</li>
<li>Finally, we switched catalog requests to use the new solr one locale at a time till all supported locales were served with the new solr.</li>
</ul>


<h2>During the upgrade we faced some challenges &ndash; we are listing them below and how we dealt with them:</h2>

<h3>How to revert unwanted updates?</h3>

<p>After a full import we tried to run some validations to accept or reject the import, since <a href="https://wiki.apache.org/solr/UpdateXmlMessages#A.22rollback.22">solr supports rollbacks!</a>
But we were disappointed because <a href="https://issues.apache.org/jira/browse/SOLR-4896">solr cloud mode doesn&rsquo;t support rollbacks</a>
We solved this issue by <strong>saving the import in temporary files, running validations on these files, then commit</strong></p>

<h3>How to swap collections?</h3>

<p>Another issue we faced was that during the full imports the product count in our catalog API decreased significantly, then increased slowly till the import finished.
The reason behind this is that we were deleting all products during the full import, then re-adding the products so solr  would show updates as fast as possible.
To solve this issue we were thinking about <a href="https://wiki.apache.org/solr/CoreAdmin#SWAP">swapping</a> but this, again, was not supported in solr cloud
So instead we used collections alias &ndash; every time we need to do a full import we <strong>create a new collection and after the updates and validations are done, we change the alias and delete the old collection</strong>.</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-sh'>## Get the current collection OM-1

curl [SOLR_HOST]/solr/admin/collections?action=LIST

#
#{
#  &quot;responseHeader&quot;: {
#    &quot;status&quot;: 0,
#    &quot;QTime&quot;: 0
#  },
# &quot;collections&quot;: [
#    &quot;OM-1&quot;
#  ]
#}

## Create the new collection OM-2
curl [SOLR_HOST]//solr/admin/collections?Action=CREATE&amp;name:OM-2

## Create the new data file and post it to the new collection
curl -XPOST -d @updates.json [SOLR_HOST]/solr/OM-2/update

##  Override the alias to point to the new collection OM-2
curl [SOLR_HOST]/solr/admin/collections?action=CREATEALIAS&amp;collections=OM-2&amp;name=OM

## Delete the old collection
curl [SOLR_HOST]/solr/admin/collections?action=DELETE&amp;name=OM-1&amp;wt=json</code></pre></figure>


<h3>How to do a full import for all collections without causing high CPU usage?</h3>

<p>In our architecture we have a collection for each country and since all countries share similar documents with small variations, like price, we use one mysql source and fork the backend to import updates for each country <a href="https://www.npmjs.com/package/zindex">(see Zindex)</a>
When we pushed updates for all countries in parallel, the solr CPU usage spiked and in order to solve this, we had to <strong>do the update synchronously with <a href="https://github.com/tj/co">co</a></strong></p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>  return prepareSolr(availableCountries, options).then(() =&gt; {
    return co(function* () {
      for(var i = 0; i &lt; availableCountries.length; i++) {
        var country = availableCountries[i];
        var result = yield importProducts(country, options);
        logger.info(`Solr Import has been finished for country ${country} with result`, result);
      }
    }).then(()=&gt;{
        logger.info(`All solr countries finished!`);
    })</code></pre></figure>


<p><img src="http://namshi.github.io/images/solr-cpu-usage-spike.png" alt="CPU usage went down!" /></p>

<h3>How to maintain solr cluster well?</h3>

<p>Just like most of our services, we <strong><a href="https://www.docker.com/">dockerize it</a></strong>. We have a monitoring script that checks the container status and another one that checks the app status e.g zookeeper replication status and solr ping, if any check fails we get an alert and apply the necessary fix.</p>

<p><img src="http://img.photobucket.com/albums/v418/bawanaal/MissionAccomplished.gif" alt="Mission Accomplished" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Get that job at Namshi]]></title>
    <link href="http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi/"/>
    <updated>2016-12-06T10:54:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/12/06/get-that-job-at-namshi</id>
    <content type="html"><![CDATA[<p>Inspired by <a href="https://hautelook.github.io/jekyll/update/2015/04/01/get-that-job-at-hautelook.html">HauteLook</a> who,
in turn, were inspired by <a href="http://steve-yegge.blogspot.ae/2008/03/get-that-job-at-google.html">Steve Yegge</a>,
I decided to write a small article that briefly describes what we&rsquo;re looking for
when interviewing potential candidates.</p>

<!-- more -->


<h2>The process</h2>

<p>Our recruitment process tends to be quite lean (with a few exceptions :)):</p>

<ul>
<li>a first, introductory chat with me to get to know each other (<em>45m</em>)</li>
<li>a chat with someone from our HR department, so that the candidate gets a solid overview on our company, the culture, benefits and so on. This is also very helpful for people who are relocating, as it&rsquo;s the best time to ask anything about working in Dubai and so on (<em>1h</em>)</li>
<li>a more technical interview with someone from our <a href="http://namshi.github.io/team">tech team</a> (usually 2 of our senior engineers) (<em>1/2h</em>)</li>
</ul>


<p>Additionally, depending on the candidate and the position, there <strong>might</strong> be a
few additional steps required:</p>

<ul>
<li>coding challenge (<em>no deadlines, should take up to 2 hours of your time</em>)</li>
<li>additional technical screening with me (<em>1h</em>)</li>
<li>chat with one of our managing directors (<em>45m</em>)</li>
</ul>


<p>So you can generally assume that, after 3 positive interviews (&frac34; hours in total), you
could theoretically receive an offer letter.</p>

<p>Expect the whole process to take around 3 weeks.</p>

<h2>Backend</h2>

<p>You should be familiar with minimalist frameworks like Express or Silex, as that&rsquo;s
how we build 99% of our services nowadays. We&rsquo;re not big on any particular language,
but if you worked with Node that&rsquo;s definitely a plus, as well as understanding
async programming.</p>

<p>Being familiar with a shell is kind of a must, as we want people who can poke
around with Linux and are aware of the potential of the &ldquo;<em>do one thing and do it well</em>&rdquo;
philosophy.</p>

<p>The HTTP protocol (both 1.1 and 2) is another must as that&rsquo;s what we speak each
and every day &mdash; you will be mainly tasked to write applications that talk to
other services through HTTP. Knowing what changes with HTTP/2 and why that&rsquo;s
great shows the kind of awareness we&rsquo;re looking for.</p>

<p>We&rsquo;re not big on algorithms and data structures but that doesn&rsquo;t mean you
shouldn&rsquo;t be able to understand them &mdash; having some basic knowledge of Big O
is always appreciated, as well as understanding how to pick a data structure in
order to make the most out of it.</p>

<p>We use both relational and non-relational databases, and you should be
comfortable with a few names here (mostly MySQL and Redis). On MySQL, questions
about race conditions, locking and <code>ALTER TABLE</code> might come up.</p>

<h2>Frontend</h2>

<p>This position is all about JS &mdash; forget CSS, forget HTML: 99% of this position
will mean JavaScript.</p>

<p>Callbacks? Promises? async / await? Breakfast for you :)</p>

<p>You should be familiar with technologies like Angular 1 and React, and how they
work behind the curtain. We could ask you to write a simpler, smaller version of
redux so you&rsquo;d better understand how these libraries work.
For example, knowing that virtual DOM makes things faster won&rsquo;t cut it &mdash; why,
how and thanks to what data structure will.</p>

<p>We also have a keen eye on performance, and you should too: understanding what
changes HTTP/2 brings to frontend engineering is a must, as well as knowing basic
rules for performance optimization (<code>webpack -p</code> anyone?). We aren&rsquo;t super-fussy
about the more advanced stuff, but if you mention tree-shaking and friends we
won&rsquo;t mind :)</p>

<p>You should be familiar with methodologies such as BEM as you will be required to
discuss what&rsquo;s the best approach to structure our styles for the long run.
We also like to sometimes use CSS animations, so knowing how to make them perform
better, especially for mobile browsers, is highly appreciated.</p>

<h2>DevOps</h2>

<p>You should be very familiar with AWS or similar providers ie. Google Cloud, and
have some sort of experience with containers and orchestrators &mdash;
we use Kubernetes but if you worked with Mesos / Swarm we won&rsquo;t really mind.
A good answer to &ldquo;<em>Why would you want to use an init system inside a container?</em>&rdquo;
will definitely speed up the hiring process :)</p>

<p>Be big on Linux, as we expect you to be a ninja there &mdash; utilities
like <code>awk</code>, <code>sed</code> and so on should be music to your ears.</p>

<p>You should be familiar with one scripting language (make it python, ruby, php, bash)
and be open to jump into code, as you might be required to provide bugfixes on
some of our services, or implement system-related features. In general, the more
you can code the happier everyone is!</p>

<p>A keen eye on security is a big plus &mdash; we&rsquo;re a small team and we need brilliant
people who are going to take into account the problems that might happen when
using (or <strong>not using</strong>) a particular technology, pattern or methodology.</p>

<p>We are also big fans of automation and, in some sense, immutable infrastructures.
Know the basics.</p>

<h2>And we also generally look for&hellip;</h2>

<ul>
<li>automated testing is king here: despite the fact that we don&rsquo;t try to cover
100% of the use-cases, we rely on automated tests a lot. Knowing how to write
them, and what methodologies to use to make tests more maintainable is a must.</li>
<li>it would be great to see some of your code &mdash; github is a fan-favorite here :)</li>
<li>people who like <a href="https://en.wikipedia.org/wiki/Shawarma">shawarma</a></li>
</ul>


<p>What are you waiting for? Drop everything and <del>order some shawarma</del> <a href="http://namshi.github.io/join-us/">apply now</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Browser geolocation: the good, the bad and the ugly]]></title>
    <link href="http://namshi.github.io/blog/2016/11/13/browser-geolocation-the-good-the-bad-and-the-ugly/"/>
    <updated>2016-11-13T18:37:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/11/13/browser-geolocation-the-good-the-bad-and-the-ugly</id>
    <content type="html"><![CDATA[<p>We&rsquo;re a little late to the party &mdash; but we&rsquo;re here, amongst those who are
playing around with the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Geolocation/Using_geolocation">geolocation API</a>
provided by browsers.</p>

<p>Without further ado, let me get straight to our feedback on one the nicest web
APIs that have been standardized in recent times.</p>

<!-- more -->


<h2>Background</h2>

<p>We&rsquo;ve always been looking for ways to ease our checkout workflow, as a simpler
process usually means happier customers, and the ability to automagically
detect the device&rsquo;s location lets us take away from our customers the burden
of having to manually fill forms:</p>

<div align="center">
  <video src="http://namshi.github.io/videos/geolocation.webm" controls autoplay loop></video>
</div>


<p>Now that you&rsquo;ve seen it in action let&rsquo;s dig a little bit on what we found out
while implementing this little thing of beauty.</p>

<h2>The good</h2>

<p>First off, let me start by saying that, luckily, browser support is
<a href="http://caniuse.com/#feat=geolocation">widespread</a>, as the only major browser
that is currently lacking support is Opera Mini (not a biggie).</p>

<p>Detecting the user&rsquo;s location is also quite simple:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>var opts = {
  enableHighAccuracy: true,
  maximumAge        : 1000,
  timeout           : 1000
};

function onSuccess(position) {
  console.log(position.coords.latitude, position.coords.longitude)
}

function onError(err) {
  console.log(err)
}

navigator.geolocation.getCurrentPosition(onSuccess, onError, opts);</code></pre></figure>


<p>If this is the first time you&rsquo;re trying to access the device&rsquo;s position the
browser will show a popup to inform the user the website&rsquo;s trying to access the
device&rsquo;s location, so that he or she can accept or decline. The rest is history :)</p>

<p><strong>Takeaway</strong>: this is going to sound like a typical 80/20 story &mdash; it takes no
time to get most done, and a proportially long time to sort the wonky details
out. Regardless, the experience has been pretty positive.</p>

<h2>The bad</h2>

<p>Detecting the device&rsquo;s location turns out pretty handy on desktop devices, as
you can safely assume they won&rsquo;t move around :) Phones and tablets, on the
other hand, will probably be used around so there&rsquo;s a good chance that the
customer might move away / be away from the destination.</p>

<p>The problem is that on desktop you don&rsquo;t really get a very accurate position as
the geolocation service the browser uses won&rsquo;t have any GPS triangulation
available, so you&rsquo;re left with heuristics based on <a href="http://stackoverflow.com/questions/1668304/how-does-google-calculate-my-location-on-a-desktop">IP address mapping and previous
information about nearby networks</a>.</p>

<p><strong>Takeaway</strong>: we went mobile-first and decided to ignore desktop devices for now
(coming soon!).</p>

<p>In addition, error callbacks aren&rsquo;t as accurate as they are supposed to be: on
android, for example, if the user doesn&rsquo;t have the GPS enabled, you might get a
very cryptic error such as &ldquo;<em>User denied geolocation</em>&rdquo; &mdash; which isn&rsquo;t really
what&rsquo;s happening.</p>

<p><strong>Takeway</strong>: don&rsquo;t really rely on the error callbacks to distinguish between
errors, as they&rsquo;re not 100% reliable across all platforms. Consider any error as
a general failure, indicating that something might have gone wrong:</p>

<ul>
<li>the user didn&rsquo;t accept the geolocation request</li>
<li>the geolocation request failed for some reason</li>
<li>the GPS wasn&rsquo;t turned on</li>
<li>apocalypse just happened :)</li>
</ul>


<p>Last but not least, we were very surprised that geolocation depended on the GPS
being manually turned on, at least on Android. I don&rsquo;t know how
many android users go around with their GPS turned on but I bet it&rsquo;s a pretty
small percentage considering how it affects battery usage. We thought the
browser could temporarily turn the GPS on on its own, but that isn&rsquo;t the case. On
iOS, for some reason, it seems the percentage of users having <em>location services</em>
enabled is quite higher, thus the impact isn&rsquo;t as high.</p>

<p><strong>Takeaway</strong>: be prepared to help users figure out what&rsquo;s wrong &mdash; give them
clear instructions on what steps are required to successfully geolocate them:</p>

<ul>
<li>location services / GPS must be on</li>
<li>internet access (well&hellip;)</li>
<li>accept the geolocation request</li>
</ul>


<h2>The ugly</h2>

<p>Oh boy, we didn&rsquo;t see this coming.</p>

<p>Follow me on this simple workflow on an android phone:</p>

<ul>
<li>trigger a geolocation request, but with the GPS off</li>
<li>request fails for obvious reasons</li>
<li>enable GPS</li>
<li>trigger a new geolocation request</li>
</ul>


<p>What in the world would you expect to happen?</p>

<p>Surprise, it doesn&rsquo;t work. And guess what, if you refresh the page an trigger
the request again everything&rsquo;s good &mdash; so somehow chrome isn&rsquo;t really able to
&ldquo;recover&rdquo; from a failed request until the page is refreshed. Go figure.</p>

<p>Of course, triggering a full page reload on our checkout is out of question, as
that distracts the user away and delays the checkout process, so we looked around
for alternative solutions and thought of giving iframes a try &mdash; surprisingly,
it worked. Go figure.</p>

<p>The idea is very simple &mdash; once the user clicks on the &ldquo;<em>Detect my location</em>&rdquo;
button we load an invisible iframe that triggers the geolocation request:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-javascript'>getCurrentPosition = function(){
  return new Promise((resolve, reject) =&gt; {
    var ifr = document.createElement(&apos;iframe&apos;);
    ifr.style.opacity = &apos;0&apos;;
    ifr.style.pointerEvents = &apos;none&apos;;
    ifr.src = window.location.origin + &apos;/geo.html&apos;;

    document.body.appendChild(ifr);

    ifr.contentWindow.addEventListener(&apos;message&apos;, function(message){
      message = JSON.parse(message.data);
      document.body.removeChild(ifr);

      if(message.type === &apos;success&apos;){
        resolve(message.data);
      } else {
        reject(message.data);
      }
    });
  ]})
};</code></pre></figure>


<p>(the above code got trimmed for the sake of brevity)</p>

<p>As you might have figured, we listen for a message from the iframe, which is
responsible for getting the users&#8217; location and sending it to us:</p>

<figure class='code'><figcaption><span></span></figcaption><pre><code class='language-html'>&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;title&gt;Geolocation&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;script type=&quot;text/javascript&quot;&gt;
    var triggerGeolocationRequest = function(){
      var options = {
        enableHighAccuracy: true,
        timeout: 1000,
        maximumAge: 1000
      };

      var result;

      window.navigator.geolocation.getCurrentPosition(function(position){
        var result = {
          type: &apos;success&apos;,
          data: {lat: position.coords.latitude, lng: position.coords.longitude}
        };

        window.postMessage(JSON.stringify(result), window.location.origin);
      }, null, options)
    };

    window.addEventListener(&apos;load&apos;, triggerGeolocationRequest);
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre></figure>


<p>(the above code got trimmed for the sake of brevity)</p>

<p>And that does the job: the browser sees the iframe as a brand new page, thus
is able to overcome this wonky issue. Again, go figure.</p>

<p><strong>Takeaway</strong>: iframes, rescuing lazy web developers since 1997.</p>

<h2>All in all&hellip;</h2>

<p>Our feedback is generally positive, as customers have started to use it from day
1 at a good rate (~10% of our mobile checkouts is &ldquo;geolocated&rdquo;). There are a few
quirks here and there but if you survived IE6 then this is really going to feel
like a piece of cake.</p>

<p>A big &ldquo;thanks&rdquo; goes to my partners in crime <a href="http://namshi.github.io/team/#Mohamed%20Amin">Mohamed</a>, <a href="http://namshi.github.io/team/#Gabriel%20Izebhigie">Gabriel</a>, <a href="http://namshi.github.io/team/#Shidhin%20CR">Shidhin</a>, <a href="http://namshi.github.io/team/#Razan%20Bilwani">Razan</a> and
<a href="http://namshi.github.io/team/#Yomna%20Sabry">Yomna</a>, the real masterminds behind this new feature :)</p>

<p>Au revoir!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Welcome Gabriel!]]></title>
    <link href="http://namshi.github.io/blog/2016/10/31/welcome-gabriel/"/>
    <updated>2016-10-31T12:32:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/10/31/welcome-gabriel</id>
    <content type="html"><![CDATA[<p>Fresh new vibes in the tech team as we have a new joiner who likes to hack with
JavaScript on the browser!</p>

<!-- more -->


<p><img class="left" src="http://namshi.github.io/images/gabriel.jpg" width="200"></p>

<p>Gabriel is a Frontend Engineer, who holds a B.Sc in Engineering from University
of Ibadan Nigeria.</p>

<p>He loves to build products that are functional, beautiful and easy to use.
His main focus is Frontend development (a lot of Javascript, HTML, CSS, Sass…)
and some UX to go with it (on the server NodeJS and basic PHP).</p>

<p>He loves challenging myself to do more and push beyond the limits.
His best quote is “<em>if you do it right, it would last forever – Massimo Vignelli</em>”</p>

<p>Welcome amongst the Namshees!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lightning talks #3]]></title>
    <link href="http://namshi.github.io/blog/2016/10/17/lightning-talks-17-10-2016/"/>
    <updated>2016-10-17T00:00:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/10/17/lightning-talks-17-10-2016</id>
    <content type="html"><![CDATA[<blockquote><p>At Namshi, as you probably know, we do several activities, like &ndash; small presentations about new technologies,
showcases of the latest projects, watching interesting conference talks, etc.
We had our third edition of lightning talk. Each of our team members gave a small presentation about something they found interesting.
Here is a recap of what they spoke about, and we hope you will find it interesting as well!</p></blockquote>

<!-- more -->


<p><a href="http://namshi.github.io/team/#Alessandro%20Nadalin">Alex</a> Spoke about some tricks in bash</p>

<p><a href="team/#Hossam%20Fares">Hossam</a> Explained how to use generators for sequential promises</p>

<p><a href="team/#Mohamed%20Amin">Amin</a> Spoke about Promises Breakdown</p>

<p><a href="team/#Ayham%20Alzoubi">Ayham</a> Introduced the await/async features in nodejs to the team</p>

<p><a href="team/Joe%20Jean">Joe</a> Gave an example about how to use the shortest path algorithm</p>

<p><a href="team/#Oluwaseun%20Obajobi">Oba</a> Gave us some system tweaks</p>

<p><a href="team/#Shidhin%20CR">Shidhin</a> Showed us some tips in Chrome DevTools</p>

<p><a href="team/#Geshan%20Manandhar">Geshan</a> Introduced CodeceptJs as a modern acceptance testing tool for NodeJS to the team</p>

<p><a href="">Samar</a> Spoke about Artificial Intelligence Markup Language (AIML)</p>

<p><a href="team/#Adedamola%20Disu">Disu</a> Showed us the benefits of The Great Suspender Chrome extension</p>

<p><a href="team/#filippo%20de%20santis">Filo</a> Mentioned Yarn package manager and Nock as mocking library</p>

<p>And here are the slides:</p>

<iframe src="https://docs.google.com/presentation/d/1733hpKGtrz46rJPE44SObqsZWsWIoVsjDGBh9RlPsPc/embed?start=true&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>


<p><a href="https://docs.google.com/presentation/d/1733hpKGtrz46rJPE44SObqsZWsWIoVsjDGBh9RlPsPc/pub?start=false&amp;loop=false&amp;delayms=3000">https://docs.google.com/presentation/d/1733hpKGtrz46rJPE44SObqsZWsWIoVsjDGBh9RlPsPc/pub?start=false&amp;loop=false&amp;delayms=3000</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Embracing Accelerated Mobile Pages (AMP) for Speed and Profit]]></title>
    <link href="http://namshi.github.io/blog/2016/09/20/embracing-amp-for-the-speed-and-profit/"/>
    <updated>2016-09-20T11:30:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/09/20/embracing-amp-for-the-speed-and-profit</id>
    <content type="html"><![CDATA[<p>Over the past years, we have seen the rise of smartphones. Mobile phones and mobile browsers became more powerful as they have the hardware and processors in par with  desktops. Subsequently, this lead to a rapid growth mobile browsers usage over desktop browsers.</p>

<p>On the other hand, mobile browsers has a hidden cost &mdash; called Performance.In terms of performance, they were always been compared with Native apps. The native apps had better performance because of the underlying OS level support. They could cache big chunks of data offline, hence wouldn’t suffer from network latencies. Mobile browsers/websites didn’t have this luxury and they have to bear the performance problems, always.</p>

<!-- more -->


<p>UI frameworks and libraries could use the latest technologies ( CSS Animations, VirtualDom and WebComponents ..etc ) to fight with native apps in terms of rendering performance. However, page loading performance remained as the biggest issue for mobile websites. Although, the HTTP2 protocol would be able to solve some of these issues, the web needs alternate solutions.</p>

<h2>Meet AMP</h2>

<p>AMP &mdash; Accelerated Mobile Pages &mdash; is an open source initiative from Google to fix the slowness of mobile websites. AMP initially targeted only the publishing platforms, but sooner grown into all kind of websites. The AMP team in Google is actively working for enabling more support for E-commerce websites. You can find about that more <a href="https://amphtml.wordpress.com/2016/08/22/getting-started-with-amp-for-e-commerce/">here</a></p>

<p><a href="https://www.ampproject.org/">AMP Project</a> is a collection of components and guidelines from Google on building high performing websites. These components were developed for achieving better rendering and loading performance. Google also built tools for validating the AMP pages to make sure they meet the standards.</p>

<p>Once an AMP page meets the AMP html requirements, and passes the validations, Google can cache them and serve from their CDN. These caches are highly optimized for the fastest loading experience. Moreover, websites can forget about performance problems, as it&rsquo;s on Google&rsquo;s shoulder now.. :)</p>

<p>Though the AMP project was started for the publishing platforms initially, it is grown from there. As of now, the AMP website has enough components to build a web page for an e-commerce website. Ebay was the first website to use AMP html in their website and now they have built more than 2 million AMP pages. You can read more about their stuff <a href="www.ebaytechblog.com/2016/06/30/browse-ebay-with-style-and-speed/">here</a></p>

<h2>AMP in Namshi</h2>

<p>We’re one of the top e-commerce website in MENA region. Similar to Ebay, we have seen the potential of AMP pages in e-commerce websites. AMP pages can play a vital role in the organic search results. No one would love to open a slow website even if it’s the first one in Google search results. Sooner, people will look for the AMP tag in Google results, than clicking on the first one.</p>

<p>As said, giving an ultrafast loading experience to the users was our main goal. We knew that AMP would be the right choice for this ( considering the traffic from organic search results ). At this time, AMP had all the ingredients for our requirements, and more importantly, we didn’t have to make many changes to the existing website.</p>

<p>We found out that the catalog pages are the best candidate for us to start with. First, because they are the most linked from organic search results. Second, AMP website had all the components required to build our catalog pages. We didn’t write a single JavaScript line of code to make it work!</p>

<h2>How we started</h2>

<p>As explained earlier, we chose the catalog pages for AMP. Now, let’s recap the AMP requirements:</p>

<ol>
<li>No custom JavaScript on the page</li>
<li>All CSS has to be AMP compliant ( you cannot use specific styles, no !important ..etc ) and should be inlined in the <head> tag.</li>
<li>Wherever applicable, AMP component should be used. For example, amp-image, amp-iframe &hellip;etc</li>
</ol>


<p>All these were possible in catalog pages. We started by creating an amp version of the catalog page template and linked it with the non-AMP page by providing these meta tags.</p>

<figure class='code'><figcaption><span>AMP-html</span></figcaption><pre><code class='language-html'>&lt;meta href=”canonicalUrl” rel=“canonical” /&gt;</code></pre></figure>




<figure class='code'><figcaption><span>Original-html</span></figcaption><pre><code class='language-html'>&lt;meta href=”ampUrl” rel=“amphtml” /&gt;</code></pre></figure>


<p>Generating and serving the AMP html was straightforward in our mobile website. The only change was to add a new route prefixed with “/_amp/” to serve the catalog AMP html.</p>

<p>Now, we took the basic AMP template from <a href="https://www.ampproject.org/docs/get_started/create.html">here</a> and started the validation process. AMP validation in development is really simple; Just add the ”#development=1” in the url, and AMP will show all the errors and warning in the browser developer console.</p>

<p>This was the starting point. Now all we had to do is to add new markup/components and keep validating. By the end of the day, we built the complete catalog page structure with available AMP components.</p>

<p>The next big thing was the styling. As per the AMP requirements, we had to inline the whole CSS required for the catalog pages. These are the two tools came in handy for us:</p>

<ul>
<li><a href="https://github.com/purifycss/purifycss">Purify CSS</a></li>
<li><a href="https://chrome.google.com/webstore/detail/css-used/cdopjfddjlonogibjahpnmjpoangjfff">Chrome browser extension for extracting used CSS</a></li>
</ul>


<p>Once we had the required CSS generated, the final step was to integrate it with the build process. It was not a big deal, as we had to add a new gulp task to generate the AMP html and inline the CSS with it.</p>

<p>Last but not least, building the structured data for each catalog pages. AMP required structured data for validation &mdash; but dropped later ( <a href="https://support.google.com/webmasters/answer/6211453?hl=en">see this</a> ) &mdash; and this was pretty much an easy step. The structured data is processed and included at runtime based on the catalog page content.</p>

<h2>Main Challenges</h2>

<p>Here are the main challenges faced during the development.</p>

<ul>
<li><p><strong>No support for custom JavaScript:</strong>
AMP components are optimized for rendering performance. That’s why they restricted the usage of any other JavaScript code on the page. This wouldn’t be a problem if we were building everything from scratch, but it can be challenging when trying to build an AMP version of an existing page.</p></li>
<li><p><strong>Some components are still missing:</strong>
Initially AMP was more focused on content publishing platforms, hence most of the components are built for that. However, the project is growing and they have enough components for building a catalog page. However, while developing the AMP pages for our catalog pages, we wanted to use the TABS component, but it was not available. Therefore, we couldn’t build the same UI of our normal catalog page in AMP.</p></li>
<li><p><strong>Optimizing existing CSS for AMP requirements:</strong>
AMP has some restrictions on the CSS that should be used on the page. This can be tricky when converting an existing page to AMP, as you might have to manually remove style rules to make the validation pass. To know more, see the AMP styling <a href="https://www.ampproject.org/docs/guides/responsive/style_pages.html">requirements</a></p></li>
<li><p><strong>Analytics:</strong>
This was the biggest problem for us. We were using GTM ( Google Tag Manager ) for our website, but, AMP does not have any support for GTM scripts. Because of this, we couldn’t use our existing GTM script for tracking the AMP pages.
As of now, AMP analytics component supports multiple vendor configurations. The whole list can be found <a href="https://github.com/ampproject/amphtml/blob/master/extensions/amp-analytics/0.1/vendors.js">here</a>.For the time being, we use only the Google analytics component in our AMP pages.</p></li>
</ul>


<h2>The RESULT was amazing</h2>

<p>Less than 6 months ago, Google started showing AMP page in the “Top stories” news carousel. The news carousel was a special section on top of the search results, and shows only the AMP pages for articles and news.</p>

<p>Last month, Google announced the AMP support for all the other type of web pages. This means, Google will start indexing all type of AMP pages, and will display them with an AMP tag ( <img src="http://namshi.github.io/images/posts/AMP_logo.png" alt="amp-fast-logo" /> ) in search results. The lighting fast symbol implies that the page is actually cached in Google CDN and served as fast as possible.</p>

<p>As per Google,</p>

<blockquote><p>we’ve seen incredible global adoption of AMP that has gone beyond the news industry to include e-commerce, entertainment, travel, recipe sites and so on. To date we have more than 150 million AMP docs in our index, with over 4 million new ones being added every week. As a result, today we’re sharing an early preview of our expanded AMP support across the entire search results page &mdash;not just the “Top stories” section.</p></blockquote>

<p>To support a better user experience for AMP in search results, Google provided an early preview demo page. This is actually useful for developers to test their AMP pages before Google go live with AMP search result. So far, we have most of our catalog pages indexed, and the early AMP search results preview looks amazing.</p>

<p><img class="center" src="http://namshi.github.io/images/posts/namshi-amp-demo.gif" title="Namshi AMP Demo" alt="Namshi AMP Demo"></p>

<p>This is the kind of page loading experience we wanted to provide to our customers, and AMP was the right choice for us. We’re pretty happy with the outcome and very much excited to see the actual results once Google rollout AMP search.</p>

<p>If you want to see the AMP preview, go to <strong><a href="https://g.co/ampdemo">g.co/ampdemo</a></strong> (in a mobile browser) and try the search query “namshi lacoste shoes”. We want your feedbacks!</p>

<h2>Future Work</h2>

<p>Currently we have only the catalog pages AMP-fied. We would like to try it out on more pages &mdash; once more components are available.</p>

<p>Moreover, we need to make the transition from AMP pages to the regular pages as smooth as possible. The best plan would be to use a service worker to cache all the assets from the website. The service worker can be installed either using a <a href="https://ampbyexample.com/components/amp-install-serviceworker/">amp-service-worker component</a>  or <a href="https://philna.sh/blog/2016/08/17/install-a-service-worker-declaratively/">declaratively</a> with a link tag. More importantly, this will open doors to more cool experiments like push notifications, app-shell caching ..etc. The AMP+SW combo seems to work well, and if you want to see a working example, checkout the <a href="https://www.ampproject.org/">AMP website</a>.</p>

<p>We also want to add HTTP2 and Server push to our mix and experiment with them. These are all the features we’re planning to add to the current setup.</p>

<p>Finally, Thanks to all the people who make the web awesome !</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Breakpoint On Namshi]]></title>
    <link href="http://namshi.github.io/blog/2016/08/17/breakpoint-on-namshi/"/>
    <updated>2016-08-17T09:13:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/08/17/breakpoint-on-namshi</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://namshi.github.io/images/posts/rainy-duabi.jpeg"></p>

<p><span class="figcaption_hack">Rainy days in Dubai are rare! same as good places to work.</span></p>

<p>Almost 2 years ago, I landed at the Dubai Airport on a flight that took off from
Egypt and for several reasons, a flight that won’t have a return ticket back to
Egypt (at least anytime soon, I hope).</p>

<!-- more -->


<p>At the Airport I faced one issue with my Visa, and I was about to get denied
entry: Only thanks to a polite Emirate police officer I was able to get through;
a thing, I’ve been told later on, it was unprecedented, unheard of.</p>

<h3>The Oblivion</h3>

<p>Initially, when I was hired by Namshi, I was a designer comfortable around
Photoshop and Css and, eventually, I had to learn a lot more in such a short
period of time.</p>

<p>My first weeks went by with me sitting around people who were talking about
stuff I didn’t understand, they were just doing their job normally, though,
everything sounded mythical to me.</p>

<p>My first task involved creating an application that helps the Customer Care
agents to speed up the lookup of customer details while they’re receiving a
call.</p>

<p>Imagine what I had to learn, to start building an angular application while,
back then, I barely heard of Javascript as a programming language: the best I knew was to search StackOverflow to get something that would work … in jQuery!</p>

<blockquote><p>It worked, … I don’t know how, but it did!</p></blockquote>

<p>“It worked, … I don’t know how, but it did!” I said to my team mates and manager hundreds of times!</p>

<p>You might think that life isn’t easy to grasp, <strong>but Javascript is much harder</strong> from a point of view of a designer who wants to code.<br>
I kept fighting every day to get through with an output that would make me feel quite
accomplished and I want to say that, honestly, it wasn’t an easy quest (and, by
the way, wasn’t always successful either).</p>

<p><img class="left" src="http://namshi.github.io/images/posts/gb-amino.jpeg">
<span class="figcaption_hack">Don’t leave your computer Unlocked, seriously, Don’t! A hard-learned lesson :D</span></p>

<p><strong>Bottom line: </strong> those days, I always felt overwhelmed, not knowing what I
should do most of the time; it was fun and exciting to learn but, make no
mistake, nothing is harder on a productive former-designer than seeing his
output not matching the one by his peers by any criteria.</p>

<p>The only thing I knew was that I had to push through…</p>

<h3>Light at the end of tunnel</h3>

<p>Things started to make sense: now I don’t ask “what is that?” on every term that
falls on my ears, I don’t struggle each time I want to use Promises or create a
helper function, I started to see some patterns and cling to them.</p>

<p>It was the light at the end of the tunnel, things started to make sense, I
started to have an edge doing stuff and started to believe that I only lacked a
much needed experience to be like my peers or even better, and this is something
that I’m going to compensate by an over-dose of self-learning as I did before.</p>

<br>




<br>


<p><img class="left" src="http://namshi.github.io/images/posts/arabic_quote.jpeg"></p>

<p>Anis Mansoor</p>


<blockquote><p>If he knows well , he would know that he doesn’t.</p></blockquote>

<p>That is a translated quote from an arabic wisdom saying, which describes the
situation pretty well. I just got into the surface and I thought I already
reached the nirvana!</p>

<p>I came to realize the true light at the end of the tunnel, it was something said
in one of several performance reviews that we hold on a monthly basis: ”Now, I
know what I want to know, previously I had no idea how deep it was”.</p>

<p><img class="left" src="http://namshi.github.io/images/posts/tech-trivia.jpeg">
<span class="figcaption_hack">One of the Code and Tech Trivias that took place recently, My team lost :S</span></p>

<h3>Fast Forward</h3>

<p>Now, I reached somewhere where I feel comfortable to talk about the previous
events of these very condensed months.</p>

<p>I would be happy to let you know that, finally, I did it, I prevailed, I became
a super ninja full stack developer who knows about DB, Docker and knows a bunch
of modern shiny tools and frameworks, can write Javascript while sleeping as
well …</p>

<p>But that isn’t true! (except the part of sleeping :)</p>

<p>But the real accomplishment is that my mindset has changed! This is the true
victory, I like to believe that now I think, plan and decide better! <strong>That</strong> is
the real breakthrough for me!</p>

<p>Technology doesn’t matter, it is always the matter of how you think your way out
of a problem: I feel more competent with such a mindset rather than a handful of
a skill-sets that aren’t properly utilized.</p>

<h3>Takeaways</h3>

<p>I didn’t want to sound self-promoting, I tried to be honest as much as I could,
but the TL;DR for my last 2 years is:</p>

<ol>
<li>I kept saying “I don’t know how to do this”, and there was <strong>always</strong> someone
willing to spend time to make sure that I got it</li>
<li>I would had never got anywhere without a team, who doesn’t <strong>patronize</strong> me for
not knowing things, they would gladly baby walk me to the point instead</li>
<li>The right people and the right challenges are things that I have a little
control over, but I always make sure I’m grateful to have.</li>
<li>I’m not the smartest person in the room, which always put me under pressure.
What made the difference, for me, is that I was <strong>self-conscious</strong> of my
<strong>shortcomings</strong>. and most of time I had a plan to overcome this.</li>
<li>I spent the first six month reading and watching courses heavily, it reminded me
of 8 years ago when I was trying to kick off my graphic design career. Let’s be
fair, nowadays, it is much easier to find the <a href="https://medium.com/@MohamedAmin88/web-designer-guide-to-front-end-stack-a8f72a2cd157#.clmhzr7rw">perfect learningmaterial</a> and this is something not to be taken lightly.</li>
<li>On my first weeks, I was cheered for my first push to live fix, which was a
really minor thing, but it greatly boosted my <strong>confidence</strong> and <strong>willingness</strong>
to contribute more. Now, on a daily basis, I tackle bugs , add features then
test them on the staging environment and single handedly deploy them live (which
I am now privileged to do!) with just an approval from a peer developer on the
Pull Request.</li>
<li>…which takes us to The PR aka Pull Request challenge: arguably, I can say that
30% of what I learnt was because of PRs; it was (and still is) not an easy job
to get approval on you PR from your peers or even worse (if your doomed :D )
from our VP of technology .</li>
</ol>


<br>


<p><img src="http://odino.org/images/meme-odino.jpg" alt="" /></p>

<ol>
<li><p>It is one of the most common syndromes,  I-don’t-think-it-is-good-enough
syndrome  , I have been pushed by teammates to contribute to open source and
get over the shyness! this one of the things that I should have done really
earlier and, as a note to self, I should do more often :)</p></li>
<li><p><strong>Pair programming for the win; </strong> one of the nice perks that was a super
catalyst for improving my programming skills. Nothing is better than to think
with another mind and code together, I gained a lot by watching how someone more
experienced tackles problems and breaks features down more than I learned from
courses, reading or blog posts.</p></li>
</ol>


<p>At the end, this was a retrospective on my work/life at Namshi, to have a look
at my current pace and give myself a bit of perspective on both past and
foreseeable future.<br> My hope is that, the next time I look back, I see that I
had more mistakes, more revelations and lessons-learned.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Currently hiring: a DevOps engineer and a JS hacker here in Dubai]]></title>
    <link href="http://namshi.github.io/blog/2016/08/07/currently-hiring-a-devops-engineer-and-a-js-hacker-here-in-dubai/"/>
    <updated>2016-08-07T11:29:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/08/07/currently-hiring-a-devops-engineer-and-a-js-hacker-here-in-dubai</id>
    <content type="html"><![CDATA[<p>Hey folks, here at <a href="https://www.namshi.com">Namshi</a> we&rsquo;re currently looking
to beef our team up &mdash; without further ado, let me quickly go through both
of them!</p>

<!-- more -->


<ul>
<li><p><strong>Sr. DevOps engineer</strong>: we run our entire stack on AWS, and 99% of our
services run in Docker containers orchestrated via <a href="http://kubernetes.io/">Kubernetes</a>:
a big chunk of our infrastructure is provisioned through <a href="https://saltstack.com/">SaltStack</a>
and we like to keep things simple, reliable and robust &mdash; inspired by
<a href="https://www.infoq.com/news/2013/05/dystopia-as-a-service">Netflix&rsquo;s dystopian architecture</a>.
We believe in fault-tolerant, reactive architectures that don&rsquo;t care about a
server going down, as others will be able to take on the load, or automated checks
will make sure new HW comes online &mdash; and that&rsquo;s how we setup our live infrastructure,
where a sizable chunk of our services runs through spot instances, with confidence :)
We are now looking for someone who can help us lifting the team a step further, playing
with tools like:</p>

<ul>
<li>golang / python / bash</li>
<li>Docker</li>
<li>Kubernets / Swarm / Mesos</li>
<li>AWS</li>
<li>SaltStack / Ansible / Chef</li>
</ul>
</li>
</ul>


<p>In the past 18 months we&rsquo;ve worked on a few interesting challenges such as:</p>

<ul>
<li>implementing ChatOps</li>
<li>utilizing containers on our live infrastructure</li>
<li>integrating Terraform to automate tasks / provisioning</li>
<li>reduced our AWS bill, while growing as a company, by writing more efficient
applications and introducing spot instances in our fleet</li>
</ul>


<p>This gives you an overview of the kind of stuff we would love you to work on:
we think of DevOps engineers as a mix between software developers
and system administrators, so we&rsquo;d like you to know a bit of both :)</p>

<ul>
<li><p><strong>(Sr.) JS engineer</strong>: it is no news that we&rsquo;ve been exploring the JS ecosystem
for a few years now: from rolling out our first angular apps in 2013 to testing
React Native in the past months, we&rsquo;ve been very busy trying to push our frontends
as far as possible.
We run a Service-Oriented architecture where JS plays a huge part: most of our
services are either SPAs or small NodeJS-backed APIs, and JavaScript is king at
Namshi.
We would like to work with someone who has a very strong background in the language,
who&rsquo;s been battling on the frontend for a few years and is not afraid to dive into
Node, if required.
Some of the things our frontend team has been working over the past few weeks:</p>

<ul>
<li>React Native</li>
<li>Redux</li>
<li>MobX</li>
<li>isomorphic JavaScript</li>
<li>AMP</li>
</ul>
</li>
</ul>


<p>Most of our frontend apps are built with Angular, although we&rsquo;re heavily experimenting
with React, even for our internal tools. With a fleet of 50+ microservices, we&rsquo;re
generally very busy trying to innovate as much as possible.</p>

<p>We&rsquo;re open to very promising, junior candidates even though we&rsquo;re currently hoping
to find someone with a few years of experience on his / her back &mdash; if you feel you
do not have the experience but have the right attitude, then let&rsquo;s definitely have
a chat.</p>

<p>What are you waiting for? Drop a line at <code>work-in-tech@namshi.com</code> and let&rsquo;s
start this journey together!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My First Two Weeks At Namshi]]></title>
    <link href="http://namshi.github.io/blog/2016/07/28/my-first-two-weeks-at-namshi/"/>
    <updated>2016-07-28T09:19:00+00:00</updated>
    <id>http://namshi.github.io/blog/2016/07/28/my-first-two-weeks-at-namshi</id>
    <content type="html"><![CDATA[<p>On July 10th, I joined <a href="https://namshi.com/">Namshi</a> as a Junior Software Engineer. I was really excited to start my first full time job writing software. Though, I have to confess that I was also a bit afraid and nervous. Fortunately, after just two days working with the team the fear and nervousness went away. In this post, I will share with you some of the things I have learned so far as well as what I love about working in this awesome team.</p>

<!-- more -->


<h3>Everyone is super nice</h3>

<p>From the first day I joined the team, everyone has been going out of their way to help me and make me feel welcome. In order to better understand the business as a whole, HR arranged for me to meet people from many other teams such as warehouse, business intelligence, and project management. All of those people were really nice and did a great job explaining to me how their department works.
In the tech team, I have interrupted some of my colleagues countless times to ask questions and they have always done their best to give me answers or point me to someone else who knows the answer. The VP of technology, Alex, who is also my manager has urged me to not be afraid to ask questions and discuss things with our senior engineers. In my opinion, this ability to ask questions without feeling like you are being annoying to your peers is crucial for a smooth integration of a new member, especially a junior like me, onto a team.</p>

<h3>Code quality is taken seriously</h3>

<p>On my second day, I was assigned my first task. It consisted in building a tool that could read a csv file containing a list of products and download the the image for each product from a website. This tool was for the PR department and it would reduce the amount of time it usually takes them to send new products images out to the press. Since the end users only have windows machines, the final product was supposed to be a windows executable. Because of that requirement, Alex suggested that we use the Go programming language; a language I hadn&rsquo;t used before. Ayham, one of the senior engineers on the team who was also new to Go buddied up with me to work on the project.
We started by brainstorming ideas and drawing a workflow diagram. Then, we moved to the coding part which was really fun. We managed to get something working by the next day. At one point, after making a few improvements to the code, I looked at it and thought to myself “ok, this looks great, we are done here”. But to Alex and Ayham, there was a lot of rooms for improvement. Therefore, the code went through multiple rounds of review. Each round, we were trying to make it better and better. I remember Ayham always asking &ldquo;can we do this in a better way?&rdquo; This experience taught me that even though code will never be perfect, it is still possible to attain good quality code if we care enough.</p>

<h3>Learning happens everyday</h3>

<p>Everyday, for the past two weeks, I was able to learn something new. I have learned about proper debugging techniques, Golang, how to be more productive by using keyboard shortcuts and how to break down the solution to a problem into steps before diving into coding etc&hellip; Not a day has passed without learning something new either from my manager&mdash;who is by the way an excellent teacher&mdash; or from my other colleagues.</p>

<h3>Work-life balance is encouraged</h3>

<p>We work from 9:00 am to 6:00 pm including one hour for lunch break. I often hear people say at one does not leave the office before one’s boss. But here at Namshi, that is not the case. After 6 pm anyone is allowed to go home even though our manager is still around. In fact, I have noticed that if our manager wants to discuss something with a team member after 6pm, he will always asks something along the lines of “do you have 5 minutes or are you leaving now?”. And to top it all off, on Thursdays (the last day of the week in the UAE) everyone is allowed to leave the office by 3 pm to go and start enjoying their weekend.</p>

<h3>I have one of the best managers in the world</h3>

<p>My manager, Alex, is really awesome! I’m sharing this because apparently <a href="https://hbr.org/2014/03/why-good-managers-are-so-rare/">great managers are rare</a>. The first time I interacted with him was during my first interview. I was really impressed by how he took the time to explain to me the answers to a few questions I could not answer. Then after joining, I have seen him teach, discuss ideas with, and help members  of the team &mdash;especially myself&mdash; on a daily basis.
For the past two weeks, at the end of each work day, we spend about 5 minutes talking about how my day went,  asking me for feedback for the team and giving me constructive feedback for myself. In addition to that he checks on me throughout the day to get updates on my progress in whatever task I’m working on.</p>

<p>All in all, I feel really blessed to be part of this team of talented and friendly people. I’m really excited for the long and fun road ahead.</p>

<p>If this blog post got you excited about the prospect of joining our team, please do send in an application as we are currently hiring :)</p>
]]></content>
  </entry>
  
</feed>
